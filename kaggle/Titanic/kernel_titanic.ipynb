{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import string\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "import warnings\n",
    "import math\n",
    "from collections import namedtuple\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import TitanicUtils as tu\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for the data processing\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if str.find(big_string, substring) != -1:\n",
    "            return substring\n",
    "    #print(big_string)\n",
    "    return np.nan\n",
    "\n",
    "def replace_titles(x):\n",
    "    title=x['Title']\n",
    "    if title in ['Don', 'Major', 'Capt', 'Jonkheer', 'Rev', 'Col', 'Mr', 'Master']:\n",
    "        return -1\n",
    "    elif title in ['Countess', 'Mme', 'Mrs']:\n",
    "        return 0\n",
    "    elif title in ['Mlle', 'Ms', 'Miss']:\n",
    "        return 1\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']==1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return title \n",
    "\n",
    "#The data processing for the training and testing data sets\n",
    "def data_train():\n",
    "    train_data = pd.read_csv(\"train.csv\")\n",
    "    \n",
    "    #Turning cabin number into Deck\n",
    "    cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "    train_data['Cabin'] = train_data['Cabin'].astype(str)\n",
    "    train_data['Deck'] = train_data['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    \n",
    "    train_data.loc[(train_data.Deck == 'A'),'Deck'] = -1\n",
    "    train_data.loc[(train_data.Deck == 'B'),'Deck'] = -.75\n",
    "    train_data.loc[(train_data.Deck == 'C'),'Deck'] = -.5\n",
    "    train_data.loc[(train_data.Deck == 'D'),'Deck'] = -.25\n",
    "    train_data.loc[(train_data.Deck == 'E'),'Deck'] = .25\n",
    "    train_data.loc[(train_data.Deck == 'F'),'Deck'] = .5\n",
    "    train_data.loc[(train_data.Deck == 'T'),'Deck'] = .75\n",
    "    train_data.loc[(train_data.Deck == 'G'),'Deck'] = 1\n",
    "    train_data[\"Deck\"] = train_data[\"Deck\"].fillna(0)\n",
    "    \n",
    "    #Creating new family_size column\n",
    "    train_data['Family_Size'] = train_data['SibSp'] + train_data['Parch']\n",
    "    \n",
    "    train_data['Age*Class'] = train_data['Age'] * train_data['Pclass']\n",
    "    \n",
    "    train_data['Fare_Per_Person'] = train_data['Fare']  / (train_data['Family_Size']+1)\n",
    "\n",
    "    train_data.loc[(train_data.Sex == 'female'),'Sex'] = -1\n",
    "    train_data.loc[(train_data.Sex == 'male'),'Sex'] = 1\n",
    "\n",
    "    train_data.loc[(train_data.Embarked == 'C'),'Embarked'] = -1\n",
    "    train_data.loc[(train_data.Embarked == 'Q'),'Embarked'] = 1\n",
    "    train_data.loc[(train_data.Embarked == 'S'),'Embarked'] = 2\n",
    "    train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(0)\n",
    "\n",
    "    train_data.loc[(train_data.Pclass == 1),'Pclass'] = 1\n",
    "    train_data.loc[(train_data.Pclass == 2),'Pclass'] = 0\n",
    "    train_data.loc[(train_data.Pclass == 3),'Pclass'] = -1\n",
    "    \n",
    "    train_data['Sex*Class'] = train_data['Sex'] * train_data['Pclass']\n",
    "    \n",
    "    train_data[\"Age\"] = train_data[\"Age\"].fillna(0)\n",
    "    \n",
    "    train_data[\"Age*Class\"] = train_data[\"Age*Class\"].fillna(0)\n",
    "    \n",
    "    train_data['Embarked*Class'] = train_data['Embarked'] * train_data['Pclass']\n",
    "    \n",
    "    train_data['Age*Deck'] = train_data['Age'] * train_data['Deck']\n",
    "    \n",
    "    #train_data[\"Embarked*Class\"] = train_data[\"Embarked*Class\"].fillna(0)\n",
    "\n",
    "    title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                        'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                        'Don', 'Jonkheer']\n",
    "\n",
    "    train_data['Title'] = train_data['Name'].map(lambda x: substrings_in_string(x, title_list))   \n",
    "    train_data['Title'] = train_data.apply(replace_titles, axis=1)\n",
    "    \n",
    "    train_data['Title*Class'] = train_data['Title'] * train_data['Pclass']\n",
    "\n",
    "    tmp = train_data[['Pclass', 'Title', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Deck', 'Title*Class',\n",
    "                      'Family_Size', 'Age*Class', 'Fare_Per_Person', 'Embarked*Class', 'Sex*Class', 'Age*Deck']].copy()\n",
    "    \n",
    "    X = pd.DataFrame(tmp).to_numpy()\n",
    "    X = X.T\n",
    "    Y = np.array([train_data['Survived'].values])\n",
    "\n",
    "    X = np.float32(X)\n",
    "    Y = np.float32(Y)\n",
    "    m = X.shape[1]  \n",
    "    #Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuff_X = X[:, permutation]\n",
    "    shuff_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    devM = round(m * .05)\n",
    "    devM2 = m - devM\n",
    "    \n",
    "    train_X = shuff_X[:, 0:(devM2)]\n",
    "    train_Y = shuff_Y[:, 0:(devM2)]\n",
    "    dev_X = shuff_X[:, -(devM + 1):-1]\n",
    "    dev_Y = shuff_Y[:, -(devM + 1):-1]\n",
    "    \n",
    "    m_train = train_X.shape[1]\n",
    "    m_test = dev_X.shape[1]\n",
    "    \n",
    "    print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "    print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "    print (\"train_set_x shape: \" + str(train_X.shape))\n",
    "    print (\"train_set_y shape: \" + str(train_Y.shape))\n",
    "    print (\"test_set_x shape: \" + str(dev_X.shape))\n",
    "    print (\"test_set_y shape: \" + str(dev_Y.shape))\n",
    "    \n",
    "    return train_X, train_Y, dev_X, dev_Y\n",
    "\n",
    "#The data processing for the submission data sets\n",
    "def data_test():\n",
    "    test_data = pd.read_csv(\"test.csv\")\n",
    "    \n",
    "    #Turning cabin number into Deck\n",
    "    cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "    test_data['Cabin'] = test_data['Cabin'].astype(str)\n",
    "    test_data['Deck'] = test_data['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    \n",
    "    test_data.loc[(test_data.Deck == 'A'),'Deck'] = -1\n",
    "    test_data.loc[(test_data.Deck == 'B'),'Deck'] = -.75\n",
    "    test_data.loc[(test_data.Deck == 'C'),'Deck'] = -.5\n",
    "    test_data.loc[(test_data.Deck == 'D'),'Deck'] = -.25\n",
    "    test_data.loc[(test_data.Deck == 'E'),'Deck'] = .25\n",
    "    test_data.loc[(test_data.Deck == 'F'),'Deck'] = .5\n",
    "    test_data.loc[(test_data.Deck == 'T'),'Deck'] = .75\n",
    "    test_data.loc[(test_data.Deck == 'G'),'Deck'] = 1\n",
    "    test_data[\"Deck\"] = test_data[\"Deck\"].fillna(0)\n",
    "    \n",
    "    #Creating new family_size column\n",
    "    test_data['Family_Size'] = test_data['SibSp'] + test_data['Parch']\n",
    "    \n",
    "    test_data['Age*Class'] = test_data['Age'] * test_data['Pclass']\n",
    "    \n",
    "    test_data['Fare_Per_Person'] = test_data['Fare']  / (test_data['Family_Size']+1)\n",
    "\n",
    "    test_data.loc[(test_data.Sex == 'female'),'Sex'] = -1\n",
    "    test_data.loc[(test_data.Sex == 'male'),'Sex'] = 1\n",
    "\n",
    "    test_data.loc[(test_data.Embarked == 'C'),'Embarked'] = -1\n",
    "    test_data.loc[(test_data.Embarked == 'Q'),'Embarked'] = 1\n",
    "    test_data.loc[(test_data.Embarked == 'S'),'Embarked'] = 2\n",
    "    test_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(0)\n",
    "\n",
    "    test_data.loc[(test_data.Pclass == 1),'Pclass'] = 1\n",
    "    test_data.loc[(test_data.Pclass == 2),'Pclass'] = 0\n",
    "    test_data.loc[(test_data.Pclass == 3),'Pclass'] = -1\n",
    "    \n",
    "    test_data['Sex*Class'] = test_data['Sex'] * test_data['Pclass']\n",
    "    \n",
    "    test_data[\"Age\"] = test_data[\"Age\"].fillna(0)\n",
    "    \n",
    "    test_data[\"Age*Class\"] = test_data[\"Age*Class\"].fillna(0)\n",
    "    \n",
    "    test_data['Embarked*Class'] = test_data['Embarked'] * test_data['Pclass']\n",
    "    \n",
    "    test_data['Age*Deck'] = test_data['Age'] * test_data['Deck']\n",
    "    \n",
    "    #test_data[\"Embarked*Class\"] = test_data[\"Embarked*Class\"].fillna(0)\n",
    "\n",
    "    title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                        'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                        'Don', 'Jonkheer']\n",
    "\n",
    "    test_data['Title'] = test_data['Name'].map(lambda x: substrings_in_string(x, title_list))   \n",
    "    test_data['Title'] = test_data.apply(replace_titles, axis=1)\n",
    "    \n",
    "    test_data['Title*Class'] = test_data['Title'] * test_data['Pclass']\n",
    "\n",
    "    tmp = test_data[['Pclass', 'Title', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Deck', 'Title*Class',\n",
    "                      'Family_Size', 'Age*Class', 'Fare_Per_Person', 'Embarked*Class', 'Sex*Class', 'Age*Deck']].copy()\n",
    "    \n",
    "    X = pd.DataFrame(tmp).to_numpy()\n",
    "    X = X.T\n",
    "\n",
    "    X = np.float32(X)\n",
    "    \n",
    "    test = X[:, :]\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(X, Y, tmpcache, lambd = 0):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input dataset, of shape (input size, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat)\n",
    "    cache -- cache output from forward_propagation()\n",
    "    \n",
    "    Returns:\n",
    "    gradients -- A dictionary with the gradients with respect to each parameter, activation and pre-activation variables\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    cache = {}\n",
    "    (a0, z1, a1, W1, b1, z2, a2, W2, b2, z3, a3, W3, b3, z4, a4, W4, b4, z5, a5, W5, b5, z6, a6, W6, b6) = tmpcache\n",
    "\n",
    "    for l in range(6):\n",
    "        zkey = 'z' + str(l+1)\n",
    "        akey = 'a' + str(l+1)\n",
    "        Wkey = 'W' + str(l+1)\n",
    "        bkey = 'b' + str(l+1)\n",
    "        cache[Wkey] = tmpcache[Wkey]\n",
    "        cache[bkey] = tmpcache[bkey]\n",
    "        cache[zkey] = tmpcache[zkey]\n",
    "        cache[akey] = tmpcache[akey]\n",
    "\n",
    "        \n",
    "    #dW3 = 1./m * np.dot(dZ3, A2.T) + ((lambd / m) * W3)\n",
    "    \n",
    "    if lambd > 0:\n",
    "        dz6 = 1./m * (cache['a6'] - Y)\n",
    "        dW6 = np.dot(dz6, cache['a5'].T) + ((lambd / m) * cache['W6'])\n",
    "        db6 = np.sum(dz6, axis=1, keepdims = True)  \n",
    "        dz5 = np.dot(cache['W6'].T, dz6) * (1 - np.power(cache['a5'], 2))\n",
    "        dW5 = np.dot(dz5, cache['a4'].T) + ((lambd / m) * cache['W5'])\n",
    "        db5 = np.sum(dz5, axis=1, keepdims = True)\n",
    "        dz4 = np.dot(cache['W5'].T, dz5) * (1 - np.power(cache['a4'], 2))\n",
    "        dW4 = np.dot(dz4, cache['a3'].T) + ((lambd / m) * cache['W4'])\n",
    "        db4 = np.sum(dz4, axis=1, keepdims = True)\n",
    "        dz3 = np.dot(cache['W4'].T, dz4) * (1 - np.power(cache['a3'], 2))\n",
    "        dW3 = np.dot(dz3, cache['a2'].T) + ((lambd / m) * cache['W3'])\n",
    "        db3 = np.sum(dz3, axis=1, keepdims = True)\n",
    "        dz2 = np.dot(cache['W3'].T, dz3) * (1 - np.power(cache['a2'], 2))\n",
    "        dW2 = np.dot(dz2, cache['a1'].T) + ((lambd / m) * cache['W2'])\n",
    "        db2 = np.sum(dz2, axis=1, keepdims = True)\n",
    "        dz1 = np.dot(cache['W2'].T, dz2) * (1 - np.power(cache['a1'], 2))\n",
    "        dW1 = np.dot(dz1, X.T) + ((lambd / m) * cache['W1'])\n",
    "        db1 = np.sum(dz1, axis=1, keepdims = True)\n",
    "    else:\n",
    "        dz6 = 1./m * (cache['a6'] - Y)\n",
    "        dW6 = np.dot(dz6, cache['a5'].T)\n",
    "        db6 = np.sum(dz6, axis=1, keepdims = True)  \n",
    "        dz5 = np.dot(cache['W6'].T, dz6) * (1 - np.power(cache['a5'], 2))\n",
    "        dW5 = np.dot(dz5, cache['a4'].T)\n",
    "        db5 = np.sum(dz5, axis=1, keepdims = True)\n",
    "        dz4 = np.dot(cache['W5'].T, dz5) * (1 - np.power(cache['a4'], 2))\n",
    "        dW4 = np.dot(dz4, cache['a3'].T)\n",
    "        db4 = np.sum(dz4, axis=1, keepdims = True)\n",
    "        dz3 = np.dot(cache['W4'].T, dz4) * (1 - np.power(cache['a3'], 2))\n",
    "        dW3 = np.dot(dz3, cache['a2'].T)\n",
    "        db3 = np.sum(dz3, axis=1, keepdims = True)\n",
    "        dz2 = np.dot(cache['W3'].T, dz3) * (1 - np.power(cache['a2'], 2))\n",
    "        dW2 = np.dot(dz2, cache['a1'].T)\n",
    "        db2 = np.sum(dz2, axis=1, keepdims = True)\n",
    "        dz1 = np.dot(cache['W2'].T, dz2) * (1 - np.power(cache['a1'], 2))\n",
    "        dW1 = np.dot(dz1, X.T)\n",
    "        db1 = np.sum(dz1, axis=1, keepdims = True)\n",
    "    \n",
    "    gradients = {\"dz6\": dz6, \"dW6\": dW6, \"db6\": db6,\n",
    "                 \"dz5\": dz5, \"dW5\": dW5, \"db5\": db5,\n",
    "                 \"dz4\": dz4, \"dW4\": dW4, \"db4\": db4,\n",
    "                 \"dz3\": dz3, \"dW3\": dW3, \"db3\": db3,\n",
    "                 \"dz2\": dz2, \"dW2\": dW2, \"db2\": db2,\n",
    "                 \"dz1\": dz1, \"dW1\": dW1, \"db1\": db1}\n",
    "    \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, layers_dims, optimizer, learning_rate = 0.0007, beta = 0.9, lambd = 0,\n",
    "          beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    X -- input data, of shape (2, number of examples)\n",
    "    Y -- true \"label\" vector (1 for blue dot / 0 for red dot), of shape (1, number of examples)\n",
    "    layers_dims -- python list, containing the size of each layer\n",
    "    learning_rate -- the learning rate, scalar.\n",
    "    mini_batch_size -- the size of a mini batch\n",
    "    beta -- Momentum hyperparameter\n",
    "    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n",
    "    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n",
    "    epsilon -- hyperparameter preventing division by zero in Adam updates\n",
    "    num_epochs -- number of epochs\n",
    "    print_cost -- True to print the cost every 1000 epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "\n",
    "    L = len(layers_dims)             # number of layers in the neural networks\n",
    "    costs = []                       # to keep track of the cost\n",
    "    t = 0                            # initializing the counter required for Adam update\n",
    "    seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "    m = X.shape[1]                   # number of training examples\n",
    "    \n",
    "    # Initialize parameters\n",
    "    parameters = tu.initialize_parameters(layers_dims)\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    if optimizer == \"gd\":\n",
    "        pass # no initialization required for gradient descent\n",
    "    elif optimizer == \"momentum\":\n",
    "        v = tu.initialize_velocity(parameters)\n",
    "    elif optimizer == \"adam\":\n",
    "        v, s = tu.initialize_adam(parameters)\n",
    "    \n",
    "    # Optimization loop\n",
    "    for i in range(num_epochs):\n",
    "\n",
    "        # Forward propagation and back prop\n",
    "        if lambd > 0:\n",
    "            cost, cache = tu.forward_propagation(X, Y, parameters, lambd)\n",
    "            grads = backward_propagation(X, Y, cache, lambd)\n",
    "        else:\n",
    "            cost, cache = tu.forward_propagation(X, Y, parameters)\n",
    "            grads = backward_propagation(X, Y, cache)\n",
    "\n",
    "        # Update parameters\n",
    "        if optimizer == \"gd\":\n",
    "            parameters = tu.update_parameters_with_gd(parameters, grads, learning_rate)\n",
    "        elif optimizer == \"momentum\":\n",
    "            parameters, v = tu.update_parameters_with_momentum(parameters, grads, v, beta, learning_rate)\n",
    "        elif optimizer == \"adam\":\n",
    "            t = t + 1 # Adam counter\n",
    "            parameters, v, s = tu.update_parameters_with_adam(parameters, grads, v, s,\n",
    "                                                               t, learning_rate, beta1, beta2,  epsilon)\n",
    "\n",
    "        # Print the cost every 1000 epoch\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('epochs (per 100)')\n",
    "    plt.title(\"Learning rate = \" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26281864019752443 0.09199904522700109 -1.3076660128732143 0.21287768171914198\n"
     ]
    }
   ],
   "source": [
    "X_assess, Y, parameters = tu.forward_propagation_test_case()\n",
    "_, cache = tu.forward_propagation(X_assess, Y, parameters)\n",
    "\n",
    "# Note: we use the mean here just to make sure that your output matches ours. \n",
    "print(np.mean(cache['z1']) ,np.mean(cache['a1']),np.mean(cache['z2']),np.mean(cache['a2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "<table style=\"width:50%\">\n",
    "  <tr>\n",
    "    <td> 0.262818640198 0.091999045227 -1.30766601287 0.212877681719 </td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost = 1.7864859451590758\n"
     ]
    }
   ],
   "source": [
    "A3, Y_assess, parameters = tu.compute_cost_with_regularization_test_case()\n",
    "\n",
    "print(\"cost = \" + str(tu.compute_cost_with_regularization(A3, Y_assess, parameters, lambd = 0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table> \n",
    "    <tr>\n",
    "    <td>\n",
    "    **cost**\n",
    "    </td>\n",
    "        <td>\n",
    "    1.78648594516\n",
    "    </td>\n",
    "    </tr>\n",
    "\n",
    "</table> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mYour backward propagation works perfectly fine! difference = 9.087246885374722e-09\u001b[0m\n",
      "\u001b[92mYour backward propagation works perfectly fine! difference = 1.702494951670733e-07\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "X, Y, parameters = tu.gradient_check_test_case()\n",
    "cost, cache = tu.forward_propagation(X, Y, parameters)\n",
    "gradients = backward_propagation(X, Y, cache)\n",
    "difference = tu.gradient_check(parameters, gradients, X, Y)\n",
    "lambd = 0.7\n",
    "gradients = backward_propagation(X, Y, cache, lambd = lambd)\n",
    "difference = tu.gradient_check(parameters, gradients, X, Y, lambd = lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 846\n",
      "Number of testing examples: m_test = 45\n",
      "train_set_x shape: (16, 846)\n",
      "train_set_y shape: (1, 846)\n",
      "test_set_x shape: (16, 45)\n",
      "test_set_y shape: (1, 45)\n",
      "Cost after epoch 0: 0.719571\n",
      "Cost after epoch 1000: 0.372266\n",
      "Cost after epoch 2000: 0.331047\n",
      "Cost after epoch 3000: 0.325620\n",
      "Cost after epoch 4000: 0.325084\n",
      "Cost after epoch 5000: 0.324684\n",
      "Cost after epoch 6000: 0.324379\n",
      "Cost after epoch 7000: 0.324111\n",
      "Cost after epoch 8000: 0.358893\n",
      "Cost after epoch 9000: 0.353656\n",
      "Cost after epoch 10000: 0.346708\n",
      "Cost after epoch 11000: 0.342531\n",
      "Cost after epoch 12000: 0.341107\n",
      "Cost after epoch 13000: 0.337218\n",
      "Cost after epoch 14000: 0.336351\n",
      "Cost after epoch 15000: 0.336159\n",
      "Cost after epoch 16000: 0.335696\n",
      "Cost after epoch 17000: 0.335477\n",
      "Cost after epoch 18000: 0.337629\n",
      "Cost after epoch 19000: 0.336724\n",
      "Cost after epoch 20000: 0.336526\n",
      "Cost after epoch 21000: 0.344810\n",
      "Cost after epoch 22000: 0.327293\n",
      "Cost after epoch 23000: 0.326643\n",
      "Cost after epoch 24000: 0.337451\n",
      "Cost after epoch 25000: 0.336463\n",
      "Cost after epoch 26000: 0.330545\n",
      "Cost after epoch 27000: 0.331237\n",
      "Cost after epoch 28000: 0.332064\n",
      "Cost after epoch 29000: 0.332249\n",
      "Cost after epoch 30000: 0.331670\n",
      "Cost after epoch 31000: 0.334241\n",
      "Cost after epoch 32000: 0.332048\n",
      "Cost after epoch 33000: 0.303661\n",
      "Cost after epoch 34000: 0.191672\n",
      "Cost after epoch 35000: 0.151058\n",
      "Cost after epoch 36000: 0.123796\n",
      "Cost after epoch 37000: 0.108466\n",
      "Cost after epoch 38000: 0.099027\n",
      "Cost after epoch 39000: 0.093764\n",
      "Cost after epoch 40000: 0.088518\n",
      "Cost after epoch 41000: 0.084132\n",
      "Cost after epoch 42000: 0.081637\n",
      "Cost after epoch 43000: 0.079523\n",
      "Cost after epoch 44000: 0.078700\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975177304964539\n",
      "Accuracy: 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y, dev_X, dev_Y = data_train()\n",
    "\n",
    "X = train_X\n",
    "Y = train_Y\n",
    "layers_dims = [train_X.shape[0], 32, 16, 8, 4, 2, 1]\n",
    "optimizer = \"adam\"\n",
    "learning_rate = 0.0007\n",
    "beta = 0.9\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon = 1e-8\n",
    "num_epochs = 45000\n",
    "print_cost = True\n",
    "lambd = .07\n",
    "\n",
    "parameters = model(X, Y, layers_dims, optimizer = optimizer, learning_rate = learning_rate, num_epochs = num_epochs, \n",
    "                   lambd = lambd, beta = beta, beta1 = beta1, beta2 = beta2, epsilon = epsilon, print_cost = print_cost)\n",
    "\n",
    "# Predict\n",
    "predictions = tu.predict(train_X, train_Y, parameters)\n",
    "predictions1 = tu.predict(dev_X, dev_Y, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "test_X = data_test()\n",
    "results = tu.predict_t(test_X, parameters)\n",
    "results = results.T\n",
    "predictions = results.tolist()\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output['Survived'] = output['Survived'].str.get(0)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
