{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import IPython\n",
    "\n",
    "!pip install -q -U keras-tuner\n",
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "  \n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 32)\n",
    "  model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer \n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values = [1e-2, 1e-3, 1e-4]) \n",
    "  \n",
    "  model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n",
    "                loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective = 'val_accuracy', \n",
    "                     max_epochs = 10,\n",
    "                     factor = 3,\n",
    "                     directory = 'my_dir',\n",
    "                     project_name = 'intro_to_kt')                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClearTrainingOutput(tf.keras.callbacks.Callback):\n",
    "  def on_train_end(*args, **kwargs):\n",
    "    IPython.display.clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial complete</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#4527A0\"><h1 style=\"font-size:18px\">Trial summary</h1></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Trial ID: b63e388b7f39ac996187dc088cc932fd</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Score: 0.8711000084877014</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-Best step: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:#7E57C2\"><h2 style=\"font-size:16px\">Hyperparameters:</h2></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-learning_rate: 0.0001</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/bracket: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/epochs: 10</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-tuner/initial_epoch: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:cyan\"> |-tuner/round: 0</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue\"> |-units: 256</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 128 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs = 10, validation_data = (img_test, label_test), callbacks = [ClearTrainingOutput()])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - ETA: 7:03 - loss: 2.5678 - accuracy: 0.06 - ETA: 13s - loss: 1.2963 - accuracy: 0.5861 - ETA: 7s - loss: 1.0207 - accuracy: 0.654 - ETA: 5s - loss: 0.9069 - accuracy: 0.68 - ETA: 4s - loss: 0.8518 - accuracy: 0.70 - ETA: 4s - loss: 0.8100 - accuracy: 0.72 - ETA: 3s - loss: 0.7687 - accuracy: 0.73 - ETA: 3s - loss: 0.7493 - accuracy: 0.73 - ETA: 3s - loss: 0.7243 - accuracy: 0.74 - ETA: 2s - loss: 0.7056 - accuracy: 0.75 - ETA: 2s - loss: 0.6908 - accuracy: 0.75 - ETA: 2s - loss: 0.6737 - accuracy: 0.76 - ETA: 2s - loss: 0.6595 - accuracy: 0.77 - ETA: 2s - loss: 0.6494 - accuracy: 0.77 - ETA: 2s - loss: 0.6388 - accuracy: 0.77 - ETA: 2s - loss: 0.6323 - accuracy: 0.78 - ETA: 2s - loss: 0.6253 - accuracy: 0.78 - ETA: 1s - loss: 0.6158 - accuracy: 0.78 - ETA: 1s - loss: 0.6077 - accuracy: 0.78 - ETA: 1s - loss: 0.6051 - accuracy: 0.79 - ETA: 1s - loss: 0.5991 - accuracy: 0.79 - ETA: 1s - loss: 0.5919 - accuracy: 0.79 - ETA: 1s - loss: 0.5847 - accuracy: 0.79 - ETA: 1s - loss: 0.5789 - accuracy: 0.79 - ETA: 1s - loss: 0.5739 - accuracy: 0.80 - ETA: 1s - loss: 0.5700 - accuracy: 0.80 - ETA: 1s - loss: 0.5646 - accuracy: 0.80 - ETA: 1s - loss: 0.5612 - accuracy: 0.80 - ETA: 1s - loss: 0.5586 - accuracy: 0.80 - ETA: 1s - loss: 0.5560 - accuracy: 0.80 - ETA: 1s - loss: 0.5508 - accuracy: 0.80 - ETA: 0s - loss: 0.5473 - accuracy: 0.80 - ETA: 0s - loss: 0.5446 - accuracy: 0.81 - ETA: 0s - loss: 0.5416 - accuracy: 0.81 - ETA: 0s - loss: 0.5388 - accuracy: 0.81 - ETA: 0s - loss: 0.5363 - accuracy: 0.81 - ETA: 0s - loss: 0.5334 - accuracy: 0.81 - ETA: 0s - loss: 0.5306 - accuracy: 0.81 - ETA: 0s - loss: 0.5283 - accuracy: 0.81 - ETA: 0s - loss: 0.5246 - accuracy: 0.81 - ETA: 0s - loss: 0.5222 - accuracy: 0.81 - ETA: 0s - loss: 0.5202 - accuracy: 0.81 - ETA: 0s - loss: 0.5184 - accuracy: 0.81 - ETA: 0s - loss: 0.5158 - accuracy: 0.81 - ETA: 0s - loss: 0.5132 - accuracy: 0.82 - ETA: 0s - loss: 0.5104 - accuracy: 0.82 - ETA: 0s - loss: 0.5073 - accuracy: 0.82 - ETA: 0s - loss: 0.5048 - accuracy: 0.82 - 3s 52us/sample - loss: 0.5046 - accuracy: 0.8234 - val_loss: 0.4375 - val_accuracy: 0.8386\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - ETA: 5s - loss: 0.4019 - accuracy: 0.81 - ETA: 2s - loss: 0.3618 - accuracy: 0.86 - ETA: 2s - loss: 0.3797 - accuracy: 0.86 - ETA: 2s - loss: 0.3831 - accuracy: 0.86 - ETA: 2s - loss: 0.3890 - accuracy: 0.86 - ETA: 2s - loss: 0.3924 - accuracy: 0.86 - ETA: 2s - loss: 0.3910 - accuracy: 0.86 - ETA: 2s - loss: 0.3939 - accuracy: 0.86 - ETA: 2s - loss: 0.3927 - accuracy: 0.86 - ETA: 2s - loss: 0.3929 - accuracy: 0.86 - ETA: 2s - loss: 0.3899 - accuracy: 0.86 - ETA: 2s - loss: 0.3898 - accuracy: 0.86 - ETA: 2s - loss: 0.3872 - accuracy: 0.86 - ETA: 1s - loss: 0.3864 - accuracy: 0.86 - ETA: 1s - loss: 0.3854 - accuracy: 0.86 - ETA: 1s - loss: 0.3860 - accuracy: 0.86 - ETA: 1s - loss: 0.3875 - accuracy: 0.86 - ETA: 1s - loss: 0.3851 - accuracy: 0.86 - ETA: 1s - loss: 0.3847 - accuracy: 0.86 - ETA: 1s - loss: 0.3841 - accuracy: 0.86 - ETA: 1s - loss: 0.3854 - accuracy: 0.86 - ETA: 1s - loss: 0.3858 - accuracy: 0.86 - ETA: 1s - loss: 0.3842 - accuracy: 0.86 - ETA: 1s - loss: 0.3858 - accuracy: 0.86 - ETA: 1s - loss: 0.3857 - accuracy: 0.86 - ETA: 1s - loss: 0.3852 - accuracy: 0.86 - ETA: 1s - loss: 0.3858 - accuracy: 0.86 - ETA: 1s - loss: 0.3864 - accuracy: 0.86 - ETA: 1s - loss: 0.3859 - accuracy: 0.86 - ETA: 1s - loss: 0.3857 - accuracy: 0.86 - ETA: 1s - loss: 0.3846 - accuracy: 0.86 - ETA: 1s - loss: 0.3833 - accuracy: 0.86 - ETA: 0s - loss: 0.3831 - accuracy: 0.86 - ETA: 0s - loss: 0.3825 - accuracy: 0.86 - ETA: 0s - loss: 0.3812 - accuracy: 0.86 - ETA: 0s - loss: 0.3802 - accuracy: 0.86 - ETA: 0s - loss: 0.3794 - accuracy: 0.86 - ETA: 0s - loss: 0.3797 - accuracy: 0.86 - ETA: 0s - loss: 0.3799 - accuracy: 0.86 - ETA: 0s - loss: 0.3791 - accuracy: 0.86 - ETA: 0s - loss: 0.3787 - accuracy: 0.86 - ETA: 0s - loss: 0.3776 - accuracy: 0.86 - ETA: 0s - loss: 0.3781 - accuracy: 0.86 - ETA: 0s - loss: 0.3785 - accuracy: 0.86 - ETA: 0s - loss: 0.3789 - accuracy: 0.86 - ETA: 0s - loss: 0.3793 - accuracy: 0.86 - ETA: 0s - loss: 0.3788 - accuracy: 0.86 - ETA: 0s - loss: 0.3779 - accuracy: 0.86 - ETA: 0s - loss: 0.3776 - accuracy: 0.86 - ETA: 0s - loss: 0.3775 - accuracy: 0.86 - ETA: 0s - loss: 0.3775 - accuracy: 0.86 - ETA: 0s - loss: 0.3768 - accuracy: 0.86 - ETA: 0s - loss: 0.3760 - accuracy: 0.86 - ETA: 0s - loss: 0.3747 - accuracy: 0.86 - ETA: 0s - loss: 0.3746 - accuracy: 0.86 - 3s 56us/sample - loss: 0.3744 - accuracy: 0.8658 - val_loss: 0.3737 - val_accuracy: 0.8673\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - ETA: 3s - loss: 0.2914 - accuracy: 0.90 - ETA: 3s - loss: 0.3111 - accuracy: 0.89 - ETA: 3s - loss: 0.3333 - accuracy: 0.88 - ETA: 3s - loss: 0.3420 - accuracy: 0.87 - ETA: 3s - loss: 0.3477 - accuracy: 0.87 - ETA: 3s - loss: 0.3369 - accuracy: 0.87 - ETA: 3s - loss: 0.3451 - accuracy: 0.87 - ETA: 3s - loss: 0.3448 - accuracy: 0.87 - ETA: 3s - loss: 0.3399 - accuracy: 0.87 - ETA: 3s - loss: 0.3431 - accuracy: 0.87 - ETA: 2s - loss: 0.3469 - accuracy: 0.87 - ETA: 2s - loss: 0.3464 - accuracy: 0.87 - ETA: 2s - loss: 0.3448 - accuracy: 0.87 - ETA: 2s - loss: 0.3428 - accuracy: 0.87 - ETA: 2s - loss: 0.3413 - accuracy: 0.87 - ETA: 2s - loss: 0.3404 - accuracy: 0.87 - ETA: 2s - loss: 0.3434 - accuracy: 0.87 - ETA: 2s - loss: 0.3451 - accuracy: 0.87 - ETA: 2s - loss: 0.3443 - accuracy: 0.87 - ETA: 2s - loss: 0.3435 - accuracy: 0.87 - ETA: 2s - loss: 0.3424 - accuracy: 0.87 - ETA: 2s - loss: 0.3401 - accuracy: 0.87 - ETA: 2s - loss: 0.3387 - accuracy: 0.87 - ETA: 2s - loss: 0.3371 - accuracy: 0.87 - ETA: 2s - loss: 0.3384 - accuracy: 0.87 - ETA: 2s - loss: 0.3370 - accuracy: 0.87 - ETA: 2s - loss: 0.3364 - accuracy: 0.87 - ETA: 1s - loss: 0.3360 - accuracy: 0.87 - ETA: 1s - loss: 0.3360 - accuracy: 0.87 - ETA: 1s - loss: 0.3353 - accuracy: 0.87 - ETA: 1s - loss: 0.3371 - accuracy: 0.87 - ETA: 1s - loss: 0.3373 - accuracy: 0.87 - ETA: 1s - loss: 0.3376 - accuracy: 0.87 - ETA: 1s - loss: 0.3391 - accuracy: 0.87 - ETA: 1s - loss: 0.3393 - accuracy: 0.87 - ETA: 1s - loss: 0.3401 - accuracy: 0.87 - ETA: 1s - loss: 0.3392 - accuracy: 0.87 - ETA: 1s - loss: 0.3385 - accuracy: 0.87 - ETA: 1s - loss: 0.3387 - accuracy: 0.87 - ETA: 1s - loss: 0.3385 - accuracy: 0.87 - ETA: 1s - loss: 0.3377 - accuracy: 0.87 - ETA: 1s - loss: 0.3385 - accuracy: 0.87 - ETA: 1s - loss: 0.3383 - accuracy: 0.87 - ETA: 1s - loss: 0.3380 - accuracy: 0.87 - ETA: 1s - loss: 0.3380 - accuracy: 0.87 - ETA: 1s - loss: 0.3378 - accuracy: 0.87 - ETA: 1s - loss: 0.3376 - accuracy: 0.87 - ETA: 0s - loss: 0.3389 - accuracy: 0.87 - ETA: 0s - loss: 0.3386 - accuracy: 0.87 - ETA: 0s - loss: 0.3390 - accuracy: 0.87 - ETA: 0s - loss: 0.3391 - accuracy: 0.87 - ETA: 0s - loss: 0.3383 - accuracy: 0.87 - ETA: 0s - loss: 0.3383 - accuracy: 0.87 - ETA: 0s - loss: 0.3381 - accuracy: 0.87 - ETA: 0s - loss: 0.3380 - accuracy: 0.87 - ETA: 0s - loss: 0.3378 - accuracy: 0.87 - ETA: 0s - loss: 0.3376 - accuracy: 0.87 - ETA: 0s - loss: 0.3377 - accuracy: 0.87 - ETA: 0s - loss: 0.3383 - accuracy: 0.87 - ETA: 0s - loss: 0.3377 - accuracy: 0.87 - ETA: 0s - loss: 0.3375 - accuracy: 0.87 - ETA: 0s - loss: 0.3371 - accuracy: 0.87 - ETA: 0s - loss: 0.3367 - accuracy: 0.87 - ETA: 0s - loss: 0.3361 - accuracy: 0.87 - ETA: 0s - loss: 0.3364 - accuracy: 0.87 - ETA: 0s - loss: 0.3360 - accuracy: 0.87 - ETA: 0s - loss: 0.3352 - accuracy: 0.87 - 4s 67us/sample - loss: 0.3358 - accuracy: 0.8773 - val_loss: 0.4035 - val_accuracy: 0.8524\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 3s - loss: 0.2339 - accuracy: 0.90 - ETA: 3s - loss: 0.3204 - accuracy: 0.87 - ETA: 3s - loss: 0.3189 - accuracy: 0.88 - ETA: 3s - loss: 0.3219 - accuracy: 0.88 - ETA: 3s - loss: 0.3252 - accuracy: 0.88 - ETA: 3s - loss: 0.3190 - accuracy: 0.88 - ETA: 3s - loss: 0.3187 - accuracy: 0.88 - ETA: 3s - loss: 0.3139 - accuracy: 0.88 - ETA: 3s - loss: 0.3052 - accuracy: 0.88 - ETA: 2s - loss: 0.3082 - accuracy: 0.88 - ETA: 2s - loss: 0.3089 - accuracy: 0.88 - ETA: 2s - loss: 0.3090 - accuracy: 0.88 - ETA: 2s - loss: 0.3079 - accuracy: 0.88 - ETA: 2s - loss: 0.3064 - accuracy: 0.88 - ETA: 2s - loss: 0.3075 - accuracy: 0.88 - ETA: 2s - loss: 0.3077 - accuracy: 0.88 - ETA: 2s - loss: 0.3086 - accuracy: 0.88 - ETA: 2s - loss: 0.3106 - accuracy: 0.88 - ETA: 2s - loss: 0.3108 - accuracy: 0.88 - ETA: 2s - loss: 0.3091 - accuracy: 0.88 - ETA: 2s - loss: 0.3109 - accuracy: 0.88 - ETA: 2s - loss: 0.3116 - accuracy: 0.88 - ETA: 2s - loss: 0.3128 - accuracy: 0.88 - ETA: 2s - loss: 0.3128 - accuracy: 0.88 - ETA: 2s - loss: 0.3129 - accuracy: 0.88 - ETA: 1s - loss: 0.3131 - accuracy: 0.88 - ETA: 1s - loss: 0.3123 - accuracy: 0.88 - ETA: 1s - loss: 0.3125 - accuracy: 0.88 - ETA: 1s - loss: 0.3118 - accuracy: 0.88 - ETA: 1s - loss: 0.3121 - accuracy: 0.88 - ETA: 1s - loss: 0.3130 - accuracy: 0.88 - ETA: 1s - loss: 0.3134 - accuracy: 0.88 - ETA: 1s - loss: 0.3134 - accuracy: 0.88 - ETA: 1s - loss: 0.3126 - accuracy: 0.88 - ETA: 1s - loss: 0.3129 - accuracy: 0.88 - ETA: 1s - loss: 0.3133 - accuracy: 0.88 - ETA: 1s - loss: 0.3129 - accuracy: 0.88 - ETA: 1s - loss: 0.3136 - accuracy: 0.88 - ETA: 1s - loss: 0.3124 - accuracy: 0.88 - ETA: 1s - loss: 0.3114 - accuracy: 0.88 - ETA: 1s - loss: 0.3105 - accuracy: 0.88 - ETA: 1s - loss: 0.3112 - accuracy: 0.88 - ETA: 1s - loss: 0.3116 - accuracy: 0.88 - ETA: 1s - loss: 0.3114 - accuracy: 0.88 - ETA: 1s - loss: 0.3111 - accuracy: 0.88 - ETA: 0s - loss: 0.3114 - accuracy: 0.88 - ETA: 0s - loss: 0.3111 - accuracy: 0.88 - ETA: 0s - loss: 0.3108 - accuracy: 0.88 - ETA: 0s - loss: 0.3108 - accuracy: 0.88 - ETA: 0s - loss: 0.3105 - accuracy: 0.88 - ETA: 0s - loss: 0.3114 - accuracy: 0.88 - ETA: 0s - loss: 0.3109 - accuracy: 0.88 - ETA: 0s - loss: 0.3110 - accuracy: 0.88 - ETA: 0s - loss: 0.3111 - accuracy: 0.88 - ETA: 0s - loss: 0.3103 - accuracy: 0.88 - ETA: 0s - loss: 0.3104 - accuracy: 0.88 - ETA: 0s - loss: 0.3106 - accuracy: 0.88 - ETA: 0s - loss: 0.3107 - accuracy: 0.88 - ETA: 0s - loss: 0.3105 - accuracy: 0.88 - ETA: 0s - loss: 0.3107 - accuracy: 0.88 - ETA: 0s - loss: 0.3106 - accuracy: 0.88 - ETA: 0s - loss: 0.3109 - accuracy: 0.88 - ETA: 0s - loss: 0.3111 - accuracy: 0.88 - 4s 61us/sample - loss: 0.3114 - accuracy: 0.8858 - val_loss: 0.3539 - val_accuracy: 0.8711\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - ETA: 5s - loss: 0.4906 - accuracy: 0.81 - ETA: 3s - loss: 0.3115 - accuracy: 0.89 - ETA: 3s - loss: 0.2843 - accuracy: 0.89 - ETA: 2s - loss: 0.3001 - accuracy: 0.89 - ETA: 2s - loss: 0.3019 - accuracy: 0.89 - ETA: 2s - loss: 0.2987 - accuracy: 0.89 - ETA: 2s - loss: 0.2977 - accuracy: 0.89 - ETA: 2s - loss: 0.2958 - accuracy: 0.89 - ETA: 2s - loss: 0.2923 - accuracy: 0.89 - ETA: 2s - loss: 0.2905 - accuracy: 0.89 - ETA: 2s - loss: 0.2925 - accuracy: 0.89 - ETA: 2s - loss: 0.2920 - accuracy: 0.89 - ETA: 2s - loss: 0.2922 - accuracy: 0.89 - ETA: 2s - loss: 0.2934 - accuracy: 0.89 - ETA: 2s - loss: 0.2941 - accuracy: 0.89 - ETA: 2s - loss: 0.2959 - accuracy: 0.89 - ETA: 2s - loss: 0.2940 - accuracy: 0.89 - ETA: 2s - loss: 0.2937 - accuracy: 0.89 - ETA: 2s - loss: 0.2922 - accuracy: 0.89 - ETA: 2s - loss: 0.2904 - accuracy: 0.89 - ETA: 2s - loss: 0.2881 - accuracy: 0.89 - ETA: 2s - loss: 0.2883 - accuracy: 0.89 - ETA: 2s - loss: 0.2874 - accuracy: 0.89 - ETA: 1s - loss: 0.2877 - accuracy: 0.89 - ETA: 1s - loss: 0.2886 - accuracy: 0.89 - ETA: 1s - loss: 0.2893 - accuracy: 0.89 - ETA: 1s - loss: 0.2900 - accuracy: 0.89 - ETA: 1s - loss: 0.2906 - accuracy: 0.89 - ETA: 1s - loss: 0.2901 - accuracy: 0.89 - ETA: 1s - loss: 0.2902 - accuracy: 0.89 - ETA: 1s - loss: 0.2901 - accuracy: 0.89 - ETA: 1s - loss: 0.2892 - accuracy: 0.89 - ETA: 1s - loss: 0.2917 - accuracy: 0.89 - ETA: 1s - loss: 0.2926 - accuracy: 0.89 - ETA: 1s - loss: 0.2928 - accuracy: 0.89 - ETA: 1s - loss: 0.2928 - accuracy: 0.89 - ETA: 1s - loss: 0.2929 - accuracy: 0.89 - ETA: 1s - loss: 0.2933 - accuracy: 0.89 - ETA: 1s - loss: 0.2938 - accuracy: 0.89 - ETA: 1s - loss: 0.2943 - accuracy: 0.89 - ETA: 1s - loss: 0.2935 - accuracy: 0.89 - ETA: 0s - loss: 0.2936 - accuracy: 0.89 - ETA: 0s - loss: 0.2934 - accuracy: 0.89 - ETA: 0s - loss: 0.2938 - accuracy: 0.89 - ETA: 0s - loss: 0.2936 - accuracy: 0.89 - ETA: 0s - loss: 0.2941 - accuracy: 0.89 - ETA: 0s - loss: 0.2933 - accuracy: 0.89 - ETA: 0s - loss: 0.2931 - accuracy: 0.89 - ETA: 0s - loss: 0.2920 - accuracy: 0.89 - ETA: 0s - loss: 0.2927 - accuracy: 0.89 - ETA: 0s - loss: 0.2924 - accuracy: 0.89 - ETA: 0s - loss: 0.2922 - accuracy: 0.89 - ETA: 0s - loss: 0.2923 - accuracy: 0.89 - ETA: 0s - loss: 0.2923 - accuracy: 0.89 - ETA: 0s - loss: 0.2934 - accuracy: 0.89 - ETA: 0s - loss: 0.2935 - accuracy: 0.89 - ETA: 0s - loss: 0.2942 - accuracy: 0.89 - ETA: 0s - loss: 0.2946 - accuracy: 0.89 - ETA: 0s - loss: 0.2940 - accuracy: 0.89 - ETA: 0s - loss: 0.2950 - accuracy: 0.89 - 3s 58us/sample - loss: 0.2950 - accuracy: 0.8923 - val_loss: 0.3511 - val_accuracy: 0.8732\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - ETA: 5s - loss: 0.2101 - accuracy: 0.93 - ETA: 2s - loss: 0.2555 - accuracy: 0.90 - ETA: 2s - loss: 0.2662 - accuracy: 0.90 - ETA: 2s - loss: 0.2710 - accuracy: 0.89 - ETA: 2s - loss: 0.2634 - accuracy: 0.90 - ETA: 2s - loss: 0.2668 - accuracy: 0.90 - ETA: 2s - loss: 0.2704 - accuracy: 0.90 - ETA: 2s - loss: 0.2697 - accuracy: 0.90 - ETA: 2s - loss: 0.2695 - accuracy: 0.90 - ETA: 2s - loss: 0.2745 - accuracy: 0.89 - ETA: 2s - loss: 0.2746 - accuracy: 0.90 - ETA: 2s - loss: 0.2764 - accuracy: 0.90 - ETA: 2s - loss: 0.2742 - accuracy: 0.90 - ETA: 2s - loss: 0.2756 - accuracy: 0.90 - ETA: 2s - loss: 0.2783 - accuracy: 0.89 - ETA: 2s - loss: 0.2801 - accuracy: 0.89 - ETA: 2s - loss: 0.2800 - accuracy: 0.90 - ETA: 1s - loss: 0.2796 - accuracy: 0.89 - ETA: 1s - loss: 0.2786 - accuracy: 0.90 - ETA: 1s - loss: 0.2774 - accuracy: 0.90 - ETA: 1s - loss: 0.2766 - accuracy: 0.90 - ETA: 1s - loss: 0.2774 - accuracy: 0.90 - ETA: 1s - loss: 0.2771 - accuracy: 0.90 - ETA: 1s - loss: 0.2786 - accuracy: 0.90 - ETA: 1s - loss: 0.2791 - accuracy: 0.90 - ETA: 1s - loss: 0.2789 - accuracy: 0.89 - ETA: 1s - loss: 0.2786 - accuracy: 0.89 - ETA: 1s - loss: 0.2777 - accuracy: 0.89 - ETA: 1s - loss: 0.2780 - accuracy: 0.89 - ETA: 1s - loss: 0.2776 - accuracy: 0.89 - ETA: 1s - loss: 0.2771 - accuracy: 0.90 - ETA: 1s - loss: 0.2765 - accuracy: 0.90 - ETA: 1s - loss: 0.2765 - accuracy: 0.90 - ETA: 1s - loss: 0.2770 - accuracy: 0.89 - ETA: 1s - loss: 0.2776 - accuracy: 0.90 - ETA: 1s - loss: 0.2778 - accuracy: 0.90 - ETA: 1s - loss: 0.2784 - accuracy: 0.89 - ETA: 0s - loss: 0.2794 - accuracy: 0.89 - ETA: 0s - loss: 0.2798 - accuracy: 0.89 - ETA: 0s - loss: 0.2807 - accuracy: 0.89 - ETA: 0s - loss: 0.2802 - accuracy: 0.89 - ETA: 0s - loss: 0.2802 - accuracy: 0.89 - ETA: 0s - loss: 0.2803 - accuracy: 0.89 - ETA: 0s - loss: 0.2806 - accuracy: 0.89 - ETA: 0s - loss: 0.2806 - accuracy: 0.89 - ETA: 0s - loss: 0.2804 - accuracy: 0.89 - ETA: 0s - loss: 0.2808 - accuracy: 0.89 - ETA: 0s - loss: 0.2803 - accuracy: 0.89 - ETA: 0s - loss: 0.2803 - accuracy: 0.89 - ETA: 0s - loss: 0.2802 - accuracy: 0.89 - ETA: 0s - loss: 0.2801 - accuracy: 0.89 - ETA: 0s - loss: 0.2802 - accuracy: 0.89 - ETA: 0s - loss: 0.2800 - accuracy: 0.89 - ETA: 0s - loss: 0.2799 - accuracy: 0.89 - 3s 53us/sample - loss: 0.2799 - accuracy: 0.8976 - val_loss: 0.3394 - val_accuracy: 0.8788\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 5s - loss: 0.1880 - accuracy: 0.93 - ETA: 2s - loss: 0.2815 - accuracy: 0.89 - ETA: 2s - loss: 0.2509 - accuracy: 0.90 - ETA: 2s - loss: 0.2434 - accuracy: 0.90 - ETA: 2s - loss: 0.2607 - accuracy: 0.90 - ETA: 2s - loss: 0.2542 - accuracy: 0.90 - ETA: 2s - loss: 0.2537 - accuracy: 0.90 - ETA: 2s - loss: 0.2595 - accuracy: 0.90 - ETA: 2s - loss: 0.2624 - accuracy: 0.90 - ETA: 2s - loss: 0.2621 - accuracy: 0.90 - ETA: 2s - loss: 0.2607 - accuracy: 0.90 - ETA: 2s - loss: 0.2610 - accuracy: 0.90 - ETA: 1s - loss: 0.2638 - accuracy: 0.90 - ETA: 1s - loss: 0.2629 - accuracy: 0.90 - ETA: 1s - loss: 0.2636 - accuracy: 0.90 - ETA: 1s - loss: 0.2633 - accuracy: 0.90 - ETA: 1s - loss: 0.2633 - accuracy: 0.90 - ETA: 1s - loss: 0.2640 - accuracy: 0.90 - ETA: 1s - loss: 0.2626 - accuracy: 0.90 - ETA: 1s - loss: 0.2638 - accuracy: 0.90 - ETA: 1s - loss: 0.2670 - accuracy: 0.90 - ETA: 1s - loss: 0.2674 - accuracy: 0.90 - ETA: 1s - loss: 0.2671 - accuracy: 0.90 - ETA: 1s - loss: 0.2668 - accuracy: 0.90 - ETA: 1s - loss: 0.2664 - accuracy: 0.90 - ETA: 1s - loss: 0.2649 - accuracy: 0.90 - ETA: 1s - loss: 0.2649 - accuracy: 0.90 - ETA: 1s - loss: 0.2652 - accuracy: 0.90 - ETA: 1s - loss: 0.2643 - accuracy: 0.90 - ETA: 1s - loss: 0.2643 - accuracy: 0.90 - ETA: 1s - loss: 0.2648 - accuracy: 0.90 - ETA: 1s - loss: 0.2658 - accuracy: 0.90 - ETA: 1s - loss: 0.2662 - accuracy: 0.90 - ETA: 0s - loss: 0.2664 - accuracy: 0.90 - ETA: 0s - loss: 0.2673 - accuracy: 0.90 - ETA: 0s - loss: 0.2672 - accuracy: 0.90 - ETA: 0s - loss: 0.2676 - accuracy: 0.90 - ETA: 0s - loss: 0.2683 - accuracy: 0.90 - ETA: 0s - loss: 0.2688 - accuracy: 0.90 - ETA: 0s - loss: 0.2685 - accuracy: 0.90 - ETA: 0s - loss: 0.2693 - accuracy: 0.90 - ETA: 0s - loss: 0.2691 - accuracy: 0.90 - ETA: 0s - loss: 0.2684 - accuracy: 0.90 - ETA: 0s - loss: 0.2684 - accuracy: 0.90 - ETA: 0s - loss: 0.2685 - accuracy: 0.90 - ETA: 0s - loss: 0.2687 - accuracy: 0.90 - ETA: 0s - loss: 0.2692 - accuracy: 0.90 - ETA: 0s - loss: 0.2694 - accuracy: 0.90 - ETA: 0s - loss: 0.2696 - accuracy: 0.90 - ETA: 0s - loss: 0.2696 - accuracy: 0.90 - ETA: 0s - loss: 0.2694 - accuracy: 0.90 - ETA: 0s - loss: 0.2694 - accuracy: 0.90 - 3s 50us/sample - loss: 0.2694 - accuracy: 0.9002 - val_loss: 0.3300 - val_accuracy: 0.8834\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - ETA: 5s - loss: 0.2588 - accuracy: 0.87 - ETA: 2s - loss: 0.2463 - accuracy: 0.91 - ETA: 2s - loss: 0.2541 - accuracy: 0.90 - ETA: 2s - loss: 0.2583 - accuracy: 0.90 - ETA: 2s - loss: 0.2547 - accuracy: 0.91 - ETA: 2s - loss: 0.2512 - accuracy: 0.91 - ETA: 2s - loss: 0.2504 - accuracy: 0.91 - ETA: 2s - loss: 0.2473 - accuracy: 0.91 - ETA: 2s - loss: 0.2394 - accuracy: 0.91 - ETA: 2s - loss: 0.2422 - accuracy: 0.91 - ETA: 2s - loss: 0.2429 - accuracy: 0.91 - ETA: 1s - loss: 0.2435 - accuracy: 0.91 - ETA: 1s - loss: 0.2430 - accuracy: 0.91 - ETA: 1s - loss: 0.2440 - accuracy: 0.91 - ETA: 1s - loss: 0.2436 - accuracy: 0.91 - ETA: 1s - loss: 0.2439 - accuracy: 0.91 - ETA: 1s - loss: 0.2448 - accuracy: 0.91 - ETA: 1s - loss: 0.2453 - accuracy: 0.91 - ETA: 1s - loss: 0.2465 - accuracy: 0.90 - ETA: 1s - loss: 0.2468 - accuracy: 0.90 - ETA: 1s - loss: 0.2481 - accuracy: 0.90 - ETA: 1s - loss: 0.2472 - accuracy: 0.90 - ETA: 1s - loss: 0.2474 - accuracy: 0.90 - ETA: 1s - loss: 0.2483 - accuracy: 0.90 - ETA: 1s - loss: 0.2491 - accuracy: 0.90 - ETA: 1s - loss: 0.2497 - accuracy: 0.90 - ETA: 1s - loss: 0.2510 - accuracy: 0.90 - ETA: 1s - loss: 0.2521 - accuracy: 0.90 - ETA: 1s - loss: 0.2528 - accuracy: 0.90 - ETA: 1s - loss: 0.2516 - accuracy: 0.90 - ETA: 1s - loss: 0.2518 - accuracy: 0.90 - ETA: 0s - loss: 0.2534 - accuracy: 0.90 - ETA: 0s - loss: 0.2539 - accuracy: 0.90 - ETA: 0s - loss: 0.2532 - accuracy: 0.90 - ETA: 0s - loss: 0.2534 - accuracy: 0.90 - ETA: 0s - loss: 0.2530 - accuracy: 0.90 - ETA: 0s - loss: 0.2525 - accuracy: 0.90 - ETA: 0s - loss: 0.2532 - accuracy: 0.90 - ETA: 0s - loss: 0.2536 - accuracy: 0.90 - ETA: 0s - loss: 0.2540 - accuracy: 0.90 - ETA: 0s - loss: 0.2545 - accuracy: 0.90 - ETA: 0s - loss: 0.2545 - accuracy: 0.90 - ETA: 0s - loss: 0.2549 - accuracy: 0.90 - ETA: 0s - loss: 0.2555 - accuracy: 0.90 - ETA: 0s - loss: 0.2554 - accuracy: 0.90 - ETA: 0s - loss: 0.2555 - accuracy: 0.90 - ETA: 0s - loss: 0.2551 - accuracy: 0.90 - ETA: 0s - loss: 0.2564 - accuracy: 0.90 - ETA: 0s - loss: 0.2568 - accuracy: 0.90 - ETA: 0s - loss: 0.2572 - accuracy: 0.90 - 3s 49us/sample - loss: 0.2575 - accuracy: 0.9045 - val_loss: 0.3261 - val_accuracy: 0.8847\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - ETA: 3s - loss: 0.2224 - accuracy: 0.90 - ETA: 2s - loss: 0.2377 - accuracy: 0.91 - ETA: 2s - loss: 0.2327 - accuracy: 0.91 - ETA: 2s - loss: 0.2279 - accuracy: 0.91 - ETA: 2s - loss: 0.2347 - accuracy: 0.91 - ETA: 2s - loss: 0.2348 - accuracy: 0.91 - ETA: 2s - loss: 0.2375 - accuracy: 0.91 - ETA: 2s - loss: 0.2413 - accuracy: 0.90 - ETA: 2s - loss: 0.2388 - accuracy: 0.91 - ETA: 2s - loss: 0.2379 - accuracy: 0.91 - ETA: 2s - loss: 0.2382 - accuracy: 0.91 - ETA: 2s - loss: 0.2382 - accuracy: 0.91 - ETA: 1s - loss: 0.2409 - accuracy: 0.91 - ETA: 1s - loss: 0.2433 - accuracy: 0.91 - ETA: 1s - loss: 0.2432 - accuracy: 0.91 - ETA: 1s - loss: 0.2428 - accuracy: 0.91 - ETA: 1s - loss: 0.2416 - accuracy: 0.91 - ETA: 1s - loss: 0.2420 - accuracy: 0.91 - ETA: 1s - loss: 0.2417 - accuracy: 0.91 - ETA: 1s - loss: 0.2411 - accuracy: 0.91 - ETA: 1s - loss: 0.2431 - accuracy: 0.91 - ETA: 1s - loss: 0.2437 - accuracy: 0.91 - ETA: 1s - loss: 0.2451 - accuracy: 0.91 - ETA: 1s - loss: 0.2449 - accuracy: 0.91 - ETA: 1s - loss: 0.2443 - accuracy: 0.90 - ETA: 1s - loss: 0.2452 - accuracy: 0.90 - ETA: 1s - loss: 0.2450 - accuracy: 0.90 - ETA: 1s - loss: 0.2453 - accuracy: 0.90 - ETA: 1s - loss: 0.2442 - accuracy: 0.90 - ETA: 1s - loss: 0.2435 - accuracy: 0.91 - ETA: 1s - loss: 0.2440 - accuracy: 0.91 - ETA: 1s - loss: 0.2441 - accuracy: 0.91 - ETA: 0s - loss: 0.2437 - accuracy: 0.91 - ETA: 0s - loss: 0.2439 - accuracy: 0.91 - ETA: 0s - loss: 0.2437 - accuracy: 0.91 - ETA: 0s - loss: 0.2437 - accuracy: 0.91 - ETA: 0s - loss: 0.2436 - accuracy: 0.91 - ETA: 0s - loss: 0.2433 - accuracy: 0.91 - ETA: 0s - loss: 0.2440 - accuracy: 0.91 - ETA: 0s - loss: 0.2448 - accuracy: 0.91 - ETA: 0s - loss: 0.2453 - accuracy: 0.90 - ETA: 0s - loss: 0.2462 - accuracy: 0.90 - ETA: 0s - loss: 0.2468 - accuracy: 0.90 - ETA: 0s - loss: 0.2475 - accuracy: 0.90 - ETA: 0s - loss: 0.2472 - accuracy: 0.90 - ETA: 0s - loss: 0.2473 - accuracy: 0.90 - ETA: 0s - loss: 0.2473 - accuracy: 0.90 - ETA: 0s - loss: 0.2473 - accuracy: 0.90 - ETA: 0s - loss: 0.2472 - accuracy: 0.90 - ETA: 0s - loss: 0.2475 - accuracy: 0.90 - ETA: 0s - loss: 0.2479 - accuracy: 0.90 - ETA: 0s - loss: 0.2473 - accuracy: 0.90 - 3s 50us/sample - loss: 0.2473 - accuracy: 0.9089 - val_loss: 0.3699 - val_accuracy: 0.8689\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - ETA: 5s - loss: 0.1865 - accuracy: 0.90 - ETA: 2s - loss: 0.2294 - accuracy: 0.91 - ETA: 2s - loss: 0.2301 - accuracy: 0.92 - ETA: 2s - loss: 0.2305 - accuracy: 0.91 - ETA: 2s - loss: 0.2370 - accuracy: 0.91 - ETA: 2s - loss: 0.2371 - accuracy: 0.91 - ETA: 2s - loss: 0.2367 - accuracy: 0.91 - ETA: 2s - loss: 0.2339 - accuracy: 0.91 - ETA: 2s - loss: 0.2345 - accuracy: 0.91 - ETA: 2s - loss: 0.2340 - accuracy: 0.91 - ETA: 2s - loss: 0.2335 - accuracy: 0.91 - ETA: 1s - loss: 0.2326 - accuracy: 0.91 - ETA: 1s - loss: 0.2277 - accuracy: 0.91 - ETA: 1s - loss: 0.2276 - accuracy: 0.91 - ETA: 1s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2305 - accuracy: 0.91 - ETA: 1s - loss: 0.2303 - accuracy: 0.91 - ETA: 1s - loss: 0.2305 - accuracy: 0.91 - ETA: 1s - loss: 0.2312 - accuracy: 0.91 - ETA: 1s - loss: 0.2333 - accuracy: 0.91 - ETA: 1s - loss: 0.2323 - accuracy: 0.91 - ETA: 1s - loss: 0.2335 - accuracy: 0.91 - ETA: 1s - loss: 0.2337 - accuracy: 0.91 - ETA: 1s - loss: 0.2329 - accuracy: 0.91 - ETA: 1s - loss: 0.2347 - accuracy: 0.91 - ETA: 1s - loss: 0.2340 - accuracy: 0.91 - ETA: 1s - loss: 0.2335 - accuracy: 0.91 - ETA: 1s - loss: 0.2335 - accuracy: 0.91 - ETA: 1s - loss: 0.2345 - accuracy: 0.91 - ETA: 1s - loss: 0.2352 - accuracy: 0.91 - ETA: 1s - loss: 0.2362 - accuracy: 0.91 - ETA: 0s - loss: 0.2353 - accuracy: 0.91 - ETA: 0s - loss: 0.2352 - accuracy: 0.91 - ETA: 0s - loss: 0.2360 - accuracy: 0.91 - ETA: 0s - loss: 0.2356 - accuracy: 0.91 - ETA: 0s - loss: 0.2355 - accuracy: 0.91 - ETA: 0s - loss: 0.2357 - accuracy: 0.91 - ETA: 0s - loss: 0.2361 - accuracy: 0.91 - ETA: 0s - loss: 0.2352 - accuracy: 0.91 - ETA: 0s - loss: 0.2365 - accuracy: 0.91 - ETA: 0s - loss: 0.2366 - accuracy: 0.91 - ETA: 0s - loss: 0.2368 - accuracy: 0.91 - ETA: 0s - loss: 0.2377 - accuracy: 0.91 - ETA: 0s - loss: 0.2384 - accuracy: 0.91 - ETA: 0s - loss: 0.2385 - accuracy: 0.91 - ETA: 0s - loss: 0.2382 - accuracy: 0.91 - ETA: 0s - loss: 0.2385 - accuracy: 0.91 - ETA: 0s - loss: 0.2387 - accuracy: 0.91 - ETA: 0s - loss: 0.2388 - accuracy: 0.91 - ETA: 0s - loss: 0.2390 - accuracy: 0.91 - ETA: 0s - loss: 0.2388 - accuracy: 0.91 - 3s 49us/sample - loss: 0.2387 - accuracy: 0.9110 - val_loss: 0.3211 - val_accuracy: 0.8868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19f00753848>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(img_train, label_train, epochs = 10, validation_data = (img_test, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
