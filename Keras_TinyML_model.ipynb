{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing examples: m_test = 267\n",
      "test_set_x shape: (15, 267)\n",
      "test_set_y shape: (1, 267)\n",
      "Number of training examples: m_train = 624\n",
      "train_set_x shape: (15, 624)\n",
      "train_set_y shape: (1, 624)\n"
     ]
    }
   ],
   "source": [
    "#Helper functions for the data processing\n",
    "def substrings_in_string(big_string, substrings):\n",
    "    for substring in substrings:\n",
    "        if str.find(big_string, substring) != -1:\n",
    "            return substring\n",
    "    #print(big_string)\n",
    "    return np.nan\n",
    "\n",
    "def replace_titles(x):\n",
    "    title=x['Title']\n",
    "    if title in ['Don']:\n",
    "        return -1\n",
    "    elif title in ['Major']:\n",
    "        return -0.875\n",
    "    elif title in ['Capt']:\n",
    "        return -0.75\n",
    "    elif title in ['Jonkheer']:\n",
    "        return -0.625\n",
    "    elif title in ['Rev']:\n",
    "        return -0.5\n",
    "    elif title in ['Col']:\n",
    "        return -0.375\n",
    "    elif title in ['Mr']:\n",
    "        return -0.25\n",
    "    elif title in ['Master']:\n",
    "        return -.125 \n",
    "    elif title in ['Countess']:\n",
    "        return 0.125\n",
    "    elif title in ['Mrs']:\n",
    "        return 0.25\n",
    "    elif title in ['Mme']:\n",
    "        return 0.375\n",
    "    elif title in ['Mlle']:\n",
    "        return 0.5\n",
    "    elif title in ['Miss']:\n",
    "        return 0.625\n",
    "    elif title in ['Ms']:\n",
    "        return 0.75\n",
    "    elif title =='Dr':\n",
    "        if x['Sex']=='female':\n",
    "            return 0.875\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        return title \n",
    "                   \n",
    "#The data processing for the training and testing data sets\n",
    "def data_train(filename, split = True):\n",
    "    train_data = pd.read_csv(filename)\n",
    "    \n",
    "    title_list=['Mrs', 'Mr', 'Master', 'Miss', 'Major', 'Rev',\n",
    "                        'Dr', 'Ms', 'Mlle','Col', 'Capt', 'Mme', 'Countess',\n",
    "                        'Don', 'Jonkheer']\n",
    "\n",
    "    train_data['Title'] = train_data['Name'].map(lambda x: substrings_in_string(x, title_list))   \n",
    "    train_data['Title'] = train_data.apply(replace_titles, axis=1)\n",
    "    train_data['Title'] = train_data['Title'].fillna(-2)\n",
    "    \n",
    "    #Turning cabin number into Deck\n",
    "    cabin_list = ['A', 'B', 'C', 'D', 'E', 'F', 'T', 'G', 'Unknown']\n",
    "    train_data['Cabin'] = train_data['Cabin'].astype(str)\n",
    "    train_data['Deck'] = train_data['Cabin'].map(lambda x: substrings_in_string(x, cabin_list))\n",
    "    \n",
    "    train_data.loc[(train_data.Deck == 'A'),'Deck'] = -1\n",
    "    train_data.loc[(train_data.Deck == 'B'),'Deck'] = -.75\n",
    "    train_data.loc[(train_data.Deck == 'C'),'Deck'] = -.5\n",
    "    train_data.loc[(train_data.Deck == 'D'),'Deck'] = -.25\n",
    "    train_data.loc[(train_data.Deck == 'E'),'Deck'] = .25\n",
    "    train_data.loc[(train_data.Deck == 'F'),'Deck'] = .5\n",
    "    train_data.loc[(train_data.Deck == 'T'),'Deck'] = .75\n",
    "    train_data.loc[(train_data.Deck == 'G'),'Deck'] = 1\n",
    "    train_data['Deck'] = train_data['Deck'].fillna(0.0005)\n",
    "    \n",
    "    train_data['Family_Size'] = train_data['SibSp'] + train_data['Parch']\n",
    "    train_data.loc[(train_data.Family_Size == 0),'Family_Size'] = 1\n",
    "    \n",
    "    train_data['Family_Size*class'] = train_data['Family_Size'] / (train_data['Pclass'] + 0.0005)\n",
    "    \n",
    "    train_data.loc[(train_data.Pclass == 1),'Pclass'] = 1\n",
    "    train_data.loc[(train_data.Pclass == 2),'Pclass'] = .5\n",
    "    train_data.loc[(train_data.Pclass == 3),'Pclass'] = -1\n",
    "    \n",
    "    age_mean = train_data['Age'].mean(skipna = True)\n",
    "    train_data['Age'] = train_data['Age'].fillna(age_mean)\n",
    "    \n",
    "    train_data['Minor'] = train_data['Age']\n",
    "    train_data.loc[(train_data.Minor <= 16),'Minor'] = 1\n",
    "    train_data.loc[(train_data.Minor > 16),'Minor'] = -1\n",
    "    \n",
    "    train_data['Title*Class'] = train_data['Title'] / (train_data['Pclass'] + 0.0005)\n",
    "    \n",
    "    train_data['Age*Class'] = train_data['Age'] / (train_data['Pclass'] + 0.0005)\n",
    "    train_data['Age*Class'] = train_data['Age*Class'].fillna(-1)\n",
    "    \n",
    "    train_data['Fare_Per_Person'] = train_data['Fare']  / (train_data['Family_Size']+1)\n",
    "\n",
    "    train_data.loc[(train_data.Sex == 'female'),'Sex'] = -1\n",
    "    train_data.loc[(train_data.Sex == 'male'),'Sex'] = 1\n",
    "\n",
    "    train_data.loc[(train_data.Embarked == 'C'),'Embarked'] = -1\n",
    "    train_data.loc[(train_data.Embarked == 'Q'),'Embarked'] = 1\n",
    "    train_data.loc[(train_data.Embarked == 'S'),'Embarked'] = 2\n",
    "    train_data['Embarked'] = train_data['Embarked'].fillna(0.0005)\n",
    "    \n",
    "    train_data['Embarked*Class'] = train_data['Embarked'] / (train_data['Pclass'] + 0.0005)\n",
    "    \n",
    "    train_data['Sex*Class'] = train_data['Sex'] / (train_data['Pclass'] + 0.0005)\n",
    "    \n",
    "    train_data['Minor*Class'] = train_data['Minor'] / (train_data['Pclass'] + 0.0005)\n",
    "    \n",
    "    train_data['Age*Deck'] = train_data['Deck'] / (train_data['Age'] + 0.0005)\n",
    "    \n",
    "    train_data['Title*Class'] = train_data['Title'] / (train_data['Pclass'] + 0.0005)\n",
    "\n",
    "    #tmp = train_data[['Pclass', 'Title*Class', 'Title', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Deck', 'Title*Class', 'Minor', 'Minor*Class',\n",
    "    #                  'Family_Size', 'Age*Class', 'Fare_Per_Person', 'Embarked*Class', 'Sex*Class', 'Age*Deck', 'Family_Size*class']].copy()\n",
    "    \n",
    "    tmp = train_data[['Pclass','Title','Title*Class','Sex','Age','Fare','Deck','Title*Class','Minor','Minor*Class',\n",
    "                      'Family_Size','Fare_Per_Person','Sex*Class','Age*Deck','Family_Size*class']].copy()\n",
    "    \n",
    "    X = pd.DataFrame(tmp).to_numpy()\n",
    "    X = X.T\n",
    "    X = np.float32(X)\n",
    "    \n",
    "    if split == True:\n",
    "        m = X.shape[1]\n",
    "        Y = np.array([train_data['Survived'].values])\n",
    "        Y = np.float32(Y)\n",
    "        \n",
    "        #Shuffle (X, Y)\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuff_X = X[:, permutation]\n",
    "        shuff_Y = Y[:, permutation].reshape((1,m))\n",
    "    \n",
    "        devM = round(m * .3)\n",
    "        devM2 = m - devM\n",
    "        \n",
    "        train_X = shuff_X[:, 0:(devM2)]\n",
    "        train_Y = shuff_Y[:, 0:(devM2)]\n",
    "        dev_X = shuff_X[:, -(devM + 1):-1]\n",
    "        dev_Y = shuff_Y[:, -(devM + 1):-1]\n",
    "        \n",
    "        m_train = train_X.shape[1]\n",
    "        m_test = dev_X.shape[1]\n",
    "        \n",
    "        print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "        print (\"test_set_x shape: \" + str(dev_X.shape))\n",
    "        print (\"test_set_y shape: \" + str(dev_Y.shape))\n",
    "        print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "        print (\"train_set_x shape: \" + str(train_X.shape))\n",
    "        print (\"train_set_y shape: \" + str(train_Y.shape))\n",
    "    \n",
    "        return train_X, train_Y, dev_X, dev_Y\n",
    "    \n",
    "    return X\n",
    "    \n",
    "train_X, train_Y, dev_X, dev_Y = data_train(\"train.csv\", split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 624 samples, validate on 267 samples\n",
      "Epoch 1/750\n",
      "624/624 [==============================] - 0s 438us/step - loss: 11.9384 - accuracy: 0.6426 - val_loss: 7.6620 - val_accuracy: 0.7004\n",
      "Epoch 2/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 7.6663 - accuracy: 0.6859 - val_loss: 7.6277 - val_accuracy: 0.7041\n",
      "Epoch 3/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 7.6061 - accuracy: 0.6939 - val_loss: 7.5570 - val_accuracy: 0.7116\n",
      "Epoch 4/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 7.5351 - accuracy: 0.6939 - val_loss: 7.4982 - val_accuracy: 0.6854\n",
      "Epoch 5/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 7.4743 - accuracy: 0.6875 - val_loss: 7.4395 - val_accuracy: 0.6742\n",
      "Epoch 6/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 7.4138 - accuracy: 0.7019 - val_loss: 7.3808 - val_accuracy: 0.6667\n",
      "Epoch 7/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 7.3535 - accuracy: 0.6955 - val_loss: 7.3208 - val_accuracy: 0.6667\n",
      "Epoch 8/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 7.2917 - accuracy: 0.6955 - val_loss: 7.2611 - val_accuracy: 0.6554\n",
      "Epoch 9/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 7.2294 - accuracy: 0.6955 - val_loss: 7.2017 - val_accuracy: 0.6629\n",
      "Epoch 10/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 7.1699 - accuracy: 0.6298 - val_loss: 7.1432 - val_accuracy: 0.5955\n",
      "Epoch 11/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 7.1123 - accuracy: 0.6234 - val_loss: 7.0866 - val_accuracy: 0.5955\n",
      "Epoch 12/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 7.0564 - accuracy: 0.6234 - val_loss: 7.0319 - val_accuracy: 0.5955\n",
      "Epoch 13/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 7.0020 - accuracy: 0.6234 - val_loss: 6.9789 - val_accuracy: 0.5955\n",
      "Epoch 14/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.9483 - accuracy: 0.6234 - val_loss: 6.9269 - val_accuracy: 0.5955\n",
      "Epoch 15/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.8960 - accuracy: 0.6234 - val_loss: 6.8759 - val_accuracy: 0.5955\n",
      "Epoch 16/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.8450 - accuracy: 0.6234 - val_loss: 6.8256 - val_accuracy: 0.5955\n",
      "Epoch 17/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.7944 - accuracy: 0.6234 - val_loss: 6.7760 - val_accuracy: 0.5955\n",
      "Epoch 18/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.7440 - accuracy: 0.6234 - val_loss: 6.7267 - val_accuracy: 0.5955\n",
      "Epoch 19/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.6937 - accuracy: 0.6234 - val_loss: 6.6783 - val_accuracy: 0.5955\n",
      "Epoch 20/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.6448 - accuracy: 0.6234 - val_loss: 6.6303 - val_accuracy: 0.5955\n",
      "Epoch 21/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.5966 - accuracy: 0.6747 - val_loss: 6.5836 - val_accuracy: 0.6779\n",
      "Epoch 22/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.5496 - accuracy: 0.6971 - val_loss: 6.5374 - val_accuracy: 0.6742\n",
      "Epoch 23/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.5028 - accuracy: 0.6987 - val_loss: 6.4914 - val_accuracy: 0.6742\n",
      "Epoch 24/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.4570 - accuracy: 0.6987 - val_loss: 6.4461 - val_accuracy: 0.6742\n",
      "Epoch 25/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.4117 - accuracy: 0.7003 - val_loss: 6.4013 - val_accuracy: 0.6779\n",
      "Epoch 26/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.3666 - accuracy: 0.7003 - val_loss: 6.3569 - val_accuracy: 0.6779\n",
      "Epoch 27/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.3222 - accuracy: 0.7003 - val_loss: 6.3135 - val_accuracy: 0.6779\n",
      "Epoch 28/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.2786 - accuracy: 0.6987 - val_loss: 6.2708 - val_accuracy: 0.6779\n",
      "Epoch 29/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.2358 - accuracy: 0.7003 - val_loss: 6.2287 - val_accuracy: 0.6779\n",
      "Epoch 30/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.1932 - accuracy: 0.7003 - val_loss: 6.1871 - val_accuracy: 0.6779\n",
      "Epoch 31/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.1513 - accuracy: 0.7035 - val_loss: 6.1461 - val_accuracy: 0.6816\n",
      "Epoch 32/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 6.1097 - accuracy: 0.7019 - val_loss: 6.1055 - val_accuracy: 0.6779\n",
      "Epoch 33/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 6.0689 - accuracy: 0.6971 - val_loss: 6.0652 - val_accuracy: 0.6779\n",
      "Epoch 34/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 6.0281 - accuracy: 0.7003 - val_loss: 6.0256 - val_accuracy: 0.6779\n",
      "Epoch 35/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 5.9887 - accuracy: 0.7035 - val_loss: 5.9860 - val_accuracy: 0.6779\n",
      "Epoch 36/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.9495 - accuracy: 0.7067 - val_loss: 5.9474 - val_accuracy: 0.6779\n",
      "Epoch 37/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.9105 - accuracy: 0.7067 - val_loss: 5.9095 - val_accuracy: 0.6742\n",
      "Epoch 38/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.8716 - accuracy: 0.7051 - val_loss: 5.8717 - val_accuracy: 0.6816\n",
      "Epoch 39/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.8337 - accuracy: 0.6955 - val_loss: 5.8340 - val_accuracy: 0.6816\n",
      "Epoch 40/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.7965 - accuracy: 0.6939 - val_loss: 5.7971 - val_accuracy: 0.6816\n",
      "Epoch 41/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.7597 - accuracy: 0.6987 - val_loss: 5.7607 - val_accuracy: 0.6816\n",
      "Epoch 42/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.7225 - accuracy: 0.7051 - val_loss: 5.7247 - val_accuracy: 0.6854\n",
      "Epoch 43/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.6858 - accuracy: 0.7147 - val_loss: 5.6888 - val_accuracy: 0.6891\n",
      "Epoch 44/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.6499 - accuracy: 0.7147 - val_loss: 5.6536 - val_accuracy: 0.6891\n",
      "Epoch 45/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.6137 - accuracy: 0.7067 - val_loss: 5.6177 - val_accuracy: 0.6929\n",
      "Epoch 46/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.5764 - accuracy: 0.7212 - val_loss: 5.5815 - val_accuracy: 0.7041\n",
      "Epoch 47/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.5394 - accuracy: 0.7212 - val_loss: 5.5462 - val_accuracy: 0.6966\n",
      "Epoch 48/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.5029 - accuracy: 0.7196 - val_loss: 5.5151 - val_accuracy: 0.6742\n",
      "Epoch 49/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.4677 - accuracy: 0.7163 - val_loss: 5.4841 - val_accuracy: 0.6742\n",
      "Epoch 50/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.4351 - accuracy: 0.7051 - val_loss: 5.4483 - val_accuracy: 0.6779\n",
      "Epoch 51/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.4009 - accuracy: 0.7163 - val_loss: 5.4149 - val_accuracy: 0.6966\n",
      "Epoch 52/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.3693 - accuracy: 0.7260 - val_loss: 5.3840 - val_accuracy: 0.6966\n",
      "Epoch 53/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.3365 - accuracy: 0.7308 - val_loss: 5.3524 - val_accuracy: 0.7079\n",
      "Epoch 54/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.3051 - accuracy: 0.7260 - val_loss: 5.3215 - val_accuracy: 0.7079\n",
      "Epoch 55/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.2716 - accuracy: 0.7244 - val_loss: 5.2910 - val_accuracy: 0.7041\n",
      "Epoch 56/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.2395 - accuracy: 0.7388 - val_loss: 5.2599 - val_accuracy: 0.6966\n",
      "Epoch 57/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.2087 - accuracy: 0.7356 - val_loss: 5.2304 - val_accuracy: 0.7004\n",
      "Epoch 58/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 5.1753 - accuracy: 0.7340 - val_loss: 5.1997 - val_accuracy: 0.6966\n",
      "Epoch 59/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.1456 - accuracy: 0.7308 - val_loss: 5.1677 - val_accuracy: 0.7041\n",
      "Epoch 60/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.1139 - accuracy: 0.7500 - val_loss: 5.1370 - val_accuracy: 0.7041\n",
      "Epoch 61/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 5.0997 - accuracy: 0.73 - 0s 14us/step - loss: 5.0841 - accuracy: 0.7564 - val_loss: 5.1060 - val_accuracy: 0.7191\n",
      "Epoch 62/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 5.0546 - accuracy: 0.7500 - val_loss: 5.0783 - val_accuracy: 0.7079\n",
      "Epoch 63/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 5.0254 - accuracy: 0.7500 - val_loss: 5.0500 - val_accuracy: 0.7191\n",
      "Epoch 64/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.9967 - accuracy: 0.7564 - val_loss: 5.0256 - val_accuracy: 0.7079\n",
      "Epoch 65/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.9676 - accuracy: 0.7548 - val_loss: 4.9985 - val_accuracy: 0.7079\n",
      "Epoch 66/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.9390 - accuracy: 0.7580 - val_loss: 4.9701 - val_accuracy: 0.7266\n",
      "Epoch 67/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.9131 - accuracy: 0.7644 - val_loss: 4.9438 - val_accuracy: 0.7154\n",
      "Epoch 68/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.8888 - accuracy: 0.7500 - val_loss: 4.9135 - val_accuracy: 0.7266\n",
      "Epoch 69/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.8611 - accuracy: 0.7644 - val_loss: 4.8929 - val_accuracy: 0.7116\n",
      "Epoch 70/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.8430 - accuracy: 0.7468 - val_loss: 4.8707 - val_accuracy: 0.7116\n",
      "Epoch 71/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.8141 - accuracy: 0.7516 - val_loss: 4.8477 - val_accuracy: 0.7154\n",
      "Epoch 72/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.7884 - accuracy: 0.7548 - val_loss: 4.8158 - val_accuracy: 0.7228\n",
      "Epoch 73/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.7603 - accuracy: 0.7612 - val_loss: 4.7877 - val_accuracy: 0.7341\n",
      "Epoch 74/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.7327 - accuracy: 0.7644 - val_loss: 4.7588 - val_accuracy: 0.7341\n",
      "Epoch 75/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.7049 - accuracy: 0.7628 - val_loss: 4.7299 - val_accuracy: 0.7378\n",
      "Epoch 76/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.6784 - accuracy: 0.7628 - val_loss: 4.7027 - val_accuracy: 0.7491\n",
      "Epoch 77/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.6520 - accuracy: 0.7692 - val_loss: 4.6791 - val_accuracy: 0.7528\n",
      "Epoch 78/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.6300 - accuracy: 0.7724 - val_loss: 4.6554 - val_accuracy: 0.7453\n",
      "Epoch 79/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.6039 - accuracy: 0.7676 - val_loss: 4.6312 - val_accuracy: 0.7453\n",
      "Epoch 80/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.5796 - accuracy: 0.7708 - val_loss: 4.6090 - val_accuracy: 0.7491\n",
      "Epoch 81/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.5571 - accuracy: 0.7580 - val_loss: 4.5845 - val_accuracy: 0.7378\n",
      "Epoch 82/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.5346 - accuracy: 0.7676 - val_loss: 4.5615 - val_accuracy: 0.7453\n",
      "Epoch 83/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 4.5102 - accuracy: 0.7548 - val_loss: 4.5375 - val_accuracy: 0.7491\n",
      "Epoch 84/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.4857 - accuracy: 0.7692 - val_loss: 4.5206 - val_accuracy: 0.7228\n",
      "Epoch 85/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.4704 - accuracy: 0.7692 - val_loss: 4.4968 - val_accuracy: 0.7453\n",
      "Epoch 86/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.4403 - accuracy: 0.7708 - val_loss: 4.4789 - val_accuracy: 0.7640\n",
      "Epoch 87/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.4246 - accuracy: 0.7644 - val_loss: 4.4516 - val_accuracy: 0.7453\n",
      "Epoch 88/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.4042 - accuracy: 0.7708 - val_loss: 4.4282 - val_accuracy: 0.7378\n",
      "Epoch 89/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.3725 - accuracy: 0.7660 - val_loss: 4.4127 - val_accuracy: 0.7603\n",
      "Epoch 90/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.3579 - accuracy: 0.7564 - val_loss: 4.3843 - val_accuracy: 0.7266\n",
      "Epoch 91/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.3300 - accuracy: 0.7708 - val_loss: 4.3599 - val_accuracy: 0.7303\n",
      "Epoch 92/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.3115 - accuracy: 0.7692 - val_loss: 4.3412 - val_accuracy: 0.7453\n",
      "Epoch 93/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.2850 - accuracy: 0.7644 - val_loss: 4.3208 - val_accuracy: 0.7491\n",
      "Epoch 94/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.2636 - accuracy: 0.7708 - val_loss: 4.2989 - val_accuracy: 0.7491\n",
      "Epoch 95/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.2400 - accuracy: 0.7772 - val_loss: 4.2740 - val_accuracy: 0.7416\n",
      "Epoch 96/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.2183 - accuracy: 0.7821 - val_loss: 4.2571 - val_accuracy: 0.7603\n",
      "Epoch 97/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.2019 - accuracy: 0.7596 - val_loss: 4.2288 - val_accuracy: 0.7378\n",
      "Epoch 98/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.1759 - accuracy: 0.7837 - val_loss: 4.2123 - val_accuracy: 0.7678\n",
      "Epoch 99/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.1569 - accuracy: 0.7676 - val_loss: 4.1872 - val_accuracy: 0.7491\n",
      "Epoch 100/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.1359 - accuracy: 0.7788 - val_loss: 4.1663 - val_accuracy: 0.7528\n",
      "Epoch 101/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.1139 - accuracy: 0.7772 - val_loss: 4.1439 - val_accuracy: 0.7416\n",
      "Epoch 102/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.0933 - accuracy: 0.7821 - val_loss: 4.1236 - val_accuracy: 0.7753\n",
      "Epoch 103/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.0740 - accuracy: 0.7788 - val_loss: 4.1036 - val_accuracy: 0.7566\n",
      "Epoch 104/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.0537 - accuracy: 0.7853 - val_loss: 4.0865 - val_accuracy: 0.7753\n",
      "Epoch 105/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.0374 - accuracy: 0.7821 - val_loss: 4.0679 - val_accuracy: 0.7790\n",
      "Epoch 106/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 4.0204 - accuracy: 0.7756 - val_loss: 4.0475 - val_accuracy: 0.7753\n",
      "Epoch 107/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 4.0008 - accuracy: 0.7949 - val_loss: 4.0287 - val_accuracy: 0.7828\n",
      "Epoch 108/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.9805 - accuracy: 0.7837 - val_loss: 4.0087 - val_accuracy: 0.7790\n",
      "Epoch 109/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.9698 - accuracy: 0.7772 - val_loss: 3.9942 - val_accuracy: 0.7828\n",
      "Epoch 110/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.9455 - accuracy: 0.7997 - val_loss: 3.9764 - val_accuracy: 0.7828\n",
      "Epoch 111/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.9259 - accuracy: 0.7740 - val_loss: 3.9572 - val_accuracy: 0.7790\n",
      "Epoch 112/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.9098 - accuracy: 0.7885 - val_loss: 3.9378 - val_accuracy: 0.7715\n",
      "Epoch 113/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 0s 16us/step - loss: 3.8888 - accuracy: 0.7901 - val_loss: 3.9177 - val_accuracy: 0.7903\n",
      "Epoch 114/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.8751 - accuracy: 0.7837 - val_loss: 3.8997 - val_accuracy: 0.7903\n",
      "Epoch 115/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.8548 - accuracy: 0.7885 - val_loss: 3.8851 - val_accuracy: 0.7790\n",
      "Epoch 116/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.8420 - accuracy: 0.7853 - val_loss: 3.8722 - val_accuracy: 0.7566\n",
      "Epoch 117/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.8372 - accuracy: 0.7804 - val_loss: 3.8580 - val_accuracy: 0.7828\n",
      "Epoch 118/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.8228 - accuracy: 0.7756 - val_loss: 3.8432 - val_accuracy: 0.7828\n",
      "Epoch 119/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.8016 - accuracy: 0.7756 - val_loss: 3.8298 - val_accuracy: 0.7491\n",
      "Epoch 120/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 3.7778 - accuracy: 0.7788 - val_loss: 3.8143 - val_accuracy: 0.7603\n",
      "Epoch 121/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.7606 - accuracy: 0.7853 - val_loss: 3.8039 - val_accuracy: 0.7828\n",
      "Epoch 122/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.7405 - accuracy: 0.7804 - val_loss: 3.7917 - val_accuracy: 0.7416\n",
      "Epoch 123/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 3.7418 - accuracy: 0.7933 - val_loss: 3.7805 - val_accuracy: 0.7790\n",
      "Epoch 124/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.7276 - accuracy: 0.7708 - val_loss: 3.7564 - val_accuracy: 0.7678\n",
      "Epoch 125/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.7186 - accuracy: 0.7724 - val_loss: 3.7366 - val_accuracy: 0.7603\n",
      "Epoch 126/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.6854 - accuracy: 0.7676 - val_loss: 3.7240 - val_accuracy: 0.7903\n",
      "Epoch 127/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.6739 - accuracy: 0.7837 - val_loss: 3.7101 - val_accuracy: 0.7566\n",
      "Epoch 128/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.6577 - accuracy: 0.7740 - val_loss: 3.6944 - val_accuracy: 0.7903\n",
      "Epoch 129/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.6393 - accuracy: 0.7724 - val_loss: 3.6756 - val_accuracy: 0.7678\n",
      "Epoch 130/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.6219 - accuracy: 0.7853 - val_loss: 3.6736 - val_accuracy: 0.7603\n",
      "Epoch 131/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.6136 - accuracy: 0.7612 - val_loss: 3.6457 - val_accuracy: 0.7453\n",
      "Epoch 132/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.5949 - accuracy: 0.7885 - val_loss: 3.6285 - val_accuracy: 0.7528\n",
      "Epoch 133/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.5714 - accuracy: 0.7885 - val_loss: 3.6257 - val_accuracy: 0.7865\n",
      "Epoch 134/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.5687 - accuracy: 0.7772 - val_loss: 3.6009 - val_accuracy: 0.7790\n",
      "Epoch 135/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.5571 - accuracy: 0.7933 - val_loss: 3.5837 - val_accuracy: 0.7940\n",
      "Epoch 136/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.5544 - accuracy: 0.7660 - val_loss: 3.5668 - val_accuracy: 0.7640\n",
      "Epoch 137/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 3.5184 - accuracy: 0.7933 - val_loss: 3.5546 - val_accuracy: 0.7865\n",
      "Epoch 138/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.5035 - accuracy: 0.7885 - val_loss: 3.5384 - val_accuracy: 0.7753\n",
      "Epoch 139/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.4899 - accuracy: 0.7772 - val_loss: 3.5298 - val_accuracy: 0.7715\n",
      "Epoch 140/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.4834 - accuracy: 0.7981 - val_loss: 3.5205 - val_accuracy: 0.7790\n",
      "Epoch 141/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.4746 - accuracy: 0.7644 - val_loss: 3.5043 - val_accuracy: 0.7678\n",
      "Epoch 142/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.4578 - accuracy: 0.7885 - val_loss: 3.4906 - val_accuracy: 0.7790\n",
      "Epoch 143/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.4354 - accuracy: 0.7949 - val_loss: 3.4846 - val_accuracy: 0.7828\n",
      "Epoch 144/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.4242 - accuracy: 0.7804 - val_loss: 3.4606 - val_accuracy: 0.7678\n",
      "Epoch 145/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.4164 - accuracy: 0.7869 - val_loss: 3.4476 - val_accuracy: 0.7566\n",
      "Epoch 146/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.3927 - accuracy: 0.7853 - val_loss: 3.4411 - val_accuracy: 0.7640\n",
      "Epoch 147/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.3879 - accuracy: 0.7949 - val_loss: 3.4304 - val_accuracy: 0.7491\n",
      "Epoch 148/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.3727 - accuracy: 0.7804 - val_loss: 3.4197 - val_accuracy: 0.7790\n",
      "Epoch 149/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.3609 - accuracy: 0.7724 - val_loss: 3.4029 - val_accuracy: 0.7603\n",
      "Epoch 150/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.3506 - accuracy: 0.7933 - val_loss: 3.3795 - val_accuracy: 0.7903\n",
      "Epoch 151/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.3312 - accuracy: 0.7837 - val_loss: 3.3724 - val_accuracy: 0.7753\n",
      "Epoch 152/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.3187 - accuracy: 0.7949 - val_loss: 3.3604 - val_accuracy: 0.7903\n",
      "Epoch 153/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.3128 - accuracy: 0.7644 - val_loss: 3.3471 - val_accuracy: 0.7753\n",
      "Epoch 154/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.2932 - accuracy: 0.7997 - val_loss: 3.3387 - val_accuracy: 0.7603\n",
      "Epoch 155/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.2808 - accuracy: 0.7756 - val_loss: 3.3250 - val_accuracy: 0.7566\n",
      "Epoch 156/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.2698 - accuracy: 0.7917 - val_loss: 3.3107 - val_accuracy: 0.7566\n",
      "Epoch 157/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.2645 - accuracy: 0.7740 - val_loss: 3.2940 - val_accuracy: 0.7828\n",
      "Epoch 158/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.2458 - accuracy: 0.7981 - val_loss: 3.2856 - val_accuracy: 0.7715\n",
      "Epoch 159/750\n",
      "624/624 [==============================] - 0s 19us/step - loss: 3.2327 - accuracy: 0.7981 - val_loss: 3.2759 - val_accuracy: 0.7603\n",
      "Epoch 160/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.2169 - accuracy: 0.7917 - val_loss: 3.2624 - val_accuracy: 0.7753\n",
      "Epoch 161/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.2100 - accuracy: 0.7885 - val_loss: 3.2452 - val_accuracy: 0.7753\n",
      "Epoch 162/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.1964 - accuracy: 0.7804 - val_loss: 3.2293 - val_accuracy: 0.7978\n",
      "Epoch 163/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.1816 - accuracy: 0.7901 - val_loss: 3.2189 - val_accuracy: 0.7828\n",
      "Epoch 164/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.1718 - accuracy: 0.7837 - val_loss: 3.2136 - val_accuracy: 0.7566\n",
      "Epoch 165/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.1572 - accuracy: 0.7885 - val_loss: 3.2081 - val_accuracy: 0.7528\n",
      "Epoch 166/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.1503 - accuracy: 0.7853 - val_loss: 3.1967 - val_accuracy: 0.7566\n",
      "Epoch 167/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 3.1555 - accuracy: 0.7837 - val_loss: 3.1838 - val_accuracy: 0.7528\n",
      "Epoch 168/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.1259 - accuracy: 0.7853 - val_loss: 3.1723 - val_accuracy: 0.7790\n",
      "Epoch 169/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.1153 - accuracy: 0.7853 - val_loss: 3.1534 - val_accuracy: 0.7790\n",
      "Epoch 170/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.1018 - accuracy: 0.7885 - val_loss: 3.1442 - val_accuracy: 0.7603\n",
      "Epoch 171/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.0944 - accuracy: 0.7853 - val_loss: 3.1321 - val_accuracy: 0.7828\n",
      "Epoch 172/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.0814 - accuracy: 0.7853 - val_loss: 3.1318 - val_accuracy: 0.7528\n",
      "Epoch 173/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.0698 - accuracy: 0.7804 - val_loss: 3.1247 - val_accuracy: 0.7416\n",
      "Epoch 174/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.0857 - accuracy: 0.7788 - val_loss: 3.1058 - val_accuracy: 0.7491\n",
      "Epoch 175/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 3.0629 - accuracy: 0.7740 - val_loss: 3.0901 - val_accuracy: 0.7828\n",
      "Epoch 176/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.0566 - accuracy: 0.7756 - val_loss: 3.0846 - val_accuracy: 0.7640\n",
      "Epoch 177/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.0479 - accuracy: 0.7756 - val_loss: 3.0760 - val_accuracy: 0.7865\n",
      "Epoch 178/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 3.0321 - accuracy: 0.7596 - val_loss: 3.0690 - val_accuracy: 0.7491\n",
      "Epoch 179/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.0181 - accuracy: 0.7917 - val_loss: 3.0807 - val_accuracy: 0.7715\n",
      "Epoch 180/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 3.0114 - accuracy: 0.7740 - val_loss: 3.0512 - val_accuracy: 0.7491\n",
      "Epoch 181/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 3.0065 - accuracy: 0.7804 - val_loss: 3.0380 - val_accuracy: 0.7566\n",
      "Epoch 182/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.9825 - accuracy: 0.7772 - val_loss: 3.0235 - val_accuracy: 0.7715\n",
      "Epoch 183/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.9633 - accuracy: 0.7949 - val_loss: 3.0138 - val_accuracy: 0.7603\n",
      "Epoch 184/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.9640 - accuracy: 0.7949 - val_loss: 2.9937 - val_accuracy: 0.7940\n",
      "Epoch 185/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.9532 - accuracy: 0.7772 - val_loss: 2.9806 - val_accuracy: 0.7940\n",
      "Epoch 186/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.9407 - accuracy: 0.7804 - val_loss: 2.9727 - val_accuracy: 0.7790\n",
      "Epoch 187/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.9235 - accuracy: 0.7949 - val_loss: 2.9663 - val_accuracy: 0.7828\n",
      "Epoch 188/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.9114 - accuracy: 0.7965 - val_loss: 2.9637 - val_accuracy: 0.7903\n",
      "Epoch 189/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.9091 - accuracy: 0.7772 - val_loss: 2.9514 - val_accuracy: 0.7640\n",
      "Epoch 190/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.9152 - accuracy: 0.7837 - val_loss: 2.9380 - val_accuracy: 0.7603\n",
      "Epoch 191/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.8888 - accuracy: 0.7837 - val_loss: 2.9331 - val_accuracy: 0.7828\n",
      "Epoch 192/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.8775 - accuracy: 0.7869 - val_loss: 2.9183 - val_accuracy: 0.7678\n",
      "Epoch 193/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.8708 - accuracy: 0.7917 - val_loss: 2.9072 - val_accuracy: 0.7640\n",
      "Epoch 194/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.8520 - accuracy: 0.7933 - val_loss: 2.9026 - val_accuracy: 0.7640\n",
      "Epoch 195/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.8571 - accuracy: 0.7901 - val_loss: 2.8867 - val_accuracy: 0.7678\n",
      "Epoch 196/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 2.8360 - accuracy: 0.7772 - val_loss: 2.8774 - val_accuracy: 0.7603\n",
      "Epoch 197/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.8266 - accuracy: 0.7853 - val_loss: 2.8679 - val_accuracy: 0.7865\n",
      "Epoch 198/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.8152 - accuracy: 0.8029 - val_loss: 2.8627 - val_accuracy: 0.7828\n",
      "Epoch 199/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.8170 - accuracy: 0.7756 - val_loss: 2.8565 - val_accuracy: 0.7678\n",
      "Epoch 200/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.8125 - accuracy: 0.7901 - val_loss: 2.8398 - val_accuracy: 0.7790\n",
      "Epoch 201/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7907 - accuracy: 0.7853 - val_loss: 2.8359 - val_accuracy: 0.7715\n",
      "Epoch 202/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7934 - accuracy: 0.7917 - val_loss: 2.8398 - val_accuracy: 0.7378\n",
      "Epoch 203/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7858 - accuracy: 0.7676 - val_loss: 2.8367 - val_accuracy: 0.7378\n",
      "Epoch 204/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.7793 - accuracy: 0.7708 - val_loss: 2.8192 - val_accuracy: 0.7603\n",
      "Epoch 205/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7686 - accuracy: 0.7837 - val_loss: 2.8022 - val_accuracy: 0.7828\n",
      "Epoch 206/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7612 - accuracy: 0.7660 - val_loss: 2.7903 - val_accuracy: 0.7828\n",
      "Epoch 207/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.7455 - accuracy: 0.7869 - val_loss: 2.7839 - val_accuracy: 0.7753\n",
      "Epoch 208/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7340 - accuracy: 0.7853 - val_loss: 2.7764 - val_accuracy: 0.7678\n",
      "Epoch 209/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7215 - accuracy: 0.7885 - val_loss: 2.7678 - val_accuracy: 0.7678\n",
      "Epoch 210/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 2.7154 - accuracy: 0.7837 - val_loss: 2.7566 - val_accuracy: 0.7790\n",
      "Epoch 211/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.7122 - accuracy: 0.7965 - val_loss: 2.7508 - val_accuracy: 0.7640\n",
      "Epoch 212/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.7079 - accuracy: 0.7660 - val_loss: 2.7431 - val_accuracy: 0.7453\n",
      "Epoch 213/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.6866 - accuracy: 0.7885 - val_loss: 2.7295 - val_accuracy: 0.7790\n",
      "Epoch 214/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.6756 - accuracy: 0.7901 - val_loss: 2.7296 - val_accuracy: 0.7828\n",
      "Epoch 215/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.6727 - accuracy: 0.7724 - val_loss: 2.7142 - val_accuracy: 0.7715\n",
      "Epoch 216/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 2.6628 - accuracy: 0.7901 - val_loss: 2.7051 - val_accuracy: 0.7715\n",
      "Epoch 217/750\n",
      "624/624 [==============================] - 0s 15us/step - loss: 2.6513 - accuracy: 0.7917 - val_loss: 2.6963 - val_accuracy: 0.7865\n",
      "Epoch 218/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.6410 - accuracy: 0.7981 - val_loss: 2.6876 - val_accuracy: 0.7603\n",
      "Epoch 219/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.6354 - accuracy: 0.7933 - val_loss: 2.6784 - val_accuracy: 0.7678\n",
      "Epoch 220/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.6317 - accuracy: 0.7804 - val_loss: 2.6700 - val_accuracy: 0.7865\n",
      "Epoch 221/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.6194 - accuracy: 0.8045 - val_loss: 2.6615 - val_accuracy: 0.7790\n",
      "Epoch 222/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 2.6101 - accuracy: 0.7853 - val_loss: 2.6547 - val_accuracy: 0.7753\n",
      "Epoch 223/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.6022 - accuracy: 0.7869 - val_loss: 2.6446 - val_accuracy: 0.7828\n",
      "Epoch 224/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5906 - accuracy: 0.7949 - val_loss: 2.6450 - val_accuracy: 0.7865\n",
      "Epoch 225/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 0s 14us/step - loss: 2.5965 - accuracy: 0.7724 - val_loss: 2.6343 - val_accuracy: 0.7678\n",
      "Epoch 226/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.5914 - accuracy: 0.7981 - val_loss: 2.6256 - val_accuracy: 0.7865\n",
      "Epoch 227/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5934 - accuracy: 0.7532 - val_loss: 2.6167 - val_accuracy: 0.7715\n",
      "Epoch 228/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.5853 - accuracy: 0.7869 - val_loss: 2.6135 - val_accuracy: 0.7678\n",
      "Epoch 229/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.5602 - accuracy: 0.7901 - val_loss: 2.6102 - val_accuracy: 0.7678\n",
      "Epoch 230/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5534 - accuracy: 0.7917 - val_loss: 2.5921 - val_accuracy: 0.7828\n",
      "Epoch 231/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.5387 - accuracy: 0.7949 - val_loss: 2.5869 - val_accuracy: 0.7865\n",
      "Epoch 232/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5395 - accuracy: 0.7788 - val_loss: 2.5767 - val_accuracy: 0.7715\n",
      "Epoch 233/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5222 - accuracy: 0.7981 - val_loss: 2.5815 - val_accuracy: 0.7828\n",
      "Epoch 234/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5327 - accuracy: 0.7676 - val_loss: 2.5676 - val_accuracy: 0.7566\n",
      "Epoch 235/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.5292 - accuracy: 0.7869 - val_loss: 2.5597 - val_accuracy: 0.7566\n",
      "Epoch 236/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5045 - accuracy: 0.7804 - val_loss: 2.5517 - val_accuracy: 0.7566\n",
      "Epoch 237/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5017 - accuracy: 0.7869 - val_loss: 2.5419 - val_accuracy: 0.7790\n",
      "Epoch 238/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.4818 - accuracy: 0.8061 - val_loss: 2.5669 - val_accuracy: 0.7640\n",
      "Epoch 239/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.5150 - accuracy: 0.7564 - val_loss: 2.5365 - val_accuracy: 0.7528\n",
      "Epoch 240/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4950 - accuracy: 0.7853 - val_loss: 2.5258 - val_accuracy: 0.7566\n",
      "Epoch 241/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4791 - accuracy: 0.7772 - val_loss: 2.5184 - val_accuracy: 0.7528\n",
      "Epoch 242/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.4783 - accuracy: 0.7756 - val_loss: 2.5210 - val_accuracy: 0.7453\n",
      "Epoch 243/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.4769 - accuracy: 0.7708 - val_loss: 2.5084 - val_accuracy: 0.7865\n",
      "Epoch 244/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 2.4533 - accuracy: 0.7756 - val_loss: 2.5017 - val_accuracy: 0.7603\n",
      "Epoch 245/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4650 - accuracy: 0.7788 - val_loss: 2.4820 - val_accuracy: 0.7790\n",
      "Epoch 246/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4290 - accuracy: 0.7933 - val_loss: 2.4763 - val_accuracy: 0.7790\n",
      "Epoch 247/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4273 - accuracy: 0.7885 - val_loss: 2.4715 - val_accuracy: 0.7790\n",
      "Epoch 248/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.4173 - accuracy: 0.7917 - val_loss: 2.4664 - val_accuracy: 0.7640\n",
      "Epoch 249/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4204 - accuracy: 0.7917 - val_loss: 2.4609 - val_accuracy: 0.7865\n",
      "Epoch 250/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.4057 - accuracy: 0.7869 - val_loss: 2.4559 - val_accuracy: 0.7903\n",
      "Epoch 251/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.4078 - accuracy: 0.7788 - val_loss: 2.4456 - val_accuracy: 0.7753\n",
      "Epoch 252/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.3928 - accuracy: 0.7837 - val_loss: 2.4361 - val_accuracy: 0.7678\n",
      "Epoch 253/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3808 - accuracy: 0.7997 - val_loss: 2.4275 - val_accuracy: 0.7865\n",
      "Epoch 254/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3766 - accuracy: 0.7933 - val_loss: 2.4189 - val_accuracy: 0.7790\n",
      "Epoch 255/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3696 - accuracy: 0.7901 - val_loss: 2.4157 - val_accuracy: 0.7790\n",
      "Epoch 256/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3630 - accuracy: 0.7901 - val_loss: 2.4095 - val_accuracy: 0.7790\n",
      "Epoch 257/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.3602 - accuracy: 0.8045 - val_loss: 2.3986 - val_accuracy: 0.7828\n",
      "Epoch 258/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 2.3503 - accuracy: 0.7837 - val_loss: 2.3938 - val_accuracy: 0.7753\n",
      "Epoch 259/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3415 - accuracy: 0.7997 - val_loss: 2.3881 - val_accuracy: 0.7828\n",
      "Epoch 260/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.3399 - accuracy: 0.7949 - val_loss: 2.3846 - val_accuracy: 0.7566\n",
      "Epoch 261/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.3354 - accuracy: 0.7965 - val_loss: 2.3886 - val_accuracy: 0.7603\n",
      "Epoch 262/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.3342 - accuracy: 0.7853 - val_loss: 2.3811 - val_accuracy: 0.7715\n",
      "Epoch 263/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 2.3221 - accuracy: 0.7901 - val_loss: 2.3685 - val_accuracy: 0.7753\n",
      "Epoch 264/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3166 - accuracy: 0.8045 - val_loss: 2.3568 - val_accuracy: 0.7790\n",
      "Epoch 265/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3046 - accuracy: 0.7933 - val_loss: 2.3533 - val_accuracy: 0.7640\n",
      "Epoch 266/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 2.3039 - accuracy: 0.79 - 0s 14us/step - loss: 2.3003 - accuracy: 0.7997 - val_loss: 2.3632 - val_accuracy: 0.7715\n",
      "Epoch 267/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.3162 - accuracy: 0.7644 - val_loss: 2.3457 - val_accuracy: 0.7640\n",
      "Epoch 268/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3148 - accuracy: 0.7788 - val_loss: 2.3487 - val_accuracy: 0.7528\n",
      "Epoch 269/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 2.2953 - accuracy: 0.7933 - val_loss: 2.3621 - val_accuracy: 0.7528\n",
      "Epoch 270/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.3001 - accuracy: 0.7740 - val_loss: 2.3337 - val_accuracy: 0.7528\n",
      "Epoch 271/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2839 - accuracy: 0.7885 - val_loss: 2.3206 - val_accuracy: 0.7865\n",
      "Epoch 272/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2785 - accuracy: 0.7564 - val_loss: 2.3203 - val_accuracy: 0.7640\n",
      "Epoch 273/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2895 - accuracy: 0.7821 - val_loss: 2.3075 - val_accuracy: 0.7678\n",
      "Epoch 274/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2605 - accuracy: 0.7804 - val_loss: 2.3113 - val_accuracy: 0.7828\n",
      "Epoch 275/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2563 - accuracy: 0.7724 - val_loss: 2.3034 - val_accuracy: 0.7566\n",
      "Epoch 276/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2503 - accuracy: 0.7949 - val_loss: 2.2975 - val_accuracy: 0.7790\n",
      "Epoch 277/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.2460 - accuracy: 0.7708 - val_loss: 2.2834 - val_accuracy: 0.7566\n",
      "Epoch 278/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2279 - accuracy: 0.8045 - val_loss: 2.2742 - val_accuracy: 0.7753\n",
      "Epoch 279/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.2190 - accuracy: 0.7917 - val_loss: 2.2693 - val_accuracy: 0.7865\n",
      "Epoch 280/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2211 - accuracy: 0.7788 - val_loss: 2.2617 - val_accuracy: 0.7828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2141 - accuracy: 0.7837 - val_loss: 2.2587 - val_accuracy: 0.7790\n",
      "Epoch 282/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.2093 - accuracy: 0.7949 - val_loss: 2.2507 - val_accuracy: 0.7678\n",
      "Epoch 283/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1977 - accuracy: 0.7885 - val_loss: 2.2440 - val_accuracy: 0.7790\n",
      "Epoch 284/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1934 - accuracy: 0.8061 - val_loss: 2.2385 - val_accuracy: 0.7678\n",
      "Epoch 285/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1973 - accuracy: 0.7788 - val_loss: 2.2360 - val_accuracy: 0.7753\n",
      "Epoch 286/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1872 - accuracy: 0.7965 - val_loss: 2.2338 - val_accuracy: 0.7678\n",
      "Epoch 287/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1793 - accuracy: 0.7917 - val_loss: 2.2284 - val_accuracy: 0.7903\n",
      "Epoch 288/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1734 - accuracy: 0.7788 - val_loss: 2.2238 - val_accuracy: 0.7566\n",
      "Epoch 289/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1750 - accuracy: 0.7901 - val_loss: 2.2144 - val_accuracy: 0.7566\n",
      "Epoch 290/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1579 - accuracy: 0.7949 - val_loss: 2.2064 - val_accuracy: 0.7715\n",
      "Epoch 291/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1697 - accuracy: 0.7692 - val_loss: 2.2088 - val_accuracy: 0.7603\n",
      "Epoch 292/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1666 - accuracy: 0.7917 - val_loss: 2.2077 - val_accuracy: 0.7865\n",
      "Epoch 293/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1877 - accuracy: 0.7500 - val_loss: 2.2011 - val_accuracy: 0.7566\n",
      "Epoch 294/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1450 - accuracy: 0.7885 - val_loss: 2.1981 - val_accuracy: 0.7528\n",
      "Epoch 295/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1413 - accuracy: 0.8013 - val_loss: 2.1876 - val_accuracy: 0.7828\n",
      "Epoch 296/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1451 - accuracy: 0.7692 - val_loss: 2.1751 - val_accuracy: 0.7715\n",
      "Epoch 297/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1371 - accuracy: 0.7949 - val_loss: 2.1714 - val_accuracy: 0.7566\n",
      "Epoch 298/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1416 - accuracy: 0.7756 - val_loss: 2.1777 - val_accuracy: 0.7828\n",
      "Epoch 299/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1284 - accuracy: 0.7885 - val_loss: 2.1688 - val_accuracy: 0.7528\n",
      "Epoch 300/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1163 - accuracy: 0.7933 - val_loss: 2.1620 - val_accuracy: 0.7865\n",
      "Epoch 301/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1106 - accuracy: 0.7724 - val_loss: 2.1536 - val_accuracy: 0.7640\n",
      "Epoch 302/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.1098 - accuracy: 0.7949 - val_loss: 2.1383 - val_accuracy: 0.7715\n",
      "Epoch 303/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.1072 - accuracy: 0.7692 - val_loss: 2.1409 - val_accuracy: 0.7640\n",
      "Epoch 304/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0998 - accuracy: 0.7917 - val_loss: 2.1431 - val_accuracy: 0.7528\n",
      "Epoch 305/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0924 - accuracy: 0.7837 - val_loss: 2.1425 - val_accuracy: 0.7678\n",
      "Epoch 306/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0832 - accuracy: 0.7837 - val_loss: 2.1276 - val_accuracy: 0.7678\n",
      "Epoch 307/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0777 - accuracy: 0.7965 - val_loss: 2.1111 - val_accuracy: 0.7865\n",
      "Epoch 308/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0748 - accuracy: 0.7692 - val_loss: 2.1148 - val_accuracy: 0.7715\n",
      "Epoch 309/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0906 - accuracy: 0.7804 - val_loss: 2.1055 - val_accuracy: 0.7715\n",
      "Epoch 310/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0707 - accuracy: 0.7772 - val_loss: 2.1187 - val_accuracy: 0.7753\n",
      "Epoch 311/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0672 - accuracy: 0.7772 - val_loss: 2.1173 - val_accuracy: 0.7491\n",
      "Epoch 312/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0633 - accuracy: 0.7869 - val_loss: 2.1148 - val_accuracy: 0.7678\n",
      "Epoch 313/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0569 - accuracy: 0.7772 - val_loss: 2.0966 - val_accuracy: 0.7603\n",
      "Epoch 314/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0373 - accuracy: 0.8109 - val_loss: 2.0841 - val_accuracy: 0.7753\n",
      "Epoch 315/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 2.0556 - accuracy: 0.75 - 0s 16us/step - loss: 2.0329 - accuracy: 0.7853 - val_loss: 2.0795 - val_accuracy: 0.7715\n",
      "Epoch 316/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0317 - accuracy: 0.7885 - val_loss: 2.0842 - val_accuracy: 0.7603\n",
      "Epoch 317/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0345 - accuracy: 0.7949 - val_loss: 2.0751 - val_accuracy: 0.7640\n",
      "Epoch 318/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0220 - accuracy: 0.7885 - val_loss: 2.0698 - val_accuracy: 0.7715\n",
      "Epoch 319/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0158 - accuracy: 0.7901 - val_loss: 2.0578 - val_accuracy: 0.7715\n",
      "Epoch 320/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0127 - accuracy: 0.7804 - val_loss: 2.0484 - val_accuracy: 0.7940\n",
      "Epoch 321/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0094 - accuracy: 0.7965 - val_loss: 2.0428 - val_accuracy: 0.7903\n",
      "Epoch 322/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0109 - accuracy: 0.7869 - val_loss: 2.0399 - val_accuracy: 0.7790\n",
      "Epoch 323/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0147 - accuracy: 0.7772 - val_loss: 2.0431 - val_accuracy: 0.7678\n",
      "Epoch 324/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 2.0035 - accuracy: 0.7965 - val_loss: 2.0516 - val_accuracy: 0.7865\n",
      "Epoch 325/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 2.0093 - accuracy: 0.7724 - val_loss: 2.0483 - val_accuracy: 0.7416\n",
      "Epoch 326/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9920 - accuracy: 0.7917 - val_loss: 2.0430 - val_accuracy: 0.7416\n",
      "Epoch 327/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9833 - accuracy: 0.7965 - val_loss: 2.0295 - val_accuracy: 0.7603\n",
      "Epoch 328/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9720 - accuracy: 0.7997 - val_loss: 2.0134 - val_accuracy: 0.7865\n",
      "Epoch 329/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9690 - accuracy: 0.7853 - val_loss: 2.0110 - val_accuracy: 0.7753\n",
      "Epoch 330/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9687 - accuracy: 0.7933 - val_loss: 2.0101 - val_accuracy: 0.7790\n",
      "Epoch 331/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9654 - accuracy: 0.7869 - val_loss: 2.0107 - val_accuracy: 0.7566\n",
      "Epoch 332/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9763 - accuracy: 0.7837 - val_loss: 2.0080 - val_accuracy: 0.7603\n",
      "Epoch 333/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.9557 - accuracy: 0.7933 - val_loss: 2.0044 - val_accuracy: 0.7865\n",
      "Epoch 334/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9488 - accuracy: 0.7772 - val_loss: 2.0137 - val_accuracy: 0.7416\n",
      "Epoch 335/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9921 - accuracy: 0.7724 - val_loss: 1.9870 - val_accuracy: 0.7828\n",
      "Epoch 336/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9513 - accuracy: 0.7756 - val_loss: 1.9909 - val_accuracy: 0.7678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9519 - accuracy: 0.7724 - val_loss: 2.0069 - val_accuracy: 0.7378\n",
      "Epoch 338/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9635 - accuracy: 0.7580 - val_loss: 2.0173 - val_accuracy: 0.7453\n",
      "Epoch 339/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9476 - accuracy: 0.7756 - val_loss: 1.9932 - val_accuracy: 0.7416\n",
      "Epoch 340/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9308 - accuracy: 0.7981 - val_loss: 1.9780 - val_accuracy: 0.7491\n",
      "Epoch 341/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9162 - accuracy: 0.7933 - val_loss: 1.9709 - val_accuracy: 0.7753\n",
      "Epoch 342/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.9171 - accuracy: 0.7804 - val_loss: 1.9647 - val_accuracy: 0.7640\n",
      "Epoch 343/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.9177 - accuracy: 0.7933 - val_loss: 1.9544 - val_accuracy: 0.7940\n",
      "Epoch 344/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9187 - accuracy: 0.7708 - val_loss: 1.9500 - val_accuracy: 0.7790\n",
      "Epoch 345/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9169 - accuracy: 0.7804 - val_loss: 1.9500 - val_accuracy: 0.7753\n",
      "Epoch 346/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8914 - accuracy: 0.7965 - val_loss: 1.9690 - val_accuracy: 0.7715\n",
      "Epoch 347/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9168 - accuracy: 0.7692 - val_loss: 1.9488 - val_accuracy: 0.7603\n",
      "Epoch 348/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.9125 - accuracy: 0.7837 - val_loss: 1.9424 - val_accuracy: 0.7678\n",
      "Epoch 349/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8979 - accuracy: 0.7837 - val_loss: 1.9425 - val_accuracy: 0.7715\n",
      "Epoch 350/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8910 - accuracy: 0.7821 - val_loss: 1.9394 - val_accuracy: 0.7566\n",
      "Epoch 351/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8917 - accuracy: 0.7853 - val_loss: 1.9371 - val_accuracy: 0.7715\n",
      "Epoch 352/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8872 - accuracy: 0.7724 - val_loss: 1.9262 - val_accuracy: 0.7678\n",
      "Epoch 353/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8816 - accuracy: 0.7901 - val_loss: 1.9275 - val_accuracy: 0.7453\n",
      "Epoch 354/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8685 - accuracy: 0.7821 - val_loss: 1.9250 - val_accuracy: 0.7528\n",
      "Epoch 355/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8651 - accuracy: 0.7853 - val_loss: 1.9151 - val_accuracy: 0.7715\n",
      "Epoch 356/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8609 - accuracy: 0.7981 - val_loss: 1.9067 - val_accuracy: 0.7790\n",
      "Epoch 357/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8521 - accuracy: 0.7949 - val_loss: 1.8971 - val_accuracy: 0.7640\n",
      "Epoch 358/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8493 - accuracy: 0.7901 - val_loss: 1.8932 - val_accuracy: 0.7865\n",
      "Epoch 359/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8548 - accuracy: 0.7853 - val_loss: 1.8923 - val_accuracy: 0.7715\n",
      "Epoch 360/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8551 - accuracy: 0.7708 - val_loss: 1.8926 - val_accuracy: 0.7528\n",
      "Epoch 361/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8439 - accuracy: 0.7965 - val_loss: 1.8995 - val_accuracy: 0.7453\n",
      "Epoch 362/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8470 - accuracy: 0.7804 - val_loss: 1.8954 - val_accuracy: 0.7491\n",
      "Epoch 363/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8412 - accuracy: 0.7853 - val_loss: 1.8850 - val_accuracy: 0.7603\n",
      "Epoch 364/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8382 - accuracy: 0.7724 - val_loss: 1.8714 - val_accuracy: 0.7753\n",
      "Epoch 365/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.8208 - accuracy: 0.7772 - val_loss: 1.8713 - val_accuracy: 0.7678\n",
      "Epoch 366/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8229 - accuracy: 0.7917 - val_loss: 1.8666 - val_accuracy: 0.7903\n",
      "Epoch 367/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8216 - accuracy: 0.7708 - val_loss: 1.8632 - val_accuracy: 0.7753\n",
      "Epoch 368/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8130 - accuracy: 0.7981 - val_loss: 1.8617 - val_accuracy: 0.7640\n",
      "Epoch 369/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8089 - accuracy: 0.7885 - val_loss: 1.8579 - val_accuracy: 0.7603\n",
      "Epoch 370/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.8012 - accuracy: 0.8029 - val_loss: 1.8492 - val_accuracy: 0.7790\n",
      "Epoch 371/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7972 - accuracy: 0.8013 - val_loss: 1.8416 - val_accuracy: 0.7753\n",
      "Epoch 372/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7952 - accuracy: 0.7885 - val_loss: 1.8400 - val_accuracy: 0.7865\n",
      "Epoch 373/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7950 - accuracy: 0.8045 - val_loss: 1.8363 - val_accuracy: 0.7978\n",
      "Epoch 374/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8005 - accuracy: 0.7740 - val_loss: 1.8338 - val_accuracy: 0.7603\n",
      "Epoch 375/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 1.7914 - accuracy: 0.77 - 0s 14us/step - loss: 1.7918 - accuracy: 0.7917 - val_loss: 1.8317 - val_accuracy: 0.7566\n",
      "Epoch 376/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7803 - accuracy: 0.7788 - val_loss: 1.8279 - val_accuracy: 0.7715\n",
      "Epoch 377/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7790 - accuracy: 0.7885 - val_loss: 1.8258 - val_accuracy: 0.7715\n",
      "Epoch 378/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7756 - accuracy: 0.8013 - val_loss: 1.8313 - val_accuracy: 0.7790\n",
      "Epoch 379/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.8042 - accuracy: 0.7580 - val_loss: 1.8274 - val_accuracy: 0.7566\n",
      "Epoch 380/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7899 - accuracy: 0.7885 - val_loss: 1.8270 - val_accuracy: 0.7453\n",
      "Epoch 381/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7768 - accuracy: 0.7901 - val_loss: 1.8338 - val_accuracy: 0.7566\n",
      "Epoch 382/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7716 - accuracy: 0.7821 - val_loss: 1.8179 - val_accuracy: 0.7566\n",
      "Epoch 383/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7659 - accuracy: 0.8013 - val_loss: 1.8017 - val_accuracy: 0.7903\n",
      "Epoch 384/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7620 - accuracy: 0.7772 - val_loss: 1.7944 - val_accuracy: 0.7903\n",
      "Epoch 385/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7513 - accuracy: 0.7869 - val_loss: 1.7919 - val_accuracy: 0.7753\n",
      "Epoch 386/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7453 - accuracy: 0.7901 - val_loss: 1.7963 - val_accuracy: 0.7753\n",
      "Epoch 387/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7452 - accuracy: 0.7981 - val_loss: 1.7978 - val_accuracy: 0.7566\n",
      "Epoch 388/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7420 - accuracy: 0.7933 - val_loss: 1.7891 - val_accuracy: 0.7678\n",
      "Epoch 389/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7377 - accuracy: 0.7949 - val_loss: 1.7824 - val_accuracy: 0.7790\n",
      "Epoch 390/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7371 - accuracy: 0.7788 - val_loss: 1.7740 - val_accuracy: 0.7828\n",
      "Epoch 391/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7336 - accuracy: 0.7949 - val_loss: 1.7757 - val_accuracy: 0.7790\n",
      "Epoch 392/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7270 - accuracy: 0.7917 - val_loss: 1.7731 - val_accuracy: 0.7790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7226 - accuracy: 0.7917 - val_loss: 1.7672 - val_accuracy: 0.7865\n",
      "Epoch 394/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7176 - accuracy: 0.8029 - val_loss: 1.7605 - val_accuracy: 0.7753\n",
      "Epoch 395/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7171 - accuracy: 0.7917 - val_loss: 1.7627 - val_accuracy: 0.7790\n",
      "Epoch 396/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7156 - accuracy: 0.7917 - val_loss: 1.7623 - val_accuracy: 0.7566\n",
      "Epoch 397/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.7111 - accuracy: 0.8029 - val_loss: 1.7546 - val_accuracy: 0.7715\n",
      "Epoch 398/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7057 - accuracy: 0.7917 - val_loss: 1.7456 - val_accuracy: 0.7715\n",
      "Epoch 399/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7030 - accuracy: 0.7885 - val_loss: 1.7431 - val_accuracy: 0.7828\n",
      "Epoch 400/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.7046 - accuracy: 0.7756 - val_loss: 1.7448 - val_accuracy: 0.7865\n",
      "Epoch 401/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6972 - accuracy: 0.7949 - val_loss: 1.7457 - val_accuracy: 0.7640\n",
      "Epoch 402/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6913 - accuracy: 0.8029 - val_loss: 1.7403 - val_accuracy: 0.7903\n",
      "Epoch 403/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6926 - accuracy: 0.7837 - val_loss: 1.7325 - val_accuracy: 0.7865\n",
      "Epoch 404/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6868 - accuracy: 0.7965 - val_loss: 1.7375 - val_accuracy: 0.7678\n",
      "Epoch 405/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6883 - accuracy: 0.7949 - val_loss: 1.7452 - val_accuracy: 0.7453\n",
      "Epoch 406/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6899 - accuracy: 0.7804 - val_loss: 1.7392 - val_accuracy: 0.7453\n",
      "Epoch 407/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6854 - accuracy: 0.8045 - val_loss: 1.7253 - val_accuracy: 0.7640\n",
      "Epoch 408/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6789 - accuracy: 0.7869 - val_loss: 1.7189 - val_accuracy: 0.7903\n",
      "Epoch 409/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6882 - accuracy: 0.7917 - val_loss: 1.7136 - val_accuracy: 0.7790\n",
      "Epoch 410/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6705 - accuracy: 0.7837 - val_loss: 1.7133 - val_accuracy: 0.7828\n",
      "Epoch 411/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6657 - accuracy: 0.7869 - val_loss: 1.7184 - val_accuracy: 0.7678\n",
      "Epoch 412/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6677 - accuracy: 0.8013 - val_loss: 1.7126 - val_accuracy: 0.7753\n",
      "Epoch 413/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.6629 - accuracy: 0.7837 - val_loss: 1.7049 - val_accuracy: 0.7640\n",
      "Epoch 414/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6670 - accuracy: 0.7821 - val_loss: 1.7083 - val_accuracy: 0.7678\n",
      "Epoch 415/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6547 - accuracy: 0.8045 - val_loss: 1.7079 - val_accuracy: 0.7865\n",
      "Epoch 416/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6597 - accuracy: 0.7788 - val_loss: 1.6973 - val_accuracy: 0.7828\n",
      "Epoch 417/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6525 - accuracy: 0.8029 - val_loss: 1.7049 - val_accuracy: 0.7828\n",
      "Epoch 418/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.6827 - accuracy: 0.7500 - val_loss: 1.7005 - val_accuracy: 0.7603\n",
      "Epoch 419/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6633 - accuracy: 0.7917 - val_loss: 1.6915 - val_accuracy: 0.7566\n",
      "Epoch 420/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6679 - accuracy: 0.7756 - val_loss: 1.6885 - val_accuracy: 0.7603\n",
      "Epoch 421/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6412 - accuracy: 0.7933 - val_loss: 1.6796 - val_accuracy: 0.7640\n",
      "Epoch 422/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6483 - accuracy: 0.7869 - val_loss: 1.6772 - val_accuracy: 0.7828\n",
      "Epoch 423/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6557 - accuracy: 0.7869 - val_loss: 1.6738 - val_accuracy: 0.7640\n",
      "Epoch 424/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6348 - accuracy: 0.7804 - val_loss: 1.6898 - val_accuracy: 0.7865\n",
      "Epoch 425/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6420 - accuracy: 0.7853 - val_loss: 1.6853 - val_accuracy: 0.7603\n",
      "Epoch 426/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.6332 - accuracy: 0.7901 - val_loss: 1.6828 - val_accuracy: 0.7865\n",
      "Epoch 427/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.6381 - accuracy: 0.7724 - val_loss: 1.6705 - val_accuracy: 0.7715\n",
      "Epoch 428/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 1.6564 - accuracy: 0.76 - 0s 14us/step - loss: 1.6199 - accuracy: 0.8077 - val_loss: 1.6785 - val_accuracy: 0.7753\n",
      "Epoch 429/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6348 - accuracy: 0.7676 - val_loss: 1.6711 - val_accuracy: 0.7678\n",
      "Epoch 430/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6312 - accuracy: 0.7853 - val_loss: 1.6662 - val_accuracy: 0.7678\n",
      "Epoch 431/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6203 - accuracy: 0.7772 - val_loss: 1.6581 - val_accuracy: 0.7603\n",
      "Epoch 432/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6298 - accuracy: 0.7724 - val_loss: 1.6469 - val_accuracy: 0.7940\n",
      "Epoch 433/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6085 - accuracy: 0.7708 - val_loss: 1.6756 - val_accuracy: 0.7828\n",
      "Epoch 434/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6198 - accuracy: 0.7724 - val_loss: 1.6657 - val_accuracy: 0.7640\n",
      "Epoch 435/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6212 - accuracy: 0.8013 - val_loss: 1.6436 - val_accuracy: 0.7978\n",
      "Epoch 436/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6061 - accuracy: 0.7788 - val_loss: 1.6500 - val_accuracy: 0.7566\n",
      "Epoch 437/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.6091 - accuracy: 0.7869 - val_loss: 1.6460 - val_accuracy: 0.7790\n",
      "Epoch 438/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.6055 - accuracy: 0.7756 - val_loss: 1.6411 - val_accuracy: 0.7790\n",
      "Epoch 439/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5950 - accuracy: 0.7997 - val_loss: 1.6369 - val_accuracy: 0.7566\n",
      "Epoch 440/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5888 - accuracy: 0.7869 - val_loss: 1.6336 - val_accuracy: 0.7828\n",
      "Epoch 441/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5852 - accuracy: 0.7885 - val_loss: 1.6375 - val_accuracy: 0.7715\n",
      "Epoch 442/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5829 - accuracy: 0.8013 - val_loss: 1.6296 - val_accuracy: 0.7940\n",
      "Epoch 443/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5867 - accuracy: 0.7772 - val_loss: 1.6261 - val_accuracy: 0.7790\n",
      "Epoch 444/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5781 - accuracy: 0.8061 - val_loss: 1.6157 - val_accuracy: 0.7640\n",
      "Epoch 445/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5701 - accuracy: 0.7965 - val_loss: 1.6086 - val_accuracy: 0.7753\n",
      "Epoch 446/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.5713 - accuracy: 0.7901 - val_loss: 1.6084 - val_accuracy: 0.7940\n",
      "Epoch 447/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5749 - accuracy: 0.7756 - val_loss: 1.6079 - val_accuracy: 0.7678\n",
      "Epoch 448/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5712 - accuracy: 0.7965 - val_loss: 1.6061 - val_accuracy: 0.7640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.5740 - accuracy: 0.7821 - val_loss: 1.6083 - val_accuracy: 0.7715\n",
      "Epoch 450/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5611 - accuracy: 0.8045 - val_loss: 1.6035 - val_accuracy: 0.7715\n",
      "Epoch 451/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5689 - accuracy: 0.7756 - val_loss: 1.5957 - val_accuracy: 0.7715\n",
      "Epoch 452/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5544 - accuracy: 0.8077 - val_loss: 1.6010 - val_accuracy: 0.7715\n",
      "Epoch 453/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.5570 - accuracy: 0.7885 - val_loss: 1.5952 - val_accuracy: 0.7978\n",
      "Epoch 454/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5503 - accuracy: 0.7981 - val_loss: 1.6058 - val_accuracy: 0.7603\n",
      "Epoch 455/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5538 - accuracy: 0.7981 - val_loss: 1.5975 - val_accuracy: 0.7828\n",
      "Epoch 456/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5453 - accuracy: 0.7901 - val_loss: 1.5904 - val_accuracy: 0.7790\n",
      "Epoch 457/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5464 - accuracy: 0.7965 - val_loss: 1.5779 - val_accuracy: 0.7715\n",
      "Epoch 458/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 1.5231 - accuracy: 0.80 - 0s 14us/step - loss: 1.5380 - accuracy: 0.7949 - val_loss: 1.5855 - val_accuracy: 0.7603\n",
      "Epoch 459/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5379 - accuracy: 0.7981 - val_loss: 1.5865 - val_accuracy: 0.7865\n",
      "Epoch 460/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5397 - accuracy: 0.7965 - val_loss: 1.5823 - val_accuracy: 0.7865\n",
      "Epoch 461/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5340 - accuracy: 0.8061 - val_loss: 1.5731 - val_accuracy: 0.8052\n",
      "Epoch 462/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5308 - accuracy: 0.7837 - val_loss: 1.5715 - val_accuracy: 0.7903\n",
      "Epoch 463/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5307 - accuracy: 0.8013 - val_loss: 1.5683 - val_accuracy: 0.7715\n",
      "Epoch 464/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5271 - accuracy: 0.7885 - val_loss: 1.5700 - val_accuracy: 0.7715\n",
      "Epoch 465/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5266 - accuracy: 0.7949 - val_loss: 1.5768 - val_accuracy: 0.7491\n",
      "Epoch 466/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5390 - accuracy: 0.7837 - val_loss: 1.5736 - val_accuracy: 0.7640\n",
      "Epoch 467/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5240 - accuracy: 0.7804 - val_loss: 1.5817 - val_accuracy: 0.7603\n",
      "Epoch 468/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5287 - accuracy: 0.7901 - val_loss: 1.5707 - val_accuracy: 0.7678\n",
      "Epoch 469/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5212 - accuracy: 0.7965 - val_loss: 1.5532 - val_accuracy: 0.7940\n",
      "Epoch 470/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5128 - accuracy: 0.7949 - val_loss: 1.5470 - val_accuracy: 0.7978\n",
      "Epoch 471/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5084 - accuracy: 0.7917 - val_loss: 1.5473 - val_accuracy: 0.7940\n",
      "Epoch 472/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5061 - accuracy: 0.7853 - val_loss: 1.5492 - val_accuracy: 0.7903\n",
      "Epoch 473/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5050 - accuracy: 0.7997 - val_loss: 1.5483 - val_accuracy: 0.7903\n",
      "Epoch 474/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5037 - accuracy: 0.7821 - val_loss: 1.5489 - val_accuracy: 0.7715\n",
      "Epoch 475/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5070 - accuracy: 0.7997 - val_loss: 1.5468 - val_accuracy: 0.7903\n",
      "Epoch 476/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5365 - accuracy: 0.7628 - val_loss: 1.5505 - val_accuracy: 0.7715\n",
      "Epoch 477/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5406 - accuracy: 0.7708 - val_loss: 1.5579 - val_accuracy: 0.7528\n",
      "Epoch 478/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5130 - accuracy: 0.7788 - val_loss: 1.5777 - val_accuracy: 0.7603\n",
      "Epoch 479/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5189 - accuracy: 0.7676 - val_loss: 1.5630 - val_accuracy: 0.7453\n",
      "Epoch 480/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5163 - accuracy: 0.7837 - val_loss: 1.5484 - val_accuracy: 0.7865\n",
      "Epoch 481/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5265 - accuracy: 0.7548 - val_loss: 1.5402 - val_accuracy: 0.7528\n",
      "Epoch 482/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5313 - accuracy: 0.7740 - val_loss: 1.5695 - val_accuracy: 0.7341\n",
      "Epoch 483/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5140 - accuracy: 0.7740 - val_loss: 1.5964 - val_accuracy: 0.7491\n",
      "Epoch 484/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.5426 - accuracy: 0.7548 - val_loss: 1.5470 - val_accuracy: 0.7416\n",
      "Epoch 485/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5230 - accuracy: 0.7596 - val_loss: 1.5454 - val_accuracy: 0.7528\n",
      "Epoch 486/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4986 - accuracy: 0.7708 - val_loss: 1.5514 - val_accuracy: 0.7678\n",
      "Epoch 487/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.5024 - accuracy: 0.7628 - val_loss: 1.5441 - val_accuracy: 0.7453\n",
      "Epoch 488/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4985 - accuracy: 0.7821 - val_loss: 1.5285 - val_accuracy: 0.7865\n",
      "Epoch 489/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4975 - accuracy: 0.7644 - val_loss: 1.5266 - val_accuracy: 0.7715\n",
      "Epoch 490/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.4796 - accuracy: 0.7853 - val_loss: 1.5355 - val_accuracy: 0.7566\n",
      "Epoch 491/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4871 - accuracy: 0.7740 - val_loss: 1.5213 - val_accuracy: 0.7865\n",
      "Epoch 492/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4837 - accuracy: 0.7692 - val_loss: 1.5200 - val_accuracy: 0.7715\n",
      "Epoch 493/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4855 - accuracy: 0.7853 - val_loss: 1.5138 - val_accuracy: 0.7603\n",
      "Epoch 494/750\n",
      "624/624 [==============================] - 0s 15us/step - loss: 1.4634 - accuracy: 0.7917 - val_loss: 1.5199 - val_accuracy: 0.7790\n",
      "Epoch 495/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4716 - accuracy: 0.7821 - val_loss: 1.5176 - val_accuracy: 0.7566\n",
      "Epoch 496/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4666 - accuracy: 0.7965 - val_loss: 1.5024 - val_accuracy: 0.7678\n",
      "Epoch 497/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4595 - accuracy: 0.7853 - val_loss: 1.4921 - val_accuracy: 0.7865\n",
      "Epoch 498/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4535 - accuracy: 0.7997 - val_loss: 1.4989 - val_accuracy: 0.7828\n",
      "Epoch 499/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4517 - accuracy: 0.7997 - val_loss: 1.4943 - val_accuracy: 0.8015\n",
      "Epoch 500/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4588 - accuracy: 0.7724 - val_loss: 1.4918 - val_accuracy: 0.7903\n",
      "Epoch 501/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4558 - accuracy: 0.7901 - val_loss: 1.4893 - val_accuracy: 0.7715\n",
      "Epoch 502/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4583 - accuracy: 0.7756 - val_loss: 1.4976 - val_accuracy: 0.7753\n",
      "Epoch 503/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4484 - accuracy: 0.8013 - val_loss: 1.5170 - val_accuracy: 0.7491\n",
      "Epoch 504/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4634 - accuracy: 0.7804 - val_loss: 1.5107 - val_accuracy: 0.7678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/750\n",
      "624/624 [==============================] - 0s 15us/step - loss: 1.4689 - accuracy: 0.7708 - val_loss: 1.4912 - val_accuracy: 0.7528\n",
      "Epoch 506/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4407 - accuracy: 0.8029 - val_loss: 1.4901 - val_accuracy: 0.7566\n",
      "Epoch 507/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4436 - accuracy: 0.7901 - val_loss: 1.4835 - val_accuracy: 0.7903\n",
      "Epoch 508/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4403 - accuracy: 0.7917 - val_loss: 1.4832 - val_accuracy: 0.7640\n",
      "Epoch 509/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4333 - accuracy: 0.8013 - val_loss: 1.4776 - val_accuracy: 0.7640\n",
      "Epoch 510/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4279 - accuracy: 0.7949 - val_loss: 1.4763 - val_accuracy: 0.7715\n",
      "Epoch 511/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4271 - accuracy: 0.7965 - val_loss: 1.4709 - val_accuracy: 0.7715\n",
      "Epoch 512/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4243 - accuracy: 0.7917 - val_loss: 1.4670 - val_accuracy: 0.7678\n",
      "Epoch 513/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4213 - accuracy: 0.7965 - val_loss: 1.4628 - val_accuracy: 0.7828\n",
      "Epoch 514/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4205 - accuracy: 0.7901 - val_loss: 1.4613 - val_accuracy: 0.7715\n",
      "Epoch 515/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 1.4433 - accuracy: 0.78 - 0s 14us/step - loss: 1.4180 - accuracy: 0.7901 - val_loss: 1.4615 - val_accuracy: 0.7678\n",
      "Epoch 516/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4175 - accuracy: 0.7901 - val_loss: 1.4631 - val_accuracy: 0.7790\n",
      "Epoch 517/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4119 - accuracy: 0.7981 - val_loss: 1.4649 - val_accuracy: 0.7640\n",
      "Epoch 518/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4128 - accuracy: 0.8045 - val_loss: 1.4538 - val_accuracy: 0.7828\n",
      "Epoch 519/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4175 - accuracy: 0.7788 - val_loss: 1.4652 - val_accuracy: 0.7640\n",
      "Epoch 520/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4189 - accuracy: 0.7997 - val_loss: 1.4570 - val_accuracy: 0.7640\n",
      "Epoch 521/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4085 - accuracy: 0.7949 - val_loss: 1.4472 - val_accuracy: 0.7678\n",
      "Epoch 522/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4097 - accuracy: 0.8013 - val_loss: 1.4443 - val_accuracy: 0.7678\n",
      "Epoch 523/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4025 - accuracy: 0.7901 - val_loss: 1.4428 - val_accuracy: 0.7678\n",
      "Epoch 524/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4049 - accuracy: 0.7997 - val_loss: 1.4426 - val_accuracy: 0.7640\n",
      "Epoch 525/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.4018 - accuracy: 0.7853 - val_loss: 1.4497 - val_accuracy: 0.7903\n",
      "Epoch 526/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3994 - accuracy: 0.7885 - val_loss: 1.4607 - val_accuracy: 0.7640\n",
      "Epoch 527/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.4143 - accuracy: 0.7901 - val_loss: 1.4357 - val_accuracy: 0.7940\n",
      "Epoch 528/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3971 - accuracy: 0.7788 - val_loss: 1.4344 - val_accuracy: 0.7753\n",
      "Epoch 529/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3887 - accuracy: 0.7981 - val_loss: 1.4382 - val_accuracy: 0.7865\n",
      "Epoch 530/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3935 - accuracy: 0.7917 - val_loss: 1.4353 - val_accuracy: 0.7678\n",
      "Epoch 531/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3930 - accuracy: 0.7981 - val_loss: 1.4283 - val_accuracy: 0.7678\n",
      "Epoch 532/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.4015 - accuracy: 0.7853 - val_loss: 1.4371 - val_accuracy: 0.7715\n",
      "Epoch 533/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3923 - accuracy: 0.7965 - val_loss: 1.4379 - val_accuracy: 0.7790\n",
      "Epoch 534/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3866 - accuracy: 0.7933 - val_loss: 1.4299 - val_accuracy: 0.7828\n",
      "Epoch 535/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3849 - accuracy: 0.7997 - val_loss: 1.4255 - val_accuracy: 0.7865\n",
      "Epoch 536/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3827 - accuracy: 0.7933 - val_loss: 1.4189 - val_accuracy: 0.7865\n",
      "Epoch 537/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.3830 - accuracy: 0.7981 - val_loss: 1.4198 - val_accuracy: 0.7903\n",
      "Epoch 538/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3787 - accuracy: 0.7869 - val_loss: 1.4169 - val_accuracy: 0.7790\n",
      "Epoch 539/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.3777 - accuracy: 0.8029 - val_loss: 1.4192 - val_accuracy: 0.7790\n",
      "Epoch 540/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3682 - accuracy: 0.7917 - val_loss: 1.4156 - val_accuracy: 0.7790\n",
      "Epoch 541/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3712 - accuracy: 0.7821 - val_loss: 1.4178 - val_accuracy: 0.7790\n",
      "Epoch 542/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.3683 - accuracy: 0.7981 - val_loss: 1.4107 - val_accuracy: 0.7678\n",
      "Epoch 543/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.3632 - accuracy: 0.8013 - val_loss: 1.4194 - val_accuracy: 0.7715\n",
      "Epoch 544/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3712 - accuracy: 0.7997 - val_loss: 1.4053 - val_accuracy: 0.7828\n",
      "Epoch 545/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.3637 - accuracy: 0.7917 - val_loss: 1.3992 - val_accuracy: 0.7940\n",
      "Epoch 546/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3604 - accuracy: 0.7901 - val_loss: 1.4046 - val_accuracy: 0.7865\n",
      "Epoch 547/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3651 - accuracy: 0.8013 - val_loss: 1.4145 - val_accuracy: 0.7528\n",
      "Epoch 548/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3631 - accuracy: 0.7869 - val_loss: 1.4161 - val_accuracy: 0.7640\n",
      "Epoch 549/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.3613 - accuracy: 0.7853 - val_loss: 1.4057 - val_accuracy: 0.7715\n",
      "Epoch 550/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3586 - accuracy: 0.7981 - val_loss: 1.3891 - val_accuracy: 0.7903\n",
      "Epoch 551/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3543 - accuracy: 0.7821 - val_loss: 1.3863 - val_accuracy: 0.8090\n",
      "Epoch 552/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3540 - accuracy: 0.7949 - val_loss: 1.3849 - val_accuracy: 0.7828\n",
      "Epoch 553/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3570 - accuracy: 0.7772 - val_loss: 1.3886 - val_accuracy: 0.7678\n",
      "Epoch 554/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3517 - accuracy: 0.7885 - val_loss: 1.3888 - val_accuracy: 0.7678\n",
      "Epoch 555/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3499 - accuracy: 0.7788 - val_loss: 1.3873 - val_accuracy: 0.7678\n",
      "Epoch 556/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3404 - accuracy: 0.7997 - val_loss: 1.3926 - val_accuracy: 0.7753\n",
      "Epoch 557/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3394 - accuracy: 0.8013 - val_loss: 1.4045 - val_accuracy: 0.7753\n",
      "Epoch 558/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3599 - accuracy: 0.7660 - val_loss: 1.4049 - val_accuracy: 0.7603\n",
      "Epoch 559/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3574 - accuracy: 0.7901 - val_loss: 1.3953 - val_accuracy: 0.7828\n",
      "Epoch 560/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3619 - accuracy: 0.7740 - val_loss: 1.3872 - val_accuracy: 0.7603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3451 - accuracy: 0.7949 - val_loss: 1.3753 - val_accuracy: 0.7715\n",
      "Epoch 562/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3338 - accuracy: 0.7885 - val_loss: 1.3813 - val_accuracy: 0.8015\n",
      "Epoch 563/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3403 - accuracy: 0.7965 - val_loss: 1.3785 - val_accuracy: 0.7753\n",
      "Epoch 564/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3371 - accuracy: 0.7772 - val_loss: 1.3794 - val_accuracy: 0.7940\n",
      "Epoch 565/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3278 - accuracy: 0.7933 - val_loss: 1.3850 - val_accuracy: 0.7753\n",
      "Epoch 566/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3304 - accuracy: 0.8109 - val_loss: 1.3746 - val_accuracy: 0.7940\n",
      "Epoch 567/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3396 - accuracy: 0.7692 - val_loss: 1.3830 - val_accuracy: 0.7678\n",
      "Epoch 568/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3425 - accuracy: 0.7981 - val_loss: 1.3668 - val_accuracy: 0.7678\n",
      "Epoch 569/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3211 - accuracy: 0.8013 - val_loss: 1.3582 - val_accuracy: 0.7828\n",
      "Epoch 570/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3233 - accuracy: 0.7869 - val_loss: 1.3718 - val_accuracy: 0.7790\n",
      "Epoch 571/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3350 - accuracy: 0.7981 - val_loss: 1.3693 - val_accuracy: 0.7865\n",
      "Epoch 572/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3439 - accuracy: 0.7788 - val_loss: 1.3730 - val_accuracy: 0.7528\n",
      "Epoch 573/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3333 - accuracy: 0.7901 - val_loss: 1.3712 - val_accuracy: 0.7678\n",
      "Epoch 574/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3418 - accuracy: 0.7724 - val_loss: 1.3676 - val_accuracy: 0.7903\n",
      "Epoch 575/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3435 - accuracy: 0.7804 - val_loss: 1.3725 - val_accuracy: 0.7715\n",
      "Epoch 576/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3273 - accuracy: 0.7692 - val_loss: 1.3807 - val_accuracy: 0.7753\n",
      "Epoch 577/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3226 - accuracy: 0.7788 - val_loss: 1.3873 - val_accuracy: 0.7453\n",
      "Epoch 578/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3428 - accuracy: 0.7724 - val_loss: 1.3873 - val_accuracy: 0.7566\n",
      "Epoch 579/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3336 - accuracy: 0.7772 - val_loss: 1.3795 - val_accuracy: 0.7640\n",
      "Epoch 580/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3120 - accuracy: 0.7933 - val_loss: 1.3694 - val_accuracy: 0.7640\n",
      "Epoch 581/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3124 - accuracy: 0.7933 - val_loss: 1.3595 - val_accuracy: 0.7903\n",
      "Epoch 582/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3168 - accuracy: 0.7644 - val_loss: 1.3607 - val_accuracy: 0.7640\n",
      "Epoch 583/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3127 - accuracy: 0.8029 - val_loss: 1.3510 - val_accuracy: 0.7903\n",
      "Epoch 584/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.3069 - accuracy: 0.7837 - val_loss: 1.3531 - val_accuracy: 0.7753\n",
      "Epoch 585/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2992 - accuracy: 0.8077 - val_loss: 1.3440 - val_accuracy: 0.7828\n",
      "Epoch 586/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.3003 - accuracy: 0.7885 - val_loss: 1.3445 - val_accuracy: 0.7940\n",
      "Epoch 587/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2983 - accuracy: 0.7981 - val_loss: 1.3407 - val_accuracy: 0.7903\n",
      "Epoch 588/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.2937 - accuracy: 0.7933 - val_loss: 1.3388 - val_accuracy: 0.7678\n",
      "Epoch 589/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2917 - accuracy: 0.7901 - val_loss: 1.3401 - val_accuracy: 0.7753\n",
      "Epoch 590/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2944 - accuracy: 0.7997 - val_loss: 1.3350 - val_accuracy: 0.7753\n",
      "Epoch 591/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2977 - accuracy: 0.7804 - val_loss: 1.3425 - val_accuracy: 0.7678\n",
      "Epoch 592/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.2936 - accuracy: 0.8029 - val_loss: 1.3454 - val_accuracy: 0.7566\n",
      "Epoch 593/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2913 - accuracy: 0.7965 - val_loss: 1.3346 - val_accuracy: 0.7753\n",
      "Epoch 594/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2857 - accuracy: 0.8013 - val_loss: 1.3271 - val_accuracy: 0.7865\n",
      "Epoch 595/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2855 - accuracy: 0.7997 - val_loss: 1.3197 - val_accuracy: 0.8090\n",
      "Epoch 596/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2820 - accuracy: 0.7901 - val_loss: 1.3217 - val_accuracy: 0.7828\n",
      "Epoch 597/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2784 - accuracy: 0.7853 - val_loss: 1.3248 - val_accuracy: 0.7715\n",
      "Epoch 598/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2758 - accuracy: 0.8013 - val_loss: 1.3273 - val_accuracy: 0.7640\n",
      "Epoch 599/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2784 - accuracy: 0.7965 - val_loss: 1.3287 - val_accuracy: 0.7678\n",
      "Epoch 600/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2756 - accuracy: 0.8029 - val_loss: 1.3281 - val_accuracy: 0.7566\n",
      "Epoch 601/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2729 - accuracy: 0.7997 - val_loss: 1.3211 - val_accuracy: 0.7640\n",
      "Epoch 602/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2743 - accuracy: 0.8029 - val_loss: 1.3189 - val_accuracy: 0.7640\n",
      "Epoch 603/750\n",
      "624/624 [==============================] - 0s 15us/step - loss: 1.2727 - accuracy: 0.7981 - val_loss: 1.3331 - val_accuracy: 0.7453\n",
      "Epoch 604/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2792 - accuracy: 0.7933 - val_loss: 1.3330 - val_accuracy: 0.7528\n",
      "Epoch 605/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2745 - accuracy: 0.7885 - val_loss: 1.3134 - val_accuracy: 0.7903\n",
      "Epoch 606/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 1.2702 - accuracy: 0.78 - 0s 16us/step - loss: 1.2676 - accuracy: 0.7917 - val_loss: 1.3124 - val_accuracy: 0.7903\n",
      "Epoch 607/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2721 - accuracy: 0.7885 - val_loss: 1.3091 - val_accuracy: 0.7903\n",
      "Epoch 608/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2661 - accuracy: 0.8077 - val_loss: 1.3200 - val_accuracy: 0.7640\n",
      "Epoch 609/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2657 - accuracy: 0.8061 - val_loss: 1.3208 - val_accuracy: 0.7640\n",
      "Epoch 610/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2646 - accuracy: 0.8045 - val_loss: 1.3063 - val_accuracy: 0.7753\n",
      "Epoch 611/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2632 - accuracy: 0.7901 - val_loss: 1.3122 - val_accuracy: 0.7753\n",
      "Epoch 612/750\n",
      "624/624 [==============================] - 0s 17us/step - loss: 1.2780 - accuracy: 0.7981 - val_loss: 1.3016 - val_accuracy: 0.7828\n",
      "Epoch 613/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2738 - accuracy: 0.7724 - val_loss: 1.3041 - val_accuracy: 0.7678\n",
      "Epoch 614/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2594 - accuracy: 0.7965 - val_loss: 1.3005 - val_accuracy: 0.7678\n",
      "Epoch 615/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2577 - accuracy: 0.7837 - val_loss: 1.2998 - val_accuracy: 0.7828\n",
      "Epoch 616/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2512 - accuracy: 0.8061 - val_loss: 1.3072 - val_accuracy: 0.7715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2586 - accuracy: 0.7869 - val_loss: 1.3039 - val_accuracy: 0.7940\n",
      "Epoch 618/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2561 - accuracy: 0.7772 - val_loss: 1.3077 - val_accuracy: 0.7715\n",
      "Epoch 619/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2528 - accuracy: 0.8013 - val_loss: 1.3008 - val_accuracy: 0.7940\n",
      "Epoch 620/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2551 - accuracy: 0.7772 - val_loss: 1.3038 - val_accuracy: 0.7678\n",
      "Epoch 621/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2678 - accuracy: 0.7965 - val_loss: 1.2841 - val_accuracy: 0.7978\n",
      "Epoch 622/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2494 - accuracy: 0.7821 - val_loss: 1.2860 - val_accuracy: 0.7790\n",
      "Epoch 623/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2444 - accuracy: 0.8013 - val_loss: 1.2872 - val_accuracy: 0.7865\n",
      "Epoch 624/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2402 - accuracy: 0.8045 - val_loss: 1.2867 - val_accuracy: 0.7865\n",
      "Epoch 625/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2466 - accuracy: 0.7949 - val_loss: 1.2834 - val_accuracy: 0.7790\n",
      "Epoch 626/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2426 - accuracy: 0.7901 - val_loss: 1.2935 - val_accuracy: 0.7715\n",
      "Epoch 627/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2459 - accuracy: 0.7965 - val_loss: 1.2975 - val_accuracy: 0.7566\n",
      "Epoch 628/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2451 - accuracy: 0.7917 - val_loss: 1.2907 - val_accuracy: 0.7566\n",
      "Epoch 629/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2337 - accuracy: 0.8093 - val_loss: 1.2888 - val_accuracy: 0.7753\n",
      "Epoch 630/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.2417 - accuracy: 0.8061 - val_loss: 1.2710 - val_accuracy: 0.7940\n",
      "Epoch 631/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2346 - accuracy: 0.7997 - val_loss: 1.2888 - val_accuracy: 0.7753\n",
      "Epoch 632/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2389 - accuracy: 0.8013 - val_loss: 1.2825 - val_accuracy: 0.7903\n",
      "Epoch 633/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2399 - accuracy: 0.7788 - val_loss: 1.2867 - val_accuracy: 0.7715\n",
      "Epoch 634/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2359 - accuracy: 0.8045 - val_loss: 1.2659 - val_accuracy: 0.7865\n",
      "Epoch 635/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2381 - accuracy: 0.7837 - val_loss: 1.2695 - val_accuracy: 0.7940\n",
      "Epoch 636/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2424 - accuracy: 0.7965 - val_loss: 1.2864 - val_accuracy: 0.7865\n",
      "Epoch 637/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2475 - accuracy: 0.7804 - val_loss: 1.2864 - val_accuracy: 0.7528\n",
      "Epoch 638/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2418 - accuracy: 0.7885 - val_loss: 1.2824 - val_accuracy: 0.7528\n",
      "Epoch 639/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2405 - accuracy: 0.7837 - val_loss: 1.2656 - val_accuracy: 0.7715\n",
      "Epoch 640/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2437 - accuracy: 0.7997 - val_loss: 1.2625 - val_accuracy: 0.7865\n",
      "Epoch 641/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2398 - accuracy: 0.7740 - val_loss: 1.2629 - val_accuracy: 0.7790\n",
      "Epoch 642/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.2298 - accuracy: 0.7917 - val_loss: 1.2746 - val_accuracy: 0.7715\n",
      "Epoch 643/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2312 - accuracy: 0.7804 - val_loss: 1.2717 - val_accuracy: 0.7903\n",
      "Epoch 644/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2204 - accuracy: 0.7965 - val_loss: 1.2761 - val_accuracy: 0.7640\n",
      "Epoch 645/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2229 - accuracy: 0.8045 - val_loss: 1.2636 - val_accuracy: 0.8052\n",
      "Epoch 646/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2212 - accuracy: 0.7788 - val_loss: 1.2581 - val_accuracy: 0.7903\n",
      "Epoch 647/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2161 - accuracy: 0.7965 - val_loss: 1.2571 - val_accuracy: 0.7903\n",
      "Epoch 648/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2160 - accuracy: 0.7917 - val_loss: 1.2614 - val_accuracy: 0.7865\n",
      "Epoch 649/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.2110 - accuracy: 0.8013 - val_loss: 1.2663 - val_accuracy: 0.7640\n",
      "Epoch 650/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2139 - accuracy: 0.7981 - val_loss: 1.2608 - val_accuracy: 0.7640\n",
      "Epoch 651/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.2088 - accuracy: 0.8077 - val_loss: 1.2499 - val_accuracy: 0.7715\n",
      "Epoch 652/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2045 - accuracy: 0.8013 - val_loss: 1.2475 - val_accuracy: 0.7678\n",
      "Epoch 653/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.2114 - accuracy: 0.7917 - val_loss: 1.2465 - val_accuracy: 0.7715\n",
      "Epoch 654/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2051 - accuracy: 0.7981 - val_loss: 1.2493 - val_accuracy: 0.7715\n",
      "Epoch 655/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2074 - accuracy: 0.8061 - val_loss: 1.2494 - val_accuracy: 0.7790\n",
      "Epoch 656/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2016 - accuracy: 0.7997 - val_loss: 1.2445 - val_accuracy: 0.7715\n",
      "Epoch 657/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1984 - accuracy: 0.8061 - val_loss: 1.2502 - val_accuracy: 0.7865\n",
      "Epoch 658/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.2030 - accuracy: 0.8029 - val_loss: 1.2406 - val_accuracy: 0.7903\n",
      "Epoch 659/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.2063 - accuracy: 0.7869 - val_loss: 1.2369 - val_accuracy: 0.7940\n",
      "Epoch 660/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1967 - accuracy: 0.8013 - val_loss: 1.2352 - val_accuracy: 0.7865\n",
      "Epoch 661/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1941 - accuracy: 0.8045 - val_loss: 1.2372 - val_accuracy: 0.8015\n",
      "Epoch 662/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1934 - accuracy: 0.7997 - val_loss: 1.2327 - val_accuracy: 0.7790\n",
      "Epoch 663/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1978 - accuracy: 0.7869 - val_loss: 1.2512 - val_accuracy: 0.7678\n",
      "Epoch 664/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2016 - accuracy: 0.8029 - val_loss: 1.2392 - val_accuracy: 0.7940\n",
      "Epoch 665/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1972 - accuracy: 0.7853 - val_loss: 1.2385 - val_accuracy: 0.7865\n",
      "Epoch 666/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1916 - accuracy: 0.8061 - val_loss: 1.2312 - val_accuracy: 0.7790\n",
      "Epoch 667/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2009 - accuracy: 0.7772 - val_loss: 1.2473 - val_accuracy: 0.7678\n",
      "Epoch 668/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1957 - accuracy: 0.8061 - val_loss: 1.2412 - val_accuracy: 0.7865\n",
      "Epoch 669/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2087 - accuracy: 0.7756 - val_loss: 1.2394 - val_accuracy: 0.7790\n",
      "Epoch 670/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1994 - accuracy: 0.7965 - val_loss: 1.2397 - val_accuracy: 0.7865\n",
      "Epoch 671/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.2284 - accuracy: 0.7596 - val_loss: 1.2254 - val_accuracy: 0.7790\n",
      "Epoch 672/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1933 - accuracy: 0.8029 - val_loss: 1.2404 - val_accuracy: 0.7678\n",
      "Epoch 673/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1939 - accuracy: 0.7933 - val_loss: 1.2334 - val_accuracy: 0.7978\n",
      "Epoch 674/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1901 - accuracy: 0.7853 - val_loss: 1.2340 - val_accuracy: 0.7790\n",
      "Epoch 675/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1894 - accuracy: 0.7885 - val_loss: 1.2170 - val_accuracy: 0.7865\n",
      "Epoch 676/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1790 - accuracy: 0.8029 - val_loss: 1.2207 - val_accuracy: 0.7978\n",
      "Epoch 677/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1808 - accuracy: 0.7997 - val_loss: 1.2175 - val_accuracy: 0.7678\n",
      "Epoch 678/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1779 - accuracy: 0.7997 - val_loss: 1.2268 - val_accuracy: 0.7715\n",
      "Epoch 679/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1753 - accuracy: 0.8029 - val_loss: 1.2201 - val_accuracy: 0.7978\n",
      "Epoch 680/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1795 - accuracy: 0.7901 - val_loss: 1.2151 - val_accuracy: 0.7753\n",
      "Epoch 681/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1722 - accuracy: 0.7981 - val_loss: 1.2111 - val_accuracy: 0.7715\n",
      "Epoch 682/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1715 - accuracy: 0.7917 - val_loss: 1.2101 - val_accuracy: 0.7828\n",
      "Epoch 683/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1724 - accuracy: 0.7949 - val_loss: 1.2130 - val_accuracy: 0.7903\n",
      "Epoch 684/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1696 - accuracy: 0.8061 - val_loss: 1.2218 - val_accuracy: 0.7715\n",
      "Epoch 685/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1712 - accuracy: 0.8045 - val_loss: 1.2210 - val_accuracy: 0.7678\n",
      "Epoch 686/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.1712 - accuracy: 0.7981 - val_loss: 1.2081 - val_accuracy: 0.7715\n",
      "Epoch 687/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1652 - accuracy: 0.7965 - val_loss: 1.2075 - val_accuracy: 0.7865\n",
      "Epoch 688/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1641 - accuracy: 0.7981 - val_loss: 1.2088 - val_accuracy: 0.7715\n",
      "Epoch 689/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1629 - accuracy: 0.8029 - val_loss: 1.2162 - val_accuracy: 0.7640\n",
      "Epoch 690/750\n",
      "624/624 [==============================] - 0s 13us/step - loss: 1.1678 - accuracy: 0.7853 - val_loss: 1.2121 - val_accuracy: 0.7640\n",
      "Epoch 691/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1614 - accuracy: 0.8013 - val_loss: 1.2027 - val_accuracy: 0.7715\n",
      "Epoch 692/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1634 - accuracy: 0.8029 - val_loss: 1.1983 - val_accuracy: 0.7940\n",
      "Epoch 693/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1631 - accuracy: 0.7837 - val_loss: 1.2009 - val_accuracy: 0.7940\n",
      "Epoch 694/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1665 - accuracy: 0.7997 - val_loss: 1.2040 - val_accuracy: 0.7940\n",
      "Epoch 695/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1712 - accuracy: 0.7837 - val_loss: 1.2202 - val_accuracy: 0.7603\n",
      "Epoch 696/750\n",
      "624/624 [==============================] - 0s 15us/step - loss: 1.1996 - accuracy: 0.7692 - val_loss: 1.2107 - val_accuracy: 0.7640\n",
      "Epoch 697/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1772 - accuracy: 0.7869 - val_loss: 1.2019 - val_accuracy: 0.7828\n",
      "Epoch 698/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1693 - accuracy: 0.7917 - val_loss: 1.2150 - val_accuracy: 0.7640\n",
      "Epoch 699/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1858 - accuracy: 0.7788 - val_loss: 1.1949 - val_accuracy: 0.7828\n",
      "Epoch 700/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1769 - accuracy: 0.7853 - val_loss: 1.2229 - val_accuracy: 0.7528\n",
      "Epoch 701/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1737 - accuracy: 0.7740 - val_loss: 1.2355 - val_accuracy: 0.7753\n",
      "Epoch 702/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1793 - accuracy: 0.7692 - val_loss: 1.2319 - val_accuracy: 0.7491\n",
      "Epoch 703/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1732 - accuracy: 0.7869 - val_loss: 1.2041 - val_accuracy: 0.8015\n",
      "Epoch 704/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1638 - accuracy: 0.7772 - val_loss: 1.1862 - val_accuracy: 0.7978\n",
      "Epoch 705/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1505 - accuracy: 0.7917 - val_loss: 1.1874 - val_accuracy: 0.7865\n",
      "Epoch 706/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1500 - accuracy: 0.7933 - val_loss: 1.1920 - val_accuracy: 0.7903\n",
      "Epoch 707/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1520 - accuracy: 0.8045 - val_loss: 1.1947 - val_accuracy: 0.8015\n",
      "Epoch 708/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1560 - accuracy: 0.7901 - val_loss: 1.1971 - val_accuracy: 0.7753\n",
      "Epoch 709/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1518 - accuracy: 0.8061 - val_loss: 1.1836 - val_accuracy: 0.7790\n",
      "Epoch 710/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1545 - accuracy: 0.7821 - val_loss: 1.1877 - val_accuracy: 0.7978\n",
      "Epoch 711/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1710 - accuracy: 0.7917 - val_loss: 1.1807 - val_accuracy: 0.7865\n",
      "Epoch 712/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1610 - accuracy: 0.7821 - val_loss: 1.1945 - val_accuracy: 0.7903\n",
      "Epoch 713/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1489 - accuracy: 0.7949 - val_loss: 1.2059 - val_accuracy: 0.7640\n",
      "Epoch 714/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1467 - accuracy: 0.7917 - val_loss: 1.2017 - val_accuracy: 0.7903\n",
      "Epoch 715/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1666 - accuracy: 0.7837 - val_loss: 1.1945 - val_accuracy: 0.7715\n",
      "Epoch 716/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1500 - accuracy: 0.8013 - val_loss: 1.1822 - val_accuracy: 0.7753\n",
      "Epoch 717/750\n",
      "624/624 [==============================] - 0s 15us/step - loss: 1.1500 - accuracy: 0.7869 - val_loss: 1.1813 - val_accuracy: 0.7753\n",
      "Epoch 718/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1438 - accuracy: 0.8061 - val_loss: 1.1931 - val_accuracy: 0.7678\n",
      "Epoch 719/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1331 - accuracy: 0.8045 - val_loss: 1.1956 - val_accuracy: 0.7978\n",
      "Epoch 720/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1471 - accuracy: 0.7756 - val_loss: 1.1873 - val_accuracy: 0.7753\n",
      "Epoch 721/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1439 - accuracy: 0.7981 - val_loss: 1.1774 - val_accuracy: 0.7715\n",
      "Epoch 722/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1385 - accuracy: 0.7885 - val_loss: 1.1734 - val_accuracy: 0.7753\n",
      "Epoch 723/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1317 - accuracy: 0.8029 - val_loss: 1.1923 - val_accuracy: 0.7453\n",
      "Epoch 724/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1386 - accuracy: 0.8013 - val_loss: 1.1873 - val_accuracy: 0.7865\n",
      "Epoch 725/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1403 - accuracy: 0.7869 - val_loss: 1.1722 - val_accuracy: 0.7640\n",
      "Epoch 726/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1300 - accuracy: 0.8013 - val_loss: 1.1689 - val_accuracy: 0.7865\n",
      "Epoch 727/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1308 - accuracy: 0.7965 - val_loss: 1.1603 - val_accuracy: 0.7978\n",
      "Epoch 728/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1350 - accuracy: 0.7821 - val_loss: 1.1606 - val_accuracy: 0.8090\n",
      "Epoch 729/750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 0s 16us/step - loss: 1.1300 - accuracy: 0.7981 - val_loss: 1.1637 - val_accuracy: 0.7865\n",
      "Epoch 730/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1243 - accuracy: 0.7965 - val_loss: 1.1701 - val_accuracy: 0.7753\n",
      "Epoch 731/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1278 - accuracy: 0.8029 - val_loss: 1.1767 - val_accuracy: 0.7603\n",
      "Epoch 732/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1215 - accuracy: 0.8109 - val_loss: 1.1716 - val_accuracy: 0.7790\n",
      "Epoch 733/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1236 - accuracy: 0.7885 - val_loss: 1.1657 - val_accuracy: 0.7790\n",
      "Epoch 734/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1186 - accuracy: 0.8013 - val_loss: 1.1671 - val_accuracy: 0.7865\n",
      "Epoch 735/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1182 - accuracy: 0.8141 - val_loss: 1.1698 - val_accuracy: 0.7978\n",
      "Epoch 736/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1282 - accuracy: 0.7821 - val_loss: 1.1695 - val_accuracy: 0.7828\n",
      "Epoch 737/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1211 - accuracy: 0.8061 - val_loss: 1.1627 - val_accuracy: 0.7715\n",
      "Epoch 738/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1224 - accuracy: 0.7901 - val_loss: 1.1578 - val_accuracy: 0.7678\n",
      "Epoch 739/750\n",
      "624/624 [==============================] - ETA: 0s - loss: 1.1025 - accuracy: 0.80 - 0s 14us/step - loss: 1.1189 - accuracy: 0.7981 - val_loss: 1.1561 - val_accuracy: 0.7903\n",
      "Epoch 740/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1134 - accuracy: 0.7965 - val_loss: 1.1544 - val_accuracy: 0.8052\n",
      "Epoch 741/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1198 - accuracy: 0.7917 - val_loss: 1.1539 - val_accuracy: 0.7828\n",
      "Epoch 742/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1119 - accuracy: 0.7901 - val_loss: 1.1573 - val_accuracy: 0.7715\n",
      "Epoch 743/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1116 - accuracy: 0.8013 - val_loss: 1.1568 - val_accuracy: 0.7978\n",
      "Epoch 744/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1168 - accuracy: 0.7981 - val_loss: 1.1585 - val_accuracy: 0.7753\n",
      "Epoch 745/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1102 - accuracy: 0.8013 - val_loss: 1.1615 - val_accuracy: 0.7640\n",
      "Epoch 746/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1094 - accuracy: 0.7965 - val_loss: 1.1542 - val_accuracy: 0.7978\n",
      "Epoch 747/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1057 - accuracy: 0.8109 - val_loss: 1.1474 - val_accuracy: 0.7790\n",
      "Epoch 748/750\n",
      "624/624 [==============================] - 0s 14us/step - loss: 1.1047 - accuracy: 0.8013 - val_loss: 1.1487 - val_accuracy: 0.7940\n",
      "Epoch 749/750\n",
      "624/624 [==============================] - 0s 18us/step - loss: 1.1042 - accuracy: 0.8093 - val_loss: 1.1492 - val_accuracy: 0.7865\n",
      "Epoch 750/750\n",
      "624/624 [==============================] - 0s 16us/step - loss: 1.1081 - accuracy: 0.7869 - val_loss: 1.1522 - val_accuracy: 0.7790\n"
     ]
    }
   ],
   "source": [
    "activation = 'relu'\n",
    "optimizer = keras.optimizers.Adam(0.0005)\n",
    "l = 0.007\n",
    "he = keras.initializers.he_normal(seed=None)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l), input_shape=(train_X.shape[0],)))\n",
    "model.add(layers.Dense(128, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(64, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(32, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(16, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(8, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(4, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(2, activation=activation, kernel_initializer=he, bias_initializer=he, kernel_regularizer=keras.regularizers.l2(l=l)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_X.T, train_Y.T,\n",
    "                    epochs=750,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(dev_X.T, dev_Y.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydd9wUxfnAv3P3dvrLCyJNQLEgIApYsUWjoILG2HuLFbvGEqPGRGIsMbZYfpbEEksSeyN2sSIWLIgURUVA6SBvvXvn98fs3M7u7e7tvbz3vry88/187nO3u7O7s3u788xT5hkhpcRisVgsFj+J1q6AxWKxWNZNrICwWCwWSyBWQFgsFoslECsgLBaLxRKIFRAWi8ViCcQKCIvFYrEEYgWEJTZCiKQQ4mchRP/mLNuaCCE2EUI0e6y3EGJPIcQ8Y/krIcTOcco24Vx3CyEuber+FksYRa1dAUvhEEL8bCxWAHVA2lk+RUr5UD7Hk1KmgY7NXbY9IKXcrDmOI4Q4CThKSrmbceyTmuPYFosfKyDWY6SUmQba6aGeJKV8Oay8EKJISplqibpZLLmwz2PrY01M7RghxJ+EEI8KIR4WQqwGjhJC7CCEeE8IsUIIsVAIcbMQotgpXySEkEKIAc7yg872F4QQq4UQ7wohBuZb1tk+TggxSwixUghxixDibSHEcSH1jlPHU4QQc4QQy4UQNxv7JoUQNwohlgoh5gJjI+7PZUKIR3zrbhNC/NX5fZIQ4kvneuY6vfuwY80XQuzm/K4QQjzg1O0LYGTAeb92jvuFEGKCs34YcCuws2O+W2Lc2yuN/U91rn2pEOJJIcSGce5NPvdZ10cI8bIQYpkQYpEQ4rfGeX7v3JNVQohpQojeQeY8IcRb+n927uebznmWAZcJIQYLIV5zrmWJc9+6GPtv5FzjYmf7TUKIMqfOWxjlNhRCVAshuoddryUAKaX9tIMPMA/Y07fuT0A9MB7VWSgHRgPbobTLQcAsYKJTvgiQwABn+UFgCTAKKAYeBR5sQtmewGpgf2fbeUADcFzItcSp41NAF2AAsExfOzAR+ALoC3QH3lSvQeB5BgE/Ax2MY/8EjHKWxztlBPALoAYY7mzbE5hnHGs+sJvz+3rgdaAbsBEww1f2EGBD5z85wqnDBs62k4DXffV8ELjS+b2XU8cRQBnwd+DVOPcmz/vcBfgROBsoBToD2zrbLgGmA4OdaxgBVAKb+O818Jb+n51rSwGnAUnU87gpsAdQ4jwnbwPXG9fzuXM/Ozjld3K23QVcbZznfOCJ1n4P29qn1StgPy30R4cLiFdz7HcB8G/nd1Cjf4dRdgLweRPKngBMMbYJYCEhAiJmHbc3tj8OXOD8fhNlatPb9vE3Wr5jvwcc4fweB8yKKPsscIbzO0pAfGf+F8DpZtmA434O7Ov8ziUg/glMMrZ1Rvmd+ua6N3ne56OBaSHl5ur6+tbHERBf56jDQcAHzu+dgUVAMqDcTsA3gHCWPwEObO73an3/WBOT5XtzQQixuRDiOcdksAq4CqiK2H+R8buaaMd0WNneZj2keqPnhx0kZh1jnQv4NqK+AP8CDnd+HwFkHPtCiP2EEO87JpYVqN571L3SbBhVByHEcUKI6Y6ZZAWweczjgrq+zPGklKuA5UAfo0ys/yzHfe4HzAmpQz+UkGgK/uexlxDiMSHED04d/uGrwzypAiI8SCnfRmkjY4QQQ4H+wHNNrFO7xQoIiz/E805Uj3UTKWVn4HJUj76QLET1cAEQQgi8DZqftanjQlTDoskVhvsosKcQoi/KBPYvp47lwH+AP6PMP12B/8Wsx6KwOgghBgG3o8ws3Z3jzjSOmyskdwHKbKWP1wllyvohRr38RN3n74GNQ/YL27bGqVOFsa6Xr4z/+v6Cir4b5tThOF8dNhJCJEPqcT9wFErbeUxKWRdSzhKCFRAWP52AlcAax8l3Sguc81lgGyHEeCFEEcqu3aNAdXwMOEcI0cdxWF4UVVhK+SPKDHIf8JWUcrazqRRlF18MpIUQ+6Fs5XHrcKkQoqtQ40QmGts6ohrJxShZeRJKg9D8CPQ1ncU+HgZOFEIMF0KUogTYFCllqEYWQdR9fhroL4SYKIQoEUJ0FkJs62y7G/iTEGJjoRghhKhECcZFqGCIpBDiZAxhFlGHNcBKIUQ/lJlL8y6wFJgklOO/XAixk7H9AZRJ6giUsLDkiRUQFj/nA8einMZ3onrQBcVphA8F/op64TcGPkb1HJu7jrcDrwCfAR+gtIBc/AvlU/iXUecVwLnAEyhH70EoQReHK1CazDzgBYzGS0r5KXAzMNUpsznwvrHvS8Bs4EchhGkq0vu/iDIFPeHs3x84Mma9/ITeZynlSuCXwK9RTvFZwK7O5uuAJ1H3eRXKYVzmmA5/A1yKCljYxHdtQVwBbIsSVE8D/zXqkAL2A7ZAaRPfof4HvX0e6n+ul1K+k+e1W3AdOBbLOoNjMlgAHCSlnNLa9bG0XYQQ96Mc31e2dl3aInagnGWdQAgxFmUyqEWFSaZQvWiLpUk4/pz9gWGtXZe2ijUxWdYVxgBfo0wPY4EDrFPR0lSEEH9GjcWYJKX8rrXr01axJiaLxWKxBGI1CIvFYrEEst74IKqqquSAAQNauxoWi8XSpvjwww+XSCkDw8rXGwExYMAApk2b1trVsFgsljaFECI0m4A1MVksFoslECsgLBaLxRKIFRAWi8ViCcQKCIvFYrEEYgWExWKxWAKxAsJisVgsgVgBYbFYLJZArICwWCyWNsDbb8Nnn7XsOdebgXIWi8WyPjNmjPpuyfR5VoOwWCwWSyBWQFjaNY8+Ch991Nq1sPiZOxfuvLO1a7HucNttwevvv7+wZqf1Jt33qFGjpM3FZMkXIdT3evIarDdssAH89BPU10Nx2OzbzUBNDRQVFfYca8uSJdDDSKVnPqv6+W1sdH/nixDiQynlqKBtVoOwWCytx+23w777Zq3+6Sf13dgY8zi/+x2cfHLep6+ogF/8Iu/dWo4//5nSk4/JWez22wtzeqtBWNo1bVWDeOcdePddOP/86HL33QdVVTB+fMvUK29C/gC9uroaysuzd/vXv6CkBA46KPw4s2bBHXfAtdcqLSGP03u45hrYdVfYYYcc11IInAoK3ArquqZSruaz997w4otNPUW4BmEFhKXVWboUEgno1m3tjzVvHvTtG94g+GmrAiKq3t9+C717q8bDX27uXBg0qOnmiGYnh4BYvRo6doyxW8BxDjkE/v1veOYZ2G+/4GuP8//rMp9/Dp07Q79+avmnn2DxYhg8WAkrk5oaZRrSZcNIp+G772DgQLW8fLlaV1XlPbkpIGprobQU1qxx780BB8ATT0SfK/z6rInJsg5TVQWVlWt/nEWL1It24YVrf6y2yvLlMGAAnHlm9raPP5JcscmD3HJtTYvXq6mk003fd/Bg9f3KKzBtGmyyCdx6a3DZ+nrfilWr4NFHaWhwVw0dCv37k1m3wQZqXZBl68QTVdmaHLf6qquU0Jo7Vy1vuaXX3xDE7/eeCtOnU1vrrquoiN6nqVgBYWkR7roLrrgi//3SaWVGeO89WLFCqdLz53vL/O9/cOyxqjcH8PLLa1/f5mLiRPjvf/Pbp74eJkyA6dPV8iWXwD/+EW/f6mr1/fTT8OCD3m3LH3+NBzmaTe8ujAQ99lh47bXmPebaCAjdaL72GsyZo36/9Zb6PvdcpVloTjkF/vlPd3nFYafCYYexesonWcc94gilmWieey773O+95z1fECtXKgEBqnMDsHCh+v7xx/D9rn1jOxgxwiMggsxwzYKUcr34jBw5Ulpahw8/lHL16ugySonPf9u8eWpbv35S3nab+n366cH7f/SR+h4+PH7do869tkyZkvv4dXVSvvuulG+9JWUqJeU776hlkFI/0voY5j0OO+6CBWp9t25uGV3ulYmPSwnyw74T1vraZs6UctEid7mmRp0nmQzf5+efpZw2zbdSV7CxMXD14sXZx1m82Htdn3/u7vDDD1I+84yUCxdKefnlanXPnlI+8oj6ffDB6p6b98Z/n6SUclrHXaQE+eYfXw8tqz8dOkj5/vtSzp0r5SefSPnpp1Luvbfads016v14/fWsS5R33eUe4513vNf99NNSzprlrvDU0fkxZ4677swzI/6sHADTZEi7WlANQggxVgjxlRBijhDi4oDt/YUQrwkhPhZCfCqE2MfYdomz31dCiL0LWU9L06muhpEjlb23EOgolmRS+SnMdUF10WVbm6+/hp13zl3ugguU83PMGDj4YNhxR1fT8l/n4YfnPl4qpb7N3qWmIaXs2YmmvvVSZiq1+eaw0UbuphUr1HeHDuG7H3EEjBqlrDdZmBfb2AiOzT1Ig9h6a+/y0KHu7402Ug75LbZwzUZ1dV5fw7x54XXU1Dc63t8s2xMI3PqB8gVstx1svDGMGAHDhysfAcDFF6v3Y7fdVGCBeY0ylSaBukD/MzthAmy6aXQdW0KDKJiAEEIkgduAccAQ4HAhxBBfscuAx6SUWwOHAX939h3iLG8JjAX+7hzPso6hH9J33y3M8XUDkUiECwi9/uefvcsAkybBL38ZfOzYIZRNQAsrzR57wJ//rJylpqnNjKt49ln1PXOm+q6p8TbC2mzhZ+JEOMaJhNQhm1EC4rvvJEuXxrwQkyFDkJWV9OmjFuvqlHMUXAGxapUKEggSArr+xx4Lp58O3bu72xZ938Bmm8GMVxdBMskpqFFyG24IP/zgPY7fxGiiBeSKFW7bbt6L//zH9VFFOerrGlWUwy03prK2NZLkObJDc02CBFvKPFS3bpw4sYw0RezLsyQS8H//F3nILEzBWKhxHIXUILYF5kgpv5ZS1gOPAPv7ykigs/O7C7DA+b0/8IiUsk5K+Q0wxzmeBfj4Y5gxY+2P89ZbKoJibdAPfSF67V99pRKUgeqRax5/3FtOR5CsWaO+TQHxu9+F+yTC7NtSqhHWpoMyX/wN9KuvwqWXKnu1tjv70efTvcFvv/X+P0H3uLFRjbJ94AHld9C29qCoHPN63nxTfadSKoY+V4iklMDMmYiVK1mwwF3/1FPqWwsIUA36jTd693/6aVdoPvmkOueyZe72e+5MMWsWvHyn8tYew/2Z8z7/fHi9Pv88fJupQfjrEsaqVUpQ16VVi1v7c/BDsA8vhB8Et7Ni4rmOVatINqqXZzzPkE43aRhHhrV5VqMopIDoA3xvLM931plcCRwlhJgPPA/o2Is4+yKEOFkIMU0IMW2x9lC2A7bZRkU7rC0776wiKNamJ61fwiabLSLYfHM47jh3WacbWLLEbQjB7T2tXJlfXcIExAMPwGGHhac3iENQDz4u2jzhr1+YgNDs7+9+GUjpahACmTn2X/+qevPjxrkCNojvvw/fBl4BAXDlle7vr79WdQtqNDUzP1Mt3KBB2ds22CB8v2HDwreZ1qEAS1GgED3qKGWiWtOgHqpimtbymsJPc+21wVFN9ZQENvDKlKXQpqgw2qKACFLg/H/J4cA/pJR9gX2AB4QQiZj7IqW8S0o5Sko5qkeu2LB2zBlnhI8xSKdVA/vAYc+pUUV5ontnUY1y797u7yOOcGO+hw2LbtT8hGlNWoPQAiKuNpPKth4AbvSQ2fN8/XVlkvjmm+zyo0dn+2C0/+F8rmcX3sjaRwiYOjX4/Lr+/pc+6B6n03AQ/+Zop8ftZxBzuYHz2H7bRv71kGpwBFIJlmnTGPHYpZmyUR2FKOFRU5MtIECZ94TwmkJCcf6MRpkd97///sENfC5MM9fRR6vvJCluYSK9ce1Wpnnmyy/VdwPZAiLqOq7i9/yVc/kr53Ih14bmR/JrMwBncivln6mHoYrF/J3TKKGOclxpUkwDJ3I3+/NkZt2NnMOtnEERDQUTEAWLKgJ2ACYby5cAl/jKfAH0M5a/Bnr6ywKTgR2izteeopjyjbwJKx8UGZGLxkYVTaQjWGbMULv17u0t9+abUr7xRvZ5zNOERZAE1c//mTvXLderl1p3xRXu9vr68GufMkXK116TcsUK7/Z771WfQYPUunvvdfc56SS17o47pHzqKRWp4q/nK6+oCCTPeQOiUPTnjDOk3GGH6Os0P/37Z59zzZroc3zI1lKCHM4n8iAekxLkM+wrH35YyvqyjlKC7MJyCep+hHHppeHnmTBBbY97HUHP3VF7LJAg5RO/fUdKkO+ynafckiXRz0VQ3XbaKbvcHrwkJcjnGJdZZ0Z8lZaq7wc4UtWL+zPbRoyQEhqzzlVEfdaJwq43E/kVsBGkvJfjMuftwY+ZbR1ZFXoT9+cJecop4f9dLmilKKYPgMFCiIFCiBKU09lv/fsO2ANACLEFUAYsdsodJoQoFUIMBAYDIf2t9kVYrzcODQ2qx6k/+bJihYodP+MM19EapkHssotKTxBmalmb+Hb//vrcplp/663eMo2N7mfnnWH33b3bf/oJTjhBfbS/w7zXeiDf0qWqRzt8eHad9tgjv3QMK1bk938GaUa57qPuAUsEJahuuECqJHi1yuazEd/mPNakSeHbnn46enscEmlVz1Q62HMc3wwqOf109SvKLGZqBmbklX6eTQ1CRxMVFUEp2SpAMsT8s22A1zRIgzBJOGalJGkqcCMd9H8XREVJqu2ZmKSUKWAiqvf/JSpa6QshxFVCiAlOsfOB3wghpgMPA8c5Qu0L4DFgBvAicIaUci2blLZPY2Oe0QpLlrhDNFGmmKIiNdJWjzKNy7JlMKzb99yy/0uAzIz2zOWDWL48eP24cfmd349uWB99lIzT9JZb3O3nnedNtzFsmBqhqs1b5jEABmxQzTA+9ZzDFG5aQJR9+TFFOezSUqrvXOUeegg++CCyiIcgASFnfuVZHsRcKlnKaKaixIKqjF9AHHusu08cAWGS67pA2cxHEp76ZiifUYFrt5ryuvozrr9BLW/P+wzhi8x2v4kpSYpt+DDruIMHNXLCCeq3PwCjD/PZ1TH36Ya4gjVslfycMmo8/3/KmUutiFQmnUVREQxgXqbMAL7JlAlixx3VgLokKfbhObbl/Zy+KYlrYjMFRJQvZHTFF21PQABIKZ+XUm4qpdxYSnm1s+5yKeXTzu8ZUsqdpJRbSSlHSCn/Z+x7tbPfZlLK6JCBdkKUHfbzz+GGG7zrUv0HqvwCPubPD7alR7F4MTzDeF5iLzZnJp07w+TJbhbJMAER5KwDeOml4PXTpyvHaS4uvFAd2xzRGsWMGaq82WiYDeLtnManbEUVbrDDOefAb3+rtIaOHWEgX3Peg9twI+dGnksf17QhNwc//KA0Ny2AADpvu7mnzFw2YSlVTGU7DuXRTEPYSIJuFar7qoVGo9MY9ec7T739+NebDVcYF3MN0xjNdmTH5pZQx2cM51EOzazTDaDpe/iCoSSdxlc/+3pE+aVM4kNGZQmJRLqBXr2C6zSffvyeP6lyzn35Nwfz7LfDeJCj+JSt6Irq0WgNooT6TEeiqAhmskXmeN+gPOrBAkLSp48KONiFN3mO/Xif7akLiYpy98pfQJy74koa6mXo9rXBptpoQ0QJiFGj1KArs/EoqokIG8mD1atVIzkC5b3twkrq62HsWPeFFcJNF2ASJiDC2GknlaFUO4rDeO451XivDaYGMdzpPZo9xMZGuO46uOgiVbYSdTE74A76kAHvpdaaOhDh2W0CNTUqRPaT7OwPgQxmtkeDGLap9wFaSRcgtwbhDxCMIyBGoCrZj2w7j95/LzL9wUwj6zfXFPkExPHHq+/NUJrTlnwBZqbThhQ9e+asXkZA7M5rAOzNZAA6ozzbWkCUUpcJfghLABkkIIpIUVWltHZ9TICf5tdnjZExMQWE+fxEmZiAtQubi8AKiDZElIDQts218VEAgcbezp1Vw60po5YlS7xlvvlGDWry55CJGtQUhG6kRozIXbYpkS1B5wJYgAq16s2CrHINDepcptlBE2RT1g1UnIa0KaxeHa+cRHhNTMI1MYHbGOcSEBtu6F2OI/ganaZFn+Pqq91t+r6UGL1ifU/9ja1fQGiWoNKdVrHEu08qFcsM6xdEuofuFxBl1LLffqrM7rsF99KDBEQxDZkR1Wbv/1f7pxk5Mrxe+r75NYhORP/pxdUrI7c3FSsg2hDmS3Iyd1Jd3t0zX+ZwplNcIlR3PsKgfBY3IRH8lwOzti1fFO5FS6GM4K+zO93fC8hQRvYI2iOOCD1cIF27qu9pjOQiroksm0gE9+DfYQf+Qm71whSmC1GtYFCPt7hY3XvdaOgGQUqVtdPPoxzCgxyZecH1fQN4hEP5ks09dvw33lDO7c6sZBWd2JOX+Dun8TzBjppc2pWmkYTH6VmW8Lay+joO4d9IBKnaeL2LDqzhKB5gBV2Y8loqq8HrzhIO5bHMeQEGrv6UGsroz7eBAkY3okEaxCbMZthwATNmMI7nkQjO5mZACQiP+cUxxp/HDdRTzCUEe8/1fdHCstTpoXdlBf34jgtQ9to/8ntuuUWNbr/s9Gx1uIiGQCf1d0WD2OaNGykp8QqIJOnMSHk/EkEVSzL1MwVEF6IFQGlNQJxxM2AFRBvCFBAH8R8qapex/C3XkXcSd2d+z/kk3Lx0E+cAcCDZCeTPOrmW+vrgRkj3oAH2//SPgcdOJt3xCE2hQwft4PyIa7gksmxYrPkOvMdvuS7nuUwZuppOQPCLWFTkHZOgG9alS9XENX4O4d8cyb8yL3gdpZlth/IYm/NVpqdaVKQivsaNUyahTvzMtfyW07iDcQQPbz7rLP0r2u7cSCLTAA7ZNM3Y3dUDpBtHv11b/hzPJFZCPTdzFl1YxY5DV3HFFd50JhOqXBOcPteIN26ijDrG8mKgZhWmQRTTwCGOsOHBB/kDV3i2V1DtuY66NWr/UUyjmBSjCY4CSJLmjDOy53Howkr2xe38JJCIhno22wwS33+bdZwurAzUIKpSP8J552UJiDCHtmZ7x2fj1yByCohaq0G0e0wBoRvri892HyLTwbfrzk0bHv3yc7Ucc4wy8Xzrex9MAbGiITgBfUNDvCR1YfTs6TXzRPkZPvoIvvgifHsugpSswN6to0H4G7FcoZf6WKaA0PSp9NqMBwyAatQ97cMPWeWDSBBdAVOD+PstaToUqwdI2bMlxaR4nV0z5dP14VqnOaq3hPqMrTwhJOPHq5TrmuNPyK5j2RrVM15K97wERBGpzLmC1MVelQ2eBrixXv3u2V1dS2XnFDvumH09CRq59VZIJLxhtV1Y6XmPADde1v9CoDSOqEY/kcjWIKLQ5/b7ILYeEK0hWAFh8QgIbe4wHyLzwa6scY3/o0J6UUGUUcujj6rfX38NfPUVB6ImNPAKCBU8vgGLONHQXD76yNuzL6eaM7mZU7iD4UznJs5ib15kONMZ7x8W89Zb7CreZNue7os4ZP7/CKIzKzmNv/PTjxKQnMbf6YbXBLAXkzNRLpvzJQc4GtOOvM0uvOFJmqdf4gN4ktFM5SxuopxqJnILHVjjERD6JTf/jyN5kH544yrPPilbg9AMG6wExG6Nr8K779KxIxyBUkd64vUKj+N5tkaZEgWNXM4fOJe/BjRM3obN1CCquqXRf2wpdZmGew3uIIDkD9/Bvfc6OzfCzTfT8H//YBBz2RzXLmIKiCApWVHm1kNdk2Tgp+q/9ptONPr++6+pP99xLM5EDVJmNd6VnRo8Dly9/247q/9o5+0aAs2Qo5kWqIIOZnYmUWAGLRgCBMT53BAZ1dbj4ZsD61eXKAssr6+vnBou4c+Z9b8/M1pAlNcVxsQUc2JGS2sjpXfiGd1YV1AdmObgSQ7I/P6AbbN7RSGYA4Eeegh2v2dz/ot6cLVQArdh+QfHMZbJTGFnZrEZf/ub93h/4jLOw5u57SzcAQueeu28M38GLtr0CXAmrT/2X3tzXEDd/87pHMm/mC+H8jWV/J0zGM8zniRqkxmbOceXDMn8fpsx6vd/3OPqBmoIXzKV7QA4lTvYgpm88/ZXPDLm1qxe7vvv633reZCjmcdGDDSioLqUhAuI/huo+/xS4x6wI5Q/m+Iyrs4qB/C8kzlUIDmYf/MHrgTgI7bxlMsyGRlOatLpzAjAUuoyZbXWAtD/tH1h8QJlL5o2Dc4+m2LgM8qpx7XFeAREQFSEmSV1b/7niQyroDrwfoRpEG+wK2X6mQxo6YtksIBIOsOmEo0RJp3f/S5r1ZX8IbucDuMKyPd2GtHpafpdfzYHsXtmWXcuahtLKCU88uh3XE0VbsrdopXR6Xe329xqEO2axx/3JkBzB/pUc+qp2eV76hY2T8qMh9Y/xsDUINbQgQ02cAWKjqXfbLO1r0dFUXh4krZ1a2dex4TbG92SptubguLMN0YNMiyvXU5DQ3YjdtBB3n37+zSI0pSqWy3ZvcUenbyNQ5fqhSE18zaKZsik3y7tvwbTxGTa00qpy1xDh56uBlG82DHtNTR4wiYrqKGrca5S6iIFxIa9vWabQbipeCuozkuDKDM6LI1p6Z7XISkbPMf71b7OPdDXGxXWF9dZph1QtbVqQEzQCxdBN9zRolpACCR/jdA8uuLr9S0Mez4U43exAqJdcsopajIS/Sx3ZiUD+CbTOPTje2ZMWUoX3wOV3UuTmUFAaeNvV0nB3BdMC4hLz1zNmlXel8sUEBLB8M3rs8JDX3/gO8qcAWJJUp6XI4iSgNQF5UXehq4zK+nGMqR0U2XrcMBKsTzTQGih4acD0eNBnn+erAgfVTdVj+KaVdTXuy93kCMVlEPTs39DuA+ie4daOhuNbpcV2eYL8IY3Cho9y/60Dx1915km6WoQxpD2Euozdd7n19m+pNoamTVkf5XjxNf7ZxrqhgYVupZO05HVJEhnjUN45Q439W6YgND3NOw/BEg3ZJuzihq9AuIvVzv/jRYQDQ2UpquDn4GoCSFMTAFRVpb35Atbb+k+zz1YTCdWkaAx8wwHkaXx5xAQgWaEZsAKiHWYhQvVXM5Tp8LDD6vonpV05RsGsTuvA3A0D/LpgipW0I2tcEOP/I3S+dzAcirpzQ+ehv4rNqPasEP/8Xd1PPuM5OpbOpPC+yKY+53EPTz03ZiMgOjFIjZiHt+xEc+iAscf5Cj2JSKZv3N+P2VJrwYDBx0AACAASURBVIBYSVeW0R1efjkzWEk3ULcuO4LzUEOvK6ghKLLnZ6NxC6KoCEpF+EjVofOepevSOZGRNkGUpMJNTFVlP7OSrpnljiuCB4y8U+Q6kU/lDv7K+e7xfYOn5rKxZ1kiXA1i/PjM+n49XQ0iaAq4ZUslssj738/EHbHtERDV1dClC5xzDqvpzN2clJ0SZPbszM8OrAnVII7jPm5jYtY2TdBo4SLZ4A0s0I4hrTmkUrw2tUPwM1BbGxwnnXVi5/+tq3MGNuQ5O48RAvc+27OKLnRkTaCAqOymx6j4hOGC7PE5HtYmdDACKyDWYe66y/398su5Q92G4s6eYtqMAX6Dmq6qkmWkjbj8AXh7rr/crYF994qX2KXHNx9kzlNODT0c5+oevMpRR8FhPJrzGP7zQ7YGkWHq1EzjY75cB/GfzO9cYYRhoaElEQICYINlM0NH+4YKiHrVa/X/FwAbVs/xLJc1BA+EGppyh01viLcXma1BeCOwkqQDfU9lRAuIRALe+zCmgNCj9pzp0I7nH9mN7uzZ0KsXlJay04hqNu2dHSlWSh375OhM1NdlO6n9JqaMaczQIEJpiompCRpEWB3M91CTTIQILCsgLH5+8pnvcwkIs9H091q1LyBJ2qMJZJFKhTzQMjBELxPGSK033nstwh9KkyEvdYcOgQKiyKiXaaMPIqgxr62Fqq45cuTUN4RqEE8+Frxv6RoVVRXUSPdYNsuzrLWNIBqc/8sfgpsr/UIRqeDghDrXSU1FcLjyz7XeP3DcHvXUlnTKnDcjIPQsQFFpSufMUXOnVlSw15hqzjwx+1rLIhy2mkcezr6WzmX1XgGhJ66I64OIY2YqkIAI0iBEmEYTlMfGxJqY2h/+eYOvJjvqwqTSsPf7nXndHB/Fjb/5ks5Rw/Z/+knNsO4jQWOggNCN5cX8hb64ZpLTXj8kq2wY/+HX9DVGMB/z3hnBBVMpNvrtIfTkx6zr00xm78hzBQmImhoYtVVuAdG7R7CAGPBQcPTRgGdvBZRQ/gOXM4GnMts6L/IKiIo3w/NRFjvn8/sYglJPe/dryBYQ5eVQV8cbL4drEOmGRmTC27vt8cqj1BWrtKYeARE0k5B/gMns2RkBwSOPwB+zB1nmuhaAmtrs53qTjRr4/XmGgNCJjppbg5g/X4URptPZo+tyEZInKdAH0dT8MQXSIGyY6zqMP9/RETwce99Vmam+vezywG+id/z0UxXi6CNJOjTnjMYc5brtvJhpVoFf83hgpE8W//gHXT7/nLPZJNTBNyogBbRJmIAoljnMag0N9OhWBIvdBlvT86no2eaTpLkcb6NYttQ7GK7kFd+o6U6dlPlm663VJORkaxC5ssUGahAdOsDSpQzsG65BpOuCNY+6ogABEZQYyt8oNzSoeUPPPhtuuimwrnE0iKA6JVINjBhs3Be/gAib57RLF9WoxpmftqHBHbE5c6bSIvIhJHlW4DMclckvjF/8IniCkmbAahDrMKYGUWyYEy4PitX2EfbCiVTTskIWkSJJmls5gx/o7VmvWZvspaG+A3NSaicOfQlVkREgUZhmGZ1Kum9fck/qm0pRmnTrGD5HcHYjFqh5rXYG9R12WPBhOjlOVaM37r+/ue53Eans0dYdOigfgf6fgwREfRrRmF3nWkeD8IS5BjXAQWadrl1VjnbDWW7SVAFBQ4O3UfULCH8vS6PzlcSZicjfqw8xy7HnnsHrQ8xvgc9wUH20GeyEE7K3AbzyCtx4Y/C2tcQKiHUY89m+fFPX4Tufvjn3DXvhEqkcDWHQrOqoRq5DSYqDD0vSq49rfjj2cPd4a5O9NFRAlBq+FCdV7DIqmywgTA3ilM3f5OP7PmGPIQtzCog5MxsYUu2OSHcdxt5GKygbbFAmzuSC+dGJq3Qj+6k7iY1fIOzCm5F1DjQxaZOSNg0FmEsa61MkAubn0hrErrwRbWIKEhBdunjP7+Oyo7/lYCPYIAidmtvD++97J/f2+yDC0mBXVUWeK0MyqZ4N0zcQJiDy1Cy22jrm5OnaoafvYQtiBcQ6jBYQnVjFZbOOyawvHbppzn3j9MgCiRAQRYk0G2yYJJl07cCdyt3GYG0ERGiOGiGyJj0qpqFZBMRtM/dgxPFbQ79+OQVECfUc8u31mWU9KM5/zZ+SrepXEjIpRkUFHHpo8LaA+vh9ELswJarKjB+XorTEJyD09Gi6IQ2IJvhwarAGUZ8sB2Ask13BE8fEBG7jFtK4dnjgzsD1JsP5LHicxKNGtJxfgwije/ec5wOUQ9p/Pc0kIHr3TSj1dYstogvq/6hzsNm4kFgBsY5SXe12fjy961dfZYuxG+Xcv8mzmUUIiKRMqYfV7E2lTAERfc6fbnkkdFuoBlFTA6++6llVRm2okzoXgc7QdDqnc9BfPz2Hgj+yrLtPGKws7ZG1LkNFBRx7bPaECxD4P+Rrwhu2eYrOHQJMTOCahgIExA3XpZnxebapI5VwtY2M6SofExOEN64+vn082Jfk6Uj07+/+Li9Xvf2WEBAhWlC+AiJZnFBTHH7+eXRBbWKyGkT7Y9Ikd9pOkzDTKWVlTPxd7geluQXEkYemSTSm1UtoCog8JsMVET2gSAHhCysspa7JGkRoI5tjNnm/c3sjviWZzB163HmD8ojKOA1NafZAuiDTSN4+nvr6bJu238QUELJZRIrVK7Ib2MaiEk8ZIHsCEGiSBpF1ruKAe4LvfzB9D6Wl6thxBURcE5MWEOY1NZMGkShOqMY/l6Ncb28FAWGjmFoZnS/ssMNUu/vqqyr1sxO4Avgaz5ISEp075jxukwVEiM325kc3cCrje2TymMKuakB4vUMFRHV1ViN2PRfyHPvEPq/Jm+wSvGHWrOD1Dn4BcQ2XcE36EpZ2HwwRedREUGOSTKoGTG+LGaLoNzHl5LbbstdpIX2Hk2QuQINIkubLL7Ib2C23LgFnLvPM/3X33VnlIn0QQfcjkcgSZI3J4LEGFSUpMnEGfgEhRLYPIozKSu++YR2E4mLvfSwrCxbokHf4a0M6ZifHahDtE7Oz/qtfqTkYDj4YRo+Gk092t3nU6tJS9UK9+CJsGu6LKMqRdz5WpYLwT+OWQ4Oo6+i+iKJjiGpOhA+ipiawEdOJ9PLFP9rYw4ABoZtMAbEC90XtvnR2UHGXcleD+Abn+LqR1N/Lo/NVaZoUJeafu3XCBPWtM5MWF/P9/3nHYBSRoq46+/8o6ViiHlRyzGsQJCB6O5FvQQIioDcfKiBKjfOaAiKRUJFfWqPJJSA6Gp2V886D+++HQYPUsukTMPOG7LYbfPlluCDQ5rZx4+DII73bAsxS1TUxm1+tQZj37oXwcTPNiRUQrci8ee7vN95w5yXx43kZ9cO5997Qp0+s89TEGWOQKZxDQPgFQg4NYs7YM90FX8/rnS5jM79DG5wADQJCQh7z4HO2zF65S4h2gdd3UZ3Mw1loCIiMkNHrYppbNJHCTeNPhOQPo62sVGMS9P9cVETdTnt4D0E6+P8oKcmk0+3cIaIBDuo0aD9LUMPdo0fWquLyYONGIsB5Dqjr6drV1caCzmOGTJvmoPJyOPpo9zkzBYSpWdx+u+pE+ARErc5aoCdgnzDBFcSaAJ+HzEpaFYIWEOZ5x44NLtvMWAHRijhRm5GMYQqHmjmNzIckZjbKvBy6uQREXZ1Xg3j22cjijSXGi+gTEDXC7VWFmphqawM1iLUZcwFQ1T9Am4lwXJrRSj02ivAr+DEERCayTK/Ld8BVHPzmD/81FRerj+59FxWRLPXe3yRpJnJr9rFLSjL/hQgKb9Vcemn2Ot0Yauea+RyXZ9/PAYODNYiEjPBVdemiNOvvvw/uuJjPrXmfdF30c2ZuM9+Hfv2y646Ra+sbx/7Wu3e2OSjg2dpl1zxNTPmO4G4GrIBoRZaFBLeYTGEXbuACd0UTBMRzJb/iSyPZWiRhceMav4AI4H+4ExR7BMRGG7Go70hmMZi5fXeh/yg3L3SggBg5Uo28DRAQgTmX9t8/uu4GvcaPzl55zjmh5U2BVNwYEfHk7w0bjV/GL6Q1h1w9yF/8IvOzmphCyS8gTFs7qHtZXOyGp5aVkSwS1PkmBNrBmRs569hBeYj6RozL2W47uMB4fg87TI36vfBCtZxIqN6w37zXvTvsuCOMGuVdb2onDz3k/q6rc1XyE07wahBbbAGbbw4HHqhMSXvt5X2P9G/9f5j30DRjaTPRxhvDNtvAxRfDttvyK57gI7ZW9dlmG9h9d9hpJ1V/HWnl/x+A4tKA5vfSS5XJy8TUIG6/HY46Knu/AmEFRCsSR0Bk0YReRG3HHgzhSxZ3HJC7cL4ahGZXNy31vjxHTYnqQZV1MepbXMwDZ01jM2Zx+6FvMHi42+gFCohp09QE1wFRHoH5pJ58UtXtjJBcTppu3ZTw8dO/Pxx+eOAunnElUQIykYD99nOXgzQILSByZTQ0zBT+VN5AcLhlLgGhNQgd1tu1K8mkN+NsqHbWoUNwnb//HrbaKnif996D665zlzfcEKZPd8e2dOyocjPp3rdZz7ffhlt9moypGRxxhNIYNPrZbWz0CoiddlK+gwkTlClp8mRv5ypKg9C89JK3/Icfwp//DO+/z6vswUg+gh12UOs7dVLX9fbb7nsRpJ0GPUdXXw033OBdZ2oQp54KDzyQvV+BsAKiBamrU+lobrtNZe8150QGKKWWnuSwOzVBgxixtSrXkMzRCy0qarqAMBqOjz8toqyj6o1tNsTboOhdhfDuk2sy97zI1fDW1YWXCenVewREVHqG5cu9DlDDz5DJ8R9XQBi99YUEjJXomDuaLath0hqEpkuXLAERGi1VXh5e57iT72j0fc51Db7/IyvbqenH0c/u9997I8Nydaq0QAjSIDRNjSDS5w4SEHHSfIA1MbUXrr0Wbr4ZJk5UHVV/ivenmcCP9Mosb7ddwEHCQuwi6HvgtnTuDBuumhldsKgot4mpvj64EdXriosZOkwgdEPiKxsmIHLP45AHuUw3tbXhKZtDYtI9AiIqcqu+3utbCHJEa63CX4eNfAMgi4oydu+gSYcCG9dOvolx/BFCRUXe2ck6dCCR8B4/VIMoKcmusx4At3d0Ft0s9H+Uy1Ef8l9+t5WjpZlalNbcZs9W/7HeliuYI8zEJISbBK9Xr+z94qDPHWSGizNZ0aBBwU7qFsIKiBbETOmuOzvmf74XL3nK339/wEHMFzRHr+37fjvAnDl0O/1wlfre/0D6G8Pi4ty9mro6MnNK/u1v7nrd2Ov66ZetKEKDMK7FIyDuuCN8pODrr2d+riGkccklIBobm65BXHllsIAwHbP+CJmsgznb/XV45RXvn15SokbZ/vgjDQQINC0gzDk+u3VTtvjqamW26dbNu09jo1dLFIKiopgmpuJib50HDoTPPlO/r75a1fXdd1W45+efZ+erN9HHyeWoD/qfbr+d/u852YJNAWPOsAUqaumdd+D884nEb2IqKVFhwMuWKdPSJ5+4Dup8ueQSVYcgv4FpBlu6NNjmPH16uIBYujT6HjcDVkC0IKa/S/+v77yTXU74M3CamI16DgEhRVI51MLwv3xxZvmpq3NDFgcOdNcbGoTnWE3RILp1C48o6t8/4wj+jv7BZeJch78nrBvyXBrEgAHBAmLYMPd3UISMif7f/PXs2tWrRZSWqoFtPXu6AsLMS6UFhKklSKmOUV6u6uoXePX1WddYWQm9+sUQEH7z1LBhbs84mYQtt4Ttt1c99y23DHTMZtD1yiUgggT2Tju5+5kCwq9dl5Yqv0Aurdv/H5WWqnvatasSvmH+lTiUlYXXweyMVVZmC3NQ/7F+XvzPZmVl9D1uBqyAaEFMAfH118rMFOQrncEQurKcDhGTyAA5BUSvvjkaSv/LF2emrOJiV+iYaRb8AiJPDcIzO1rUC11RkTEdhM6MFye+3N8462sKMX1kBERRUXDSNHOdWf+guuib4K9DWVlwdA24AsIUINrsYWoEfi3Rf/7GxkAtsWz14szvSBOTWed8/Q4mUQ7hoHImpj8gykQVd5yBvs/aAd4EM26TiOuD6No1d5kCYVNttCD+uUDCOsmb8xVjeZHeZ50YfcAcL2hJecQL8vHHsO++qnEZPlyZdQ46KPp8oNT4igpl6z74YPUS9u7tRpv4BUQyCffeq3qU/qobL7+nUTKjgPxUVmYahaA5fYF4GoRZ5vLL4UTnXpujVo0/LBOiWlSkTEHDhnkT/PkbrU8+UVEsIZPFBNbTH0ZqCIilOA9L//7wxBPqHCNHwpAhKuGbjgIKMiPedJPqBb/+unJsadPGmcYgRmPKytgmplyjlaPQz4cpEJ97Du68U/0f/nImZoMZljgvbN8gdB309TRBQOQc89izpzLD7bCDG74cV0A8+6zKWBsVTlwgrAbRgvgFRJR2KBHh89PGJeoFGTHCTX9wwgnqwdUvf3m5ihn3c/zxahRup04qy2BpqVKDdt012sR0/PGw7bbqukJMTJnImT/9KbrexcWZtzFUg3Aa+XoR4dQzR83+4Q9uvLo+t6/hyWgQxcUqxcm553qPZ5avqFAN8umnq/vlJ0yDKCoK1SAW6eCFzp3hgANULH/37nDVVbl78medpf6jK65Q90Y3hCGTFWUJCK216BBZTR6JGrPQgthsjPfZB556yqtWBwl70zkfZaJqIQ3ip5+yA06yEEL5qUwTYVwBMWAAXHTR2mlsTcQKiBZg4UL44ousrNUZAfFmwLwvjWQnMMsi1wOTqyetBYR+6fV3SP6jyBdnLZ3UJToNRZyXOpcG4TSA9SJGff33MERAVHU0TExBmA2VuW+QgPDXwSREg8hkrw36z83nJE6nQpcPaVyzwlx1z8avQeSRqDELrX3laoyDnoe4fri4AkLXQQvOPKOFevTIIwrWrNPaaGAthBUQLUDv3jB0aPZ6LSB23jl724gRIvfLfuqp2etMW7j/BfFHc+zjZETVScrMvDNBjVeUwMnTSQ0EO9DDUh9vtpnqOUOmAU6TZGb3HdU601zi5NKZXhoUJ4y3fv7zBfVsgcpyn4D49a+9+5nRSqa9YbQzYnubbdx12pylJws6+2x3W4gG8SyO2S2o13/00e5v81hh6D8hREBkTfykB7ptv33z+SD0s9YUAeEnkXD/f1PzzbXvb36jrkGbblrCB2Hev7gaRCtiBUQrEhS0oLnokoC/5t13vcsTJqgpF01WrlQpACC7Qb/+eu/yKaeonpxO/GW23kHCIMrQaoYIQjwNYu+9obYWeeZZboGwl3rmTGV7N+qx3Y5FbLLobXXQm292yx56KNTXc183lbKgeuSY7ONpQeYXEGYsvHk/amu9+40erXwMmrCxD1VV6jjHHquWBwxQKUGkVA0uqHBhfa4QDWIGW6oEhUGDY/bcU+0vJRxzTPb2MEIEhMfElE6rukupzHBm/czw2nxpTgGRTrv//3//645Az7XvnXeqeugQ1rXwQcTGrJMVEJYoTJ+TmTEAIFmSzNYg4vbq9Ysfp4dnvvBrIyBiahCaTNVKSxFL3AiafExMyZJkuFJTXMzCIvXiFy0NGJ2uz+O/R2Ex50b2U/McGcI0CP+6XNdnnrfQ0TQhx9+kl2Fi8gtQ8/qjzGe50AIilzmnKX44M0AiCiG8/2FLCAjzeWvvAkIIMVYI8ZUQYo4Q4uKA7TcKIT5xPrOEECuMbWlj29OFrGdLYYbKAwyu+1w9MK+8kj0QVQSYmKJGMJtoAZGvjdhxJAPBAiJOxEhQFJPBuHHqe999jZXaFxJQPhBt8A0ahGawIKkERENfx4Sm/4BBg9x7G6ZB+BsufS/NBsX8HeaD0MRN7R1iYioIIRpEVVlEplbzfq3N+ACd1HCzzaLL6XscMfdJFrqOcaLZTHSgQpwUJk3FfGbagIAoWJirECIJ3Ab8EpgPfCCEeFpKOUOXkVKea5Q/E9jaOESNlNI320nbw3wG/J3VDlMcteHZZ2EPb07+rIl5ILjxDIok0S9+vg3MP/+pzDjDhgUP445jYvILCF8DPHp0QKfwT39SpoF58+JpPRddpLJz7r57ZLGfk13YhTe478ZhbFz/pWqMZs9WAuLbbwPrlzOtgdnomGXMFz9Kg8hFiImpIJgCYvZsGDxY/Y6a4c788/IxZ/nZf3/13Oea16CyEl57TZmztgyYwyMIrZ3k29DffbeamGVMgEmyuejUSV3ziy+2eyf1tsAcKeXXUsp64BEgKh/z4cDDBaxPqxAVBp+JPQ8KgQjSIIJ6RPUBqae1ipyvqty5s7I3b7NN/o1cmIkpTi+prMx1+uZKFgjKNnfGGWoMQA6msAuNXbqp1Mvduyu7f8+ebr3iahCaMBOTKdiC7lOU9mXSkhqE+XyYAQNRM9zp+7bllmvnpBZCqZFxNMbddot22PnRz1C+A8wGDlTpOeIMGF0bdttNfbcBDaKQAqIPYM6RNt9Zl4UQYiNgIGAGgpYJIaYJId4TQhwQst/JTplpixcvDirS6piDjY85xpc3TPfUbrhB9YpNHn00ngYRNJeubvTWZkKafBu5MA0ibi9J9/YiJWp+TJqkbkVgrrYwE5NeDmskwkxMJgXQIM47L3v20LWmKRFJYfet0ORjLtJhua0wh3Ms9LvRzgVE0BMX5nE6DPiPlNJsTfpLKUcBRwB/E0JkxURKKe+SUo6SUo7qETBt4bqA7uDff7+KMv3oI2Ojbgx//lmlejV58MHsgwW9JDvumD29oRYaQQLi+uvhxhtzV1w3aKNHK3POFlu4YbFBhGkQcQWEzkL6c0iq6SZw8MHq9IFt8zbbKDPH3Xd714dEX2Uw72mYgAgaARlXQATNU4DqQ3z8cbxD5OTFF+Gkk5q27xZbuBPvtCT5CAitQayrAuKEE9TUrbmSCK4DFDLVxnzATIHYFwgbb3gY4JnlRUq5wPn+WgjxOso/0bSZ6lsRLSD8CSMrKsgeWp2LIA2itFSNPjUbFh2SGWRiivtQam2hSxeYOjV+3fwaRFxHuRYQzahBRFJSoiYY8pNLQJhmC32t/t53kGkjh0M9tI6FYO+980/PrSkuVv6ilmZ9EhCVlfC//7V2LWJRSA3iA2CwEGKgEKIEJQSyopGEEJsB3YB3jXXdhFDDYIUQVcBOwAz/vm0Bv4Do0kWFrT/5JM0jIILQAqI5TExx7bFra2IqgAbRJLTpJOxem42Ovma/6S3IXNMUk0xLJY1rC8QNXQVXQMTV2iyhFExASClTwERgMvAl8JiU8gshxFVCCNMmcjjwiJQeg/sWwDQhxHTgNeAaM/qpLeEXEMmkSjH/y1+Sv4CI24vSg6mMaUDzJmzOgjD8PW8dx2rmnolCh0xqB15rkY+JSf8+/nh3XViCLZ2S+5BDctdBC8u4HYL2gO54mPc6DJ100j9ZUltibcaYNCMFzeYqpXweeN637nLf8pUB+70DDPOvb4v4BYSHNWtUVM17ARPEBxG3wdhrL5VBbG38MtqBFtfM4U9dccop6kWN+5IOGaImaQlLcdtS5NIgTCoq1MQeWqv4+edwZ29lpSobJ7Jm7ty1y3PUVFav9s5IFxXu2tIUF6sJdfwz5gVx7bXwu9/FK7uu8s0360QYrE33XWAiBUR1tRt7Hod8zBRr67QPGhgWhX/cgxD59+DWhR5fLg3Cj6kx5ApljTu5S2sFXPjHDQTNe9GaxA11TSYLPpFOwWmKz6oA2FQbBSangIgbHw9NSzvQVLT9O26+nbDUFW2N5ggRtljWE6yAKDA5BUSUI037EDp1UhP1RPUs//1vd37g5uBXv1JZPCdNilc+LDtqW+PAA1Wkl86U+8or7rZ7722dOrUGzz+fu4xlvceamArI3Llq7naI8EFECYgjjlBD/zfcUKUmjiLObHD5kEzCBRfkVx7avoDo29eb9VbP/gXBkyitr+RIY2JpH1gBUUDMAJ4sASFlbg1Cmzla0rTUVMIm4FmfaMtOz3yxIbYWrImpxcgSEKtXqyiFrl3hj38M3mnwYNXghm1fl9hiC+VYa+0w1UJw/fXQq1fb147yYX0W9JbYtKMnvnXJEhA6m2j//nDZZW58/A03uGW6dVPhpnrmsXWZ3XdXGtGRR7Z2TZqf889X88ZaLO0MKyBaiCwBMXOm+tY56LUZyQxvs5E0FoulFbECooD06uX+zhIQF16ovvV80FZAWNYF1rWxD5ZWxTqpC4hpss4SEImE8mLrIfVaQJjOQesotLQ0s2e785RY2j1WQBSI6moVxarJEhA1NTB+vLusU1uETWNpsbQEPXvGHxxpWe+xAqJA+AdIZ6X2WbPGWyhoIharQVgsllbE+iAKgKk5nHUWTJ/uKxA0BkILCDO8sD2FVVoslnUO2wIVgB9/dH/37AnDh/sKNDRkT3UWJCAsFoulFbEmpgKwaJH72+NG+OEHNeeoHmJtBYTFYlmHySkghBATgYeklMtboD7rBaECom9fb0HTB6Gd1NqsZDqwLRaLpRWIo0H0Aj4QQnwE3AtM9s3+ZvGx3BCl8+dHFAzTIOrrrf/BYrG0OjlbISnlZcBg4B7gOGC2EGKSEGLjAtetzWI6qbfeOqJgmIAoLrbTTVosllYnlg9CSimFEIuARUAK6Ab8RwjxkpTyt4WsYFtEC4glS3JMbGUKiN691Xd7yhhqsVjWaeL4IM4CjgWWAHcDF0opG4QQCWA2YAWEw3vvwaxZSkAkEko4RPqczbQGN90EO++sPhaLxbIOEEeDqAIOlFJ+a66UUjYKIfYrTLXaJgcdpAKVdtlF+Z9zBiTpye5B7XDssQWtn8ViseRDHE/o88AyvSCE6CSE2A5ASvlloSrWFqmpUd9vvukbST1lChx/fPYOXbu2SL0sFoulKcTRIG4HtjGW1wSss6AUgmWOKPUIiF12Cd/BYrFY1lHiaBDCDGuVUjZiB9gFUlvr/vbnYsoimYxRyGKxWFqPOALiayHEWUKIYudzNvB1oSvWEF77ZwAAIABJREFUFslLQHTpYkdNWyyWdZo4AuJUYEfgB2A+sB1wciEr1Ra5/HLvALmcAsL6HywWyzpOTlORlPIn4LAWqEubpboa/vhH7zpziEMg/foVrD4Wi8XSHMQZB1EGnAhsCWQyC0kpTyhgvdoUP//s/u7cGVatijEQ2p+XyWKxWNYx4piYHkDlY9obeAPoC6wuZKVanPnzYdddYenSJu1uCghtWgp1L+gcS+aE1RaLxbIOEkdAbCKl/D2wRkr5T2BfYFhhq9XCXHutGrzwwANN2t3MvaRnDA0VEAcfDEceCccd16RzWSwWS0sRJ1y1wfleIYQYisrHNKBgNWoNdAvfxLBTU4PIaVoaMQIuvrhJ57FYLJaWJI4GcZcQohtwGfA0MAP4S0Fr1dI0o4BIp9X3iB8nw+TJ2YW1imGxWCzrOJEahJOQb5UzWdCbwKAWqVVL00QB8d57sHgxpFLuuro69X3ZW2NhLGpuB5NB6+cttFgs6x+RGoQzanpiC9Wl9TCdCHmw884wYQJ88YW7bvx4EDS6K+bNU99/+YuKh/3Vr5peT4vFYmlB4piYXhJCXCCE6CeEqNSfgtesJdECwlQFclBd7RZ/8kn1vXChav/LMIZUz5qlvsvKoLy8GSprsVgsLUMcJ7Ue73CGsU6yPpmbtBOhoSG6nMOLL8JqI9D3Syenbc8xgxnXry+3X/cYXOhsvPJK9W3zLlksljZGnJHUA5t6cCHEWOAmIAncLaW8xrf9RmB3Z7EC6Cml7OpsOxblGAf4kxNiWxh+/FF9x9AgpIRx47zrqquVcpCYOwfmzuHYf1S7AuLTT9X3QQc1X30tFoulBYgzkvqYoPVSyvtz7JcEbgN+icrh9IEQ4mkp5QzjGOca5c8EtnZ+VwJXAKNQ2sqHzr5GtqNmxBkgd9zRKYYuggsuyFk0QyIBjY3O1KI/OCurq90C9fXQv79N7W2xWNoccXwQo43PzsCVwIQY+20LzJFSfi2lrAceAfaPKH848LDze2/gJSnlMkcovISKCWp+dNgRUEwDkyYFF/vxRzjtNNhkE+96nTHDM/e0KSAgRmImi8ViWfeIY2I601wWQnRBpd/IRR/ge2NZZ4LNQgixETAQeDVi3z4B+52Mk1m2f//+MaoUwPLl0LMn/PQTRaSy2nbNX/4Cd9zhXVdaCh07qt8eAeGPipo5s2l1s1gsllYkjgbhpxoYHKNcULIJGbAOVLbY/0gp0/nsK6W8S0o5Sko5qkePHjGqFECvXjBDWb2KaTAVigxz58KNN7rL22+vvjt1MgREN6N6TQybtVgslnWJOD6IZ3Ab5wQwBHgsxrHnA2ZO677AgpCyh+GNkpoP7Obb9/UY52waReo2FBHspH7uOfX98stKKFRUwLBhyq2gBUSfKkOyTJ9esKpaLBZLSxEnzPV643cK+FZKOT/Gfh8Ag4UQA1Hu28OAI/yFhBCbAd2Ad43Vk4FJTooPgL2AS2Kcs2k46S+0gFi+HLp1czd/840SDHvsoZZTKZVr79xz3bRKfSsN29T15i0D9tyzQBW3WCyWwhFHQHwHLJRS1gIIIcqFEAOklPOidpJSpoQQE1GNfRK4V0r5hRDiKmCalPJpp+jhwCO+ea+XCSH+iBIyAFdJKZfldWX54GgQxU5ewvPOg/vuczfX10NJibe43q6HTvTuaggIIWCLLeD991Uujt69C1Z1i8ViKRRxBMS/UVOOatLOutG5dpRSPg8871t3uW/5ypB97wXujVG/tWb+oiL64moQq32zXTQ0hOfYGz5cmZ6SdYaAWLMGxoxRakenToWptMVisRSYOAKiyAlTBUBKWS+EKInaoa3x0ScJNiSRERCNjd7tUQLiiiuUyWn8L9bAH5yVNTVelcNisVjaIHGimBYLITLjHoQQ+wNLClellmflSkhRRDENJJP5CYjOneGmm6DTmkXeDVZAWCyWNk4cDeJU4CEhxK3O8nwgcHR1W2XVKmigmCJSlJfnJyAyfPutd9kKCIvF0saJM1BuLrC9EKIjIKSU69d81CgBoTWIigqVb8kkloC4807vshUQFouljZPTxCSEmCSE6Cql/FlKuVoI0U0I8aeWqFxLoU1MRaSoqAjWICLb+9Wr4ZNPvOusgLBYLG2cOD6IcVLKFXrByY20T+Gq1PKYJqaysiaYmLR56UwjK0lpabPX02KxWFqSOAIiKYTItHZCiHJgvWr9Vq2CtChi3B4NdOmSLSDq62MKiI03dtdZDcJisbRx4jipHwReEULooWPHA4Wbm6EVWLMGKCqm/4YNJOY2wQehBYSZ6tUKCIvF0saJ46S+VgjxKbAnKonei8BGha5YS9LYCHXJcqipyczvYNLQkCNj93ffKYGgc3+DFRAWi6XNEzeb6yKgEfg1sAfwZcFq1Aqk01CbqIDq6lABkVOD6NdPzTutsQLCYrG0cUI1CCHEpqgEe4cDS4FHUWGuu4ft01ZJp6EuqQSEEDEExLXXwlZbwV57wcknw+TJMGKEt5AVEBaLpY0TZWKaCUwBxksp5wAIIc6NKN9maWyE2mQHqF5CokMOASElXHSR+v3TT3D33TBokErvagWExWJZj4gyMf0aZVp6TQjxf0KIPQieyKfNk05DXaIC1qzJbWIyJ6VeuVJ9X3EFHHOMV0DYMFeLxdLGCdUgpJRPAE8IIToABwDnAhsIIW4HnpBS/q+F6lhw0mmoKwr3QQxY8wXd0hvAk2/BrFnuBj16umtX9W01CIvFsh4RJ4ppDfAQKh9TJXAwcDGw3giIxkaoj/BBvLxoqPLAPOrbUU8M1KWL+jYFRHl5oaprsVgsLUJec1JLKZdJKe+UUv6iUBVqDZQG0SFjYvKPg/Dw8cfw/fdeTSJIQJghrxaLxdIGiTNQbr0nnYZ6bWISksbGEFdLZaWKVvITZGLaaL0aKmKxWNoheWkQ6yuNjY6AkJIyarNMTBn8jf5WW6nvzp3VdzLpbquqavZ6WiwWS0tiNQiUBlFTrBr5ivRqGhtD/AfXXutdfuEFeOklpVmAmov6nnvUgDmxXgZ8WSyWdoQVEDgjqUuVH6FTegVS9vRsT5Fkyg4Xsfuee3p33HBDFd5qcsIJhayqxWKxtBjWxIQyMdWUKj9Cx/TKLBOTQELC3iqLxdK+sK0ejompRGkQQQIiSSMiYU1GFoulfWEFBI6AKFMaRIeGFR4BIRudmFfrU7BYLO0MKyBw0n07PoieNd96xkE0pp0Fa2KyWCztDNvqoTSI6jIVifSrmZM8GoQWENbEZLFY2htWQKAERKqsI4wcSSpZGiggrAZhsVjaG7bVQ5mYEglgxx0pSdV4BURKLVgNwmKxtDesgEBpEMkkUFFBh4YVjF/1kLstpTUIKyAsFkv7wgoIvAIC4MbFR2W2uT4Ie6ssFkv7wrZ6GCamDh2yt1kTk8ViaadYAYGhQQTM4WCd1BaLpb1iWz0MAREwEYTVICwWS3vFCggME1NDQ/a2tB1JbbFY2idWQGBoEBECQiTtrbJYLO0L2+qhNIhkEujePXubNTFZLJZ2ihUQKA0ikQCOOw6A14vdeR+sk9pisbRXCtrqCSHGCiG+EkLMEUJcHFLmECHEDCHEF0KIfxnr00KIT5zP04WsZ8bElEjwzQbb0yjd22I1CIvF0l4p2IxyQogkcBvwS2A+8IEQ4mkp5QyjzGDgEmAnKeVyIYQ5lVuNlHJEoepnkjExATKRQODm2rDJ+iwWS3ulkBrEtsAcKeXXUsp64BFgf1+Z3wC3SSmXA0gpfypgfQKRUn1cC5IgIV0BoeeDsE5qi8XS3ihkq9cH+N5Ynu+sM9kU2FQI8bYQ4j0hxFhjW5kQYpqz/oBCVTKdVt+mBgHueIh0gyMsrAZhsVjaGQUzMQFBLap/JFoRMBjYDegLTBFCDJVSrgD6SykXCCEGAa8KIT6TUs71nECIk4GTAfr379+kSurMrVpAIBLBGoR1UlsslnZGIVu9+UA/Y7kvsCCgzFNSygYp5TfAVyiBgZRygfP9NfA6sLX/BFLKu6SUo6SUo3r06NGkSmoNItP+C+H1QWgnddJqEBaLpX1RSAHxATBYCDFQCFECHAb4o5GeBHYHEEJUoUxOXwshugkhSo31OwEzKABZJiafBpFxUtuR1BaLpZ1RMBOTlDIlhJgITAaSwL1Syi+EEFcB06SUTzvb9hJCzADSwIVSyqVCiB2BO4UQjSghdo0Z/dSc+E1Mfh+EHUltsVjaK4X0QSClfB543rfucuO3BM5zPmaZd4BhhaybJtvE5PNBpO04CIvF0j5p991iv4kpywdhNQiLxdJOafetXpCJSZgmJjuS2mKxtFMKamJqC1RVwapVUFLirBAJEjQipcrwbUdSWyyW9kq7FxCJBHTqZKwQwiMg7Ehqi8XSXrGtng+ZUBqENj1lnNR2HITFYmlnWAHhRygfhBYQ6ZQdSW2xWNonttXzoTUIPT21DXO1WCztFSsgfAjHB5ExMTVaJ7XFYmmfWAHhQ4e5agGho5gSRfZWWSyW9oVt9fwIr5PajoOwWCztFSsg/BhhrmDDXC0WS/vFtnp+fCYm66S2WCztFSsg/DhRTDpHk3VSWyyW9ooVED6SxcrEtGaNWrZOaovF0l6xrZ6PkjKlQSxbppaticlisbRXrIDwUVKmfBBaQNh03xaLpb3S7pP1+SktS5A2NYhGq0FYLLloaGhg/vz51NbWtnZVLCGUlZXRt29fiouLY+9jBYSP0jJBLY0sWKDSgNescXwQNlmfxRLK/Pnz6dSpEwMGDLDzt6+DSClZunQp8+fPZ+DAgbH3s3YTH6XlysR09tnQpQtcc40SEEUl9lZZLGHU1tbSvXt3KxzWUYQQdO/ePW8Nz2oQPopKEnTr0sgNzszZvb9phFthg172wbdYorDCYd2mKf+PFRB+hKCsuJHzznOW35Jwq3VSWyyW9odt9fwkEu5E1eD+tr0ji2WdZenSpYwYMYIRI0bQq1cv+vTpk1mur6+PdYzjjz+er776KrLMbbfdxkMPPdQcVW4TWA3CTyJBJhETuL+tgLBY1lm6d+/OJ598AsCVV15Jx44dueCCCzxlpJRIKUmETP5133335TzPGWecsfaVbUNYAeHHr0FoAWFnlLNYYnHOOeC01c3GiBHwt7/lv9+cOXM44IADGDNmDO+//z7PPvssf/jDH/joo4+oqanh0EMP5fLLlcNxzJgx3HrrrQwdOpSqqipOPfVUXnjhBSoqKnjqqafo2bMnl112GVVVVZxzzjmMGTOGMWPG8Oqrr7Jy5Uruu+8+dtxxR9asWcMxxxzDnDlzGDJkCLNnz+buu+9mxIgRnrpdccUVPP/889TU1DBmzBhuv/12hBDMmjWLU089laVLl5JMJnn88ccZMGAAkyZN4uGHHyaRSLDffvtx9dVXN8etjcS2en6EsCYmi2U9YsaMGZx44ol8/PHH9OnTh2uuuYZp06Yxffp0XnrpJWbMmJG1z8qVK9l1112ZPn06O+ywA/fee2/gsaWUTJ06leuuu46rrroKgFtuuYVevXoxffp0Lr74Yj7++OPAfc8++2w++OADPvvsM1auXMmLL74IwOGHH865557L9OnTeeedd+jZsyfPPPMML7zwAlOnTmX69Omcf/75zXR3orEahB9rYrJY1oqm9PQLycYbb8zo0aMzyw8//DD33HMPqVSKBQsWMGPGDIYMGeLZp7y8nHHjxgEwcuRIpkyZEnjsAw88MFNm3rx5ALz11ltcdNFFAGy11VZsueWWgfu+8sorXHfdddTW1rJkyRJGjhzJ9ttvz5IlSxg/fjygBrcBvPzyy5xwwgmUl5cDUFlZ2ZRbkTdWQPgJc1JbE5PF0ibp0KFD5vfs2bO56aabmDp1Kl27duWoo44KHBtQUlKS+Z1MJkmlUoHHLi0tzSojzQ5mCNXV1UycOJGPPvqIPn36cNlll2XqERSOKqVslTBi2+r58ZuYrAZhsaw3rFq1ik6dOtG5c2cWLlzI5MmTm/0cY8aM4bHHHgPgs88+CzRh1dTUkEgkqKqqYvXq1fz3v/8FoFu3blRVVfHMM88AagBidXU1e+21F/fccw81NTUALNO5gAqM1SD8WCe1xbLess022zBkyBCGDh3KoEGD2GmnnZr9HGeeeSbHHHMMw/+/vfsPjqJO8zj+foRA5FcSEkAlCrGWW1mosORSCZyAsNxyggiK0ZDCOpRFPDxhqas6D5E69IA/lkKWorRckJPyarNkPTh+WYJLZXOiqyLJLgQMx4aTWMYgBDagEQoI99wf/Z1xMnZCIJlMhzyvqqnp/k53z2fSMM/0t2e+nZlJVlYWw4cPJykpqdEyqampzJ49m+HDhzNo0CByc3PDjxUWFvL000/zwgsv0K1bN7Zu3crUqVM5dOgQ2dnZJCQk8OCDD7J8+fI2zx5NWnI41BFkZ2draWlp6ze0ZAmsXg2h707v3g1TpsBHH8GoUa3fvjE3oaNHjzJ06NB4xwiEhoYGGhoaSExMpLKykkmTJlFZWUnXrvH/PO63n0SkTFWz/ZaPf+KgsS4mY0wr1NfXM3HiRBoaGlBV1q9fH4jicCM6ZupYspPUxphWSE5OpqysLN4x2oS960Wzr7kaYwxgBeL7QkcKocJgJ6mNMZ2UvetFCx0phLqW7JfUxphOygpEtNCRQqgwWBeTMaaTsgIRzbqYjOlwxo8f/70fva1du5Znnnmm2fV69eoFQE1NDXl5eU1u+1pfoV+7di0XLlwIz0+ZMoVz5861JHqgxfRdT0TuF5FjInJcRBY3scxjIlIhIp+KyG8i2meLSKW7zY5lzqhA3r11MRnTYRQUFFBUVNSoraioiIKCghatf8cdd7Bly5Ybfv7oAvHOO++QnJx8w9sLiph9zVVEugCvAj8FqoEDIrJTVSsilhkCPA/cq6p1ItLftfcFlgHZgAJlbt26WOUNa6qLyY4gjGmZOIz3nZeXx9KlS7l06RLdu3enqqqKmpoaxowZQ319PdOnT6euro4rV66wYsUKpk+f3mj9qqoqpk6dypEjR7h48SJPPvkkFRUVDB06NDy8BcD8+fM5cOAAFy9eJC8vj5deeol169ZRU1PDhAkTSEtLo6SkhMGDB1NaWkpaWhpr1qwJjwY7d+5cFi1aRFVVFZMnT2bMmDF8+OGHDBw4kB07doQH4wvZtWsXK1as4PLly6SmplJYWMiAAQOor69nwYIFlJaWIiIsW7aMRx55hD179rBkyRKuXr1KWloaxcXFrfqzx/J3EDnAcVX9DEBEioDpQOTAJE8Br4be+FX1tGv/O2Cvqv7FrbsXuB/YHMO8nuguJjuCMCbwUlNTycnJYc+ePUyfPp2ioiLy8/MRERITE9m2bRt9+vThzJkzjBo1imnTpjU5+N1rr71Gjx49KC8vp7y8nKysrPBjK1eupG/fvly9epWJEydSXl7OwoULWbNmDSUlJaSlpTXaVllZGZs2bWL//v2oKrm5udx3332kpKRQWVnJ5s2bef3113nsscfYunUrjz/+eKP1x4wZw8cff4yIsHHjRlatWsXLL7/M8uXLSUpK4vDhwwDU1dVRW1vLU089xb59+8jIyGiT8ZpiWSAGAl9EzFcDuVHL/BWAiPwB6AK8qKp7mlh3YPQTiMg8YB7AXXfd1Tap7SS1Ma0Tp/G+Q91MoQIR+tSuqixZsoR9+/Zxyy238OWXX3Lq1Cluu+023+3s27ePhQsXApCZmUlmZmb4sbfeeosNGzbQ0NDAyZMnqaioaPR4tA8++ICHH344PKLsjBkzeP/995k2bRoZGRnhiwhFDhceqbq6mvz8fE6ePMnly5fJyMgAvOG/I7vUUlJS2LVrF+PGjQsv0xZDgsey38TvHTV64KeuwBBgPFAAbBSR5Baui6puUNVsVc3u169fK+M60ecgrIvJmA7hoYceori4OHy1uNAn/8LCQmpraykrK+PgwYMMGDDAd4jvSH5HFydOnGD16tUUFxdTXl7OAw88cM3tNDfWXWiocGh6SPEFCxbw7LPPcvjwYdavXx9+Pr/hv2MxJHgs3/WqgTsj5tOBGp9ldqjqFVU9ARzDKxgtWTc2oo8grIvJmA6hV69ejB8/njlz5jQ6OX3+/Hn69+9PQkICJSUlfP75581uZ9y4cRQWFgJw5MgRysvLAW+o8J49e5KUlMSpU6fYvXt3eJ3evXvzzTff+G5r+/btXLhwgW+//ZZt27YxduzYFr+m8+fPM3Cg13ny5ptvhtsnTZrEK6+8Ep6vq6tj9OjRvPfee5w4cQJomyHBY1kgDgBDRCRDRLoBM4GdUctsByYAiEgaXpfTZ8C7wCQRSRGRFGCSa4u9UIEYPRqGDYPnnvPmrUAYE3gFBQUcOnSImTNnhttmzZpFaWkp2dnZFBYWcs899zS7jfnz51NfX09mZiarVq0iJycH8K4ON3LkSIYNG8acOXMaDRU+b948Jk+ezIQJExptKysriyeeeIKcnBxyc3OZO3cuI0eObPHrefHFF3n00UcZO3Zso/MbS5cupa6ujuHDhzNixAhKSkro168fGzZsYMaMGYwYMYL8/PwWP09TYjrct4hMAdbinV94Q1VXisi/AaWqulO846GX8U5AXwVWqmqRW3cOsMRtaqWqbmruudpsuO/KSli2DK5c+a6tXz9Ytw466IiMxsSaDffdMVzvcN92PQhjTKtZgegYrrdA2JlXY4wxvqxAGGPaxM3SG3GzupH9YwXCGNNqiYmJnD171opEQKkqZ8+eJTEx8brWs7OuxphWS09Pp7q6mtra2nhHMU1ITEwkPT39utaxAmGMabWEhITwL3jNzcO6mIwxxviyAmGMMcaXFQhjjDG+bpofyolILdD8ICtNSwPOtGGcWLCMrRf0fBD8jEHPB5bxeg1SVd/RTm+aAtEaIlLa1C8Jg8Iytl7Q80HwMwY9H1jGtmRdTMYYY3xZgTDGGOPLCoRnQ7wDtIBlbL2g54PgZwx6PrCMbcbOQRhjjPFlRxDGGGN8WYEwxhjjq9MXCBG5X0SOichxEVkcxxxviMhpETkS0dZXRPaKSKW7T3HtIiLrXOZyEclqh3x3ikiJiBwVkU9F5OcBzJgoIp+IyCGX8SXXniEi+13G37pL4CIi3d38cff44FhndM/bRUT+JCJvBzRflYgcFpGDIlLq2oK0n5NFZIuI/I/79zg6YPl+6P52odvXIrIoSBlbTFU77Q3vUqj/C9wNdAMOAT+KU5ZxQBZwJKJtFbDYTS8GfuGmpwC7AQFGAfvbId/tQJab7g38GfhRwDIK0MtNJwD73XO/Bcx07b8C5rvpZ4BfuemZwG/baV//E/Ab4G03H7R8VUBaVFuQ9vObwFw33Q1IDlK+qKxdgK+AQUHN2Gz+eAeI64uH0cC7EfPPA8/HMc/gqAJxDLjdTd8OHHPT64ECv+XaMesO4KdBzQj0AP4I5OL9YrVr9D4H3gVGu+mubjmJca50oBj4CfC2e1MITD73XH4FIhD7GegDnIj+OwQln0/eScAfgpyxuVtn72IaCHwRMV/t2oJigKqeBHD3/V17XHO7ro6ReJ/QA5XRdd8cBE4De/GOEM+paoNPjnBG9/h5IDXGEdcCzwH/5+ZTA5YPQIHfiUiZiMxzbUHZz3cDtcAm1023UUR6BihftJnAZjcd1IxN6uwFQnzaOsL3fuOWW0R6AVuBRar6dXOL+rTFPKOqXlXVH+N9Us8Bhvot5u7bNaOITAVOq2pZZHMzGeK1n+9V1SxgMvCPIjKumWXbO2NXvK7Y11R1JPAtXndNU+L5f6UbMA34z2st6tMWiPehzl4gqoE7I+bTgZo4ZfFzSkRuB3D3p117XHKLSAJecShU1f8KYsYQVT0H/Dden26yiIQujhWZI5zRPZ4E/CWGse4FpolIFVCE1820NkD5AFDVGnd/GtiGV2iDsp+rgWpV3e/mt+AVjKDkizQZ+KOqnnLzQczYrM5eIA4AQ9y3SLrhHQ7ujHOmSDuB2W56Nl6/f6j97923H0YB50OHrrEiIgL8O3BUVdcENGM/EUl207cCfwscBUqAvCYyhrLnAb9X1wkcC6r6vKqmq+pgvH9rv1fVWUHJByAiPUWkd2garw/9CAHZz6r6FfCFiPzQNU0EKoKSL0oB33UvhbIELWPz4n0SJN43vG8Q/Bmvr/qFOObYDJwEruB9ovgZXn9zMVDp7vu6ZQV41WU+DGS3Q74xeIe95cBBd5sSsIyZwJ9cxiPAv7r2u4FPgON4h/vdXXuimz/uHr+7Hff3eL77FlNg8rksh9zt09D/iYDt5x8DpW4/bwdSgpTPPW8P4CyQFNEWqIwtudlQG8YYY3x19i4mY4wxTbACYYwxxpcVCGOMMb6sQBhjjPFlBcIYY4wvKxDGXIOIXI0anbPNRv0VkcESMYKvMUHS9dqLGNPpXVRv+A5jOhU7gjDmBrnrJvxCvGtQfCIiP3Dtg0Sk2I3tXywid7n2ASKyTbzrVRwSkb9xm+oiIq+Ldw2L37lfgSMiC0Wkwm2nKE4v03RiViCMubZbo7qY8iMe+1pVc4BX8MZVwk3/h6pmAoXAOte+DnhPVUfgjR/0qWsfAryqqsOAc8Ajrn0xMNJt5x9i9eKMaYr9ktqYaxCRelXt5dNeBfxEVT9zAxl+paqpInIGbzz/K679pKqmiUgtkK6qlyK2MRjYq6pD3Py/AAmqukJE9gD1eMNJbFfV+hi/VGMasSMIY1pHm5huahk/lyKmr/LducEH8Mbo+WugLGLEV2PahRUIY1onP+L+Izf9Id5orQCzgA/cdDEwH8IXNurT1EZF5BbgTlUtwbvAUDLwvaMYY2LJPpEYc223uqvUhexR1dBXXbuLyH68D1sFrm0h8IaI/DPe1c+edO0/BzaIyM/wjhTm443g66cL8GsRScIb7fOX6l3jwph2Y+cgjLlB7hxEtqqeiXcWY2LBupiMMcb4siMIY4ytZmyaAAAAKElEQVQxvuwIwhhjjC8rEMYYY3xZgTDGGOPLCoQxxhhfViCMMcb4+n/3RxPFk7ldbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "loss_values = history_dict['loss'] \n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Training loss') \n",
    "plt.plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history_dict['accuracy'] \n",
    "val_acc = history_dict['val_accuracy']\n",
    "plt.plot(epochs, acc, 'b', label='Training acc') \n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc') \n",
    "plt.title('Training and validation accuracy') \n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# make class predictions with the model\n",
    "#predictions = model.predict_classes(dev_X.T)\n",
    "#for i in range(dev_X.shape[1]):\n",
    "#    if predictions[i] != dev_Y.T[i]:\n",
    "#        print('%s => %d (expected %d)' % (dev_X.T[i].tolist(), predictions[i], dev_Y.T[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "test_X= data_train(\"test.csv\", split = False)\n",
    "predict = model.predict_classes(test_X.T)\n",
    "predictions = predict.tolist()\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\n",
    "output['Survived'] = output['Survived'].str.get(0)\n",
    "output.to_csv('my_submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "#model = load_model('model.h5')\n",
    "# summarize model.\n",
    "#model.summary()\n",
    "model.save(\"model_titanic.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
