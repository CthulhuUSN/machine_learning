{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MODEL_NO_QUANT_TFLITE = 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = 'model.cc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 910\n",
      "train_set_x shape: (910, 1)\n",
      "train_set_y shape: (910, 1)\n",
      "Number of dev examples: m_test = 195\n",
      "test_set_x shape: (195, 1)\n",
      "test_set_y shape: (195, 1)\n",
      "Number of testing examples: m_train = 195\n",
      "train_set_x shape: (195, 1)\n",
      "train_set_y shape: (195, 1)\n"
     ]
    }
   ],
   "source": [
    "#The data processing for the training and testing data sets\n",
    "def data_train(filename, split = True):\n",
    "    train_data = pd.read_excel(filename)\n",
    "    train_data['Data'] = train_data['Data'] / 10000000\n",
    "    \n",
    "    tmp = train_data[['Data']].copy()\n",
    "\n",
    "    X = pd.DataFrame(tmp).to_numpy()\n",
    "    X = np.float32(X)\n",
    "    \n",
    "    if split == True:\n",
    "        m = X.shape[0]\n",
    "        Y = np.array([train_data['Active Attack'].values])\n",
    "        Y = np.float32(Y)\n",
    "        Y = Y.T\n",
    "        \n",
    "        #Shuffle (X, Y)\n",
    "        permutation = list(np.random.permutation(m))\n",
    "        shuff_X = X[permutation, :]\n",
    "        shuff_Y = Y[permutation, :]\n",
    "    \n",
    "        devM = round(m * .3) # 30% of the set\n",
    "        devM2 = m - devM # 70% of the set\n",
    "        devM3 = round(devM / 2) #15% of the set\n",
    "        \n",
    "        train_X = shuff_X[0:(devM2), :]\n",
    "        train_Y = shuff_Y[0:(devM2), :]\n",
    "        dev_X = shuff_X[-(devM):-(devM3), :]\n",
    "        dev_Y = shuff_Y[-(devM):-(devM3), :]\n",
    "        test_X = shuff_X[-(devM3):, :]\n",
    "        test_Y = shuff_Y[-(devM3):, :]\n",
    "        \n",
    "        m_train = train_X.shape[0]\n",
    "        m_dev = dev_X.shape[0]\n",
    "        m_test = test_X.shape[0]\n",
    "        \n",
    "        print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "        print (\"train_set_x shape: \" + str(train_X.shape))\n",
    "        print (\"train_set_y shape: \" + str(train_Y.shape))\n",
    "        print (\"Number of dev examples: m_test = \" + str(m_dev))\n",
    "        print (\"test_set_x shape: \" + str(dev_X.shape))\n",
    "        print (\"test_set_y shape: \" + str(dev_Y.shape))       \n",
    "        print (\"Number of testing examples: m_train = \" + str(m_test))\n",
    "        print (\"train_set_x shape: \" + str(test_X.shape))\n",
    "        print (\"train_set_y shape: \" + str(test_Y.shape))\n",
    "    \n",
    "        return train_X, train_Y, dev_X, dev_Y, test_X, test_Y\n",
    "    \n",
    "    return X\n",
    "    \n",
    "train_X, train_Y, dev_X, dev_Y, test_X, test_Y = data_train(\"PuttyData.xlsx\", split = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 910 samples, validate on 195 samples\n",
      "Epoch 1/300\n",
      "910/910 [==============================] - 1s 660us/sample - loss: 0.9121 - mae: 0.9113 - val_loss: 0.6766 - val_mae: 0.7774\n",
      "Epoch 2/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.5889 - mae: 0.7392 - val_loss: 0.4536 - val_mae: 0.6444\n",
      "Epoch 3/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.3854 - mae: 0.5967 - val_loss: 0.2802 - val_mae: 0.4987\n",
      "Epoch 4/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.2289 - mae: 0.4302 - val_loss: 0.1803 - val_mae: 0.3467\n",
      "Epoch 5/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.1571 - mae: 0.2815 - val_loss: 0.1573 - val_mae: 0.2620\n",
      "Epoch 6/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.1431 - mae: 0.2618 - val_loss: 0.1537 - val_mae: 0.2878\n",
      "Epoch 7/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.1367 - mae: 0.2633 - val_loss: 0.1468 - val_mae: 0.2710\n",
      "Epoch 8/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.1293 - mae: 0.2419 - val_loss: 0.1403 - val_mae: 0.2522\n",
      "Epoch 9/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.1226 - mae: 0.2265 - val_loss: 0.1349 - val_mae: 0.2428\n",
      "Epoch 10/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.1162 - mae: 0.2163 - val_loss: 0.1299 - val_mae: 0.2343\n",
      "Epoch 11/300\n",
      "910/910 [==============================] - 0s 67us/sample - loss: 0.1102 - mae: 0.2098 - val_loss: 0.1255 - val_mae: 0.2289\n",
      "Epoch 12/300\n",
      "910/910 [==============================] - 0s 68us/sample - loss: 0.1047 - mae: 0.1991 - val_loss: 0.1211 - val_mae: 0.2172\n",
      "Epoch 13/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0996 - mae: 0.1872 - val_loss: 0.1170 - val_mae: 0.2084\n",
      "Epoch 14/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0951 - mae: 0.1794 - val_loss: 0.1131 - val_mae: 0.2024\n",
      "Epoch 15/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.0906 - mae: 0.1811 - val_loss: 0.1086 - val_mae: 0.2055\n",
      "Epoch 16/300\n",
      "910/910 [==============================] - 0s 68us/sample - loss: 0.0860 - mae: 0.1718 - val_loss: 0.1051 - val_mae: 0.1951\n",
      "Epoch 17/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0817 - mae: 0.1683 - val_loss: 0.1013 - val_mae: 0.1951\n",
      "Epoch 18/300\n",
      "910/910 [==============================] - 0s 70us/sample - loss: 0.0781 - mae: 0.1686 - val_loss: 0.0988 - val_mae: 0.1922\n",
      "Epoch 19/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0752 - mae: 0.1593 - val_loss: 0.0972 - val_mae: 0.1846\n",
      "Epoch 20/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0729 - mae: 0.1556 - val_loss: 0.0956 - val_mae: 0.1850\n",
      "Epoch 21/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0709 - mae: 0.1532 - val_loss: 0.0947 - val_mae: 0.1808\n",
      "Epoch 22/300\n",
      "910/910 [==============================] - 0s 52us/sample - loss: 0.0696 - mae: 0.1547 - val_loss: 0.0936 - val_mae: 0.1834\n",
      "Epoch 23/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0684 - mae: 0.1493 - val_loss: 0.0933 - val_mae: 0.1763\n",
      "Epoch 24/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0675 - mae: 0.1476 - val_loss: 0.0927 - val_mae: 0.1761\n",
      "Epoch 25/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0668 - mae: 0.1429 - val_loss: 0.0922 - val_mae: 0.1723\n",
      "Epoch 26/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0660 - mae: 0.1415 - val_loss: 0.0915 - val_mae: 0.1741\n",
      "Epoch 27/300\n",
      "910/910 [==============================] - 0s 52us/sample - loss: 0.0654 - mae: 0.1405 - val_loss: 0.0910 - val_mae: 0.1717\n",
      "Epoch 28/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0647 - mae: 0.1425 - val_loss: 0.0903 - val_mae: 0.1739\n",
      "Epoch 29/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0642 - mae: 0.1418 - val_loss: 0.0897 - val_mae: 0.1719\n",
      "Epoch 30/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0635 - mae: 0.1373 - val_loss: 0.0893 - val_mae: 0.1668\n",
      "Epoch 31/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0629 - mae: 0.1392 - val_loss: 0.0884 - val_mae: 0.1699\n",
      "Epoch 32/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0623 - mae: 0.1394 - val_loss: 0.0878 - val_mae: 0.1667\n",
      "Epoch 33/300\n",
      "910/910 [==============================] - 0s 73us/sample - loss: 0.0617 - mae: 0.1364 - val_loss: 0.0872 - val_mae: 0.1655\n",
      "Epoch 34/300\n",
      "910/910 [==============================] - 0s 67us/sample - loss: 0.0612 - mae: 0.1337 - val_loss: 0.0866 - val_mae: 0.1626\n",
      "Epoch 35/300\n",
      "910/910 [==============================] - 0s 66us/sample - loss: 0.0606 - mae: 0.1378 - val_loss: 0.0855 - val_mae: 0.1684\n",
      "Epoch 36/300\n",
      "910/910 [==============================] - 0s 71us/sample - loss: 0.0600 - mae: 0.1347 - val_loss: 0.0850 - val_mae: 0.1627\n",
      "Epoch 37/300\n",
      "910/910 [==============================] - 0s 66us/sample - loss: 0.0593 - mae: 0.1341 - val_loss: 0.0840 - val_mae: 0.1642\n",
      "Epoch 38/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0587 - mae: 0.1322 - val_loss: 0.0835 - val_mae: 0.1595\n",
      "Epoch 39/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0581 - mae: 0.1326 - val_loss: 0.0825 - val_mae: 0.1617\n",
      "Epoch 40/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.0574 - mae: 0.1322 - val_loss: 0.0818 - val_mae: 0.1595\n",
      "Epoch 41/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0570 - mae: 0.1202 - val_loss: 0.0815 - val_mae: 0.1542\n",
      "Epoch 42/300\n",
      "910/910 [==============================] - 0s 67us/sample - loss: 0.0564 - mae: 0.1381 - val_loss: 0.0801 - val_mae: 0.1674\n",
      "Epoch 43/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0556 - mae: 0.1292 - val_loss: 0.0797 - val_mae: 0.1517\n",
      "Epoch 44/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0549 - mae: 0.1272 - val_loss: 0.0787 - val_mae: 0.1552\n",
      "Epoch 45/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0542 - mae: 0.1240 - val_loss: 0.0781 - val_mae: 0.1517\n",
      "Epoch 46/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0535 - mae: 0.1213 - val_loss: 0.0773 - val_mae: 0.1502\n",
      "Epoch 47/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.0529 - mae: 0.1217 - val_loss: 0.0764 - val_mae: 0.1505\n",
      "Epoch 48/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0522 - mae: 0.1208 - val_loss: 0.0757 - val_mae: 0.1498\n",
      "Epoch 49/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0516 - mae: 0.1212 - val_loss: 0.0748 - val_mae: 0.1493\n",
      "Epoch 50/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0509 - mae: 0.1167 - val_loss: 0.0740 - val_mae: 0.1472\n",
      "Epoch 51/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0502 - mae: 0.1157 - val_loss: 0.0731 - val_mae: 0.1471\n",
      "Epoch 52/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0496 - mae: 0.1184 - val_loss: 0.0720 - val_mae: 0.1486\n",
      "Epoch 53/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0490 - mae: 0.1215 - val_loss: 0.0714 - val_mae: 0.1438\n",
      "Epoch 54/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0483 - mae: 0.1146 - val_loss: 0.0706 - val_mae: 0.1416\n",
      "Epoch 55/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0476 - mae: 0.1154 - val_loss: 0.0697 - val_mae: 0.1433\n",
      "Epoch 56/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0470 - mae: 0.1117 - val_loss: 0.0691 - val_mae: 0.1389\n",
      "Epoch 57/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0464 - mae: 0.1102 - val_loss: 0.0681 - val_mae: 0.1401\n",
      "Epoch 58/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0457 - mae: 0.1111 - val_loss: 0.0674 - val_mae: 0.1384\n",
      "Epoch 59/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0451 - mae: 0.1162 - val_loss: 0.0662 - val_mae: 0.1414\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0443 - mae: 0.1123 - val_loss: 0.0655 - val_mae: 0.1370\n",
      "Epoch 61/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0436 - mae: 0.1072 - val_loss: 0.0647 - val_mae: 0.1357\n",
      "Epoch 62/300\n",
      "910/910 [==============================] - ETA: 0s - loss: 0.0266 - mae: 0.087 - 0s 60us/sample - loss: 0.0430 - mae: 0.1093 - val_loss: 0.0637 - val_mae: 0.1363\n",
      "Epoch 63/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0424 - mae: 0.1046 - val_loss: 0.0631 - val_mae: 0.1326\n",
      "Epoch 64/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0417 - mae: 0.1039 - val_loss: 0.0621 - val_mae: 0.1351\n",
      "Epoch 65/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0411 - mae: 0.1151 - val_loss: 0.0609 - val_mae: 0.1350\n",
      "Epoch 66/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0403 - mae: 0.1037 - val_loss: 0.0601 - val_mae: 0.1321\n",
      "Epoch 67/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0396 - mae: 0.1070 - val_loss: 0.0591 - val_mae: 0.1319\n",
      "Epoch 68/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0388 - mae: 0.1075 - val_loss: 0.0581 - val_mae: 0.1302\n",
      "Epoch 69/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0380 - mae: 0.0996 - val_loss: 0.0575 - val_mae: 0.1252\n",
      "Epoch 70/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0373 - mae: 0.1020 - val_loss: 0.0563 - val_mae: 0.1290\n",
      "Epoch 71/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0366 - mae: 0.0960 - val_loss: 0.0557 - val_mae: 0.1211\n",
      "Epoch 72/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0359 - mae: 0.0965 - val_loss: 0.0547 - val_mae: 0.1224\n",
      "Epoch 73/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0351 - mae: 0.0989 - val_loss: 0.0537 - val_mae: 0.1223\n",
      "Epoch 74/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0343 - mae: 0.0951 - val_loss: 0.0528 - val_mae: 0.1203\n",
      "Epoch 75/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0337 - mae: 0.0951 - val_loss: 0.0520 - val_mae: 0.1159\n",
      "Epoch 76/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0329 - mae: 0.0909 - val_loss: 0.0511 - val_mae: 0.1148\n",
      "Epoch 77/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0322 - mae: 0.0848 - val_loss: 0.0503 - val_mae: 0.1159\n",
      "Epoch 78/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0315 - mae: 0.0951 - val_loss: 0.0491 - val_mae: 0.1151\n",
      "Epoch 79/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0305 - mae: 0.0849 - val_loss: 0.0481 - val_mae: 0.1074\n",
      "Epoch 80/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0295 - mae: 0.0848 - val_loss: 0.0467 - val_mae: 0.1125\n",
      "Epoch 81/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0284 - mae: 0.0865 - val_loss: 0.0454 - val_mae: 0.1053\n",
      "Epoch 82/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0274 - mae: 0.0778 - val_loss: 0.0443 - val_mae: 0.1044\n",
      "Epoch 83/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0263 - mae: 0.0791 - val_loss: 0.0432 - val_mae: 0.0951\n",
      "Epoch 84/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0252 - mae: 0.0717 - val_loss: 0.0413 - val_mae: 0.0992\n",
      "Epoch 85/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0241 - mae: 0.0760 - val_loss: 0.0398 - val_mae: 0.0999\n",
      "Epoch 86/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0231 - mae: 0.0752 - val_loss: 0.0389 - val_mae: 0.0898\n",
      "Epoch 87/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0220 - mae: 0.0694 - val_loss: 0.0374 - val_mae: 0.0907\n",
      "Epoch 88/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0210 - mae: 0.0627 - val_loss: 0.0361 - val_mae: 0.0897\n",
      "Epoch 89/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0200 - mae: 0.0683 - val_loss: 0.0348 - val_mae: 0.0838\n",
      "Epoch 90/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0189 - mae: 0.0590 - val_loss: 0.0336 - val_mae: 0.0844\n",
      "Epoch 91/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0181 - mae: 0.0662 - val_loss: 0.0323 - val_mae: 0.0779\n",
      "Epoch 92/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0172 - mae: 0.0525 - val_loss: 0.0314 - val_mae: 0.0737\n",
      "Epoch 93/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0163 - mae: 0.0557 - val_loss: 0.0300 - val_mae: 0.0767\n",
      "Epoch 94/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0155 - mae: 0.0519 - val_loss: 0.0294 - val_mae: 0.0711\n",
      "Epoch 95/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0149 - mae: 0.0503 - val_loss: 0.0285 - val_mae: 0.0671\n",
      "Epoch 96/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0142 - mae: 0.0473 - val_loss: 0.0278 - val_mae: 0.0644\n",
      "Epoch 97/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0139 - mae: 0.0490 - val_loss: 0.0271 - val_mae: 0.0653\n",
      "Epoch 98/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0132 - mae: 0.0421 - val_loss: 0.0270 - val_mae: 0.0607\n",
      "Epoch 99/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0129 - mae: 0.0408 - val_loss: 0.0263 - val_mae: 0.0593\n",
      "Epoch 100/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0126 - mae: 0.0406 - val_loss: 0.0258 - val_mae: 0.0563\n",
      "Epoch 101/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0122 - mae: 0.0367 - val_loss: 0.0256 - val_mae: 0.0555\n",
      "Epoch 102/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0120 - mae: 0.0402 - val_loss: 0.0251 - val_mae: 0.0543\n",
      "Epoch 103/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0117 - mae: 0.0355 - val_loss: 0.0248 - val_mae: 0.0538\n",
      "Epoch 104/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0115 - mae: 0.0346 - val_loss: 0.0247 - val_mae: 0.0515\n",
      "Epoch 105/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0113 - mae: 0.0345 - val_loss: 0.0245 - val_mae: 0.0505\n",
      "Epoch 106/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0112 - mae: 0.0319 - val_loss: 0.0243 - val_mae: 0.0486\n",
      "Epoch 107/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0110 - mae: 0.0322 - val_loss: 0.0241 - val_mae: 0.0494\n",
      "Epoch 108/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0110 - mae: 0.0304 - val_loss: 0.0240 - val_mae: 0.0469\n",
      "Epoch 109/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0108 - mae: 0.0317 - val_loss: 0.0238 - val_mae: 0.0459\n",
      "Epoch 110/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0107 - mae: 0.0288 - val_loss: 0.0238 - val_mae: 0.0452\n",
      "Epoch 111/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0106 - mae: 0.0287 - val_loss: 0.0237 - val_mae: 0.0454\n",
      "Epoch 112/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0106 - mae: 0.0280 - val_loss: 0.0235 - val_mae: 0.0447\n",
      "Epoch 113/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0105 - mae: 0.0306 - val_loss: 0.0232 - val_mae: 0.0460\n",
      "Epoch 114/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0105 - mae: 0.0292 - val_loss: 0.0234 - val_mae: 0.0415\n",
      "Epoch 115/300\n",
      "910/910 [==============================] - 0s 52us/sample - loss: 0.0104 - mae: 0.0258 - val_loss: 0.0236 - val_mae: 0.0395\n",
      "Epoch 116/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0104 - mae: 0.0271 - val_loss: 0.0233 - val_mae: 0.0407\n",
      "Epoch 117/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0103 - mae: 0.0248 - val_loss: 0.0234 - val_mae: 0.0389\n",
      "Epoch 118/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0103 - mae: 0.0253 - val_loss: 0.0234 - val_mae: 0.0385\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0103 - mae: 0.0241 - val_loss: 0.0231 - val_mae: 0.0407\n",
      "Epoch 120/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0103 - mae: 0.0242 - val_loss: 0.0231 - val_mae: 0.0407\n",
      "Epoch 121/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0102 - mae: 0.0251 - val_loss: 0.0231 - val_mae: 0.0394\n",
      "Epoch 122/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0102 - mae: 0.0233 - val_loss: 0.0231 - val_mae: 0.0397\n",
      "Epoch 123/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0102 - mae: 0.0231 - val_loss: 0.0231 - val_mae: 0.0385\n",
      "Epoch 124/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0102 - mae: 0.0227 - val_loss: 0.0231 - val_mae: 0.0365\n",
      "Epoch 125/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0101 - mae: 0.0230 - val_loss: 0.0229 - val_mae: 0.0388\n",
      "Epoch 126/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0101 - mae: 0.0235 - val_loss: 0.0229 - val_mae: 0.0381\n",
      "Epoch 127/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0101 - mae: 0.0235 - val_loss: 0.0229 - val_mae: 0.0372\n",
      "Epoch 128/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0101 - mae: 0.0219 - val_loss: 0.0230 - val_mae: 0.0365\n",
      "Epoch 129/300\n",
      "910/910 [==============================] - ETA: 0s - loss: 2.9425e-04 - mae: 0.010 - 0s 57us/sample - loss: 0.0101 - mae: 0.0223 - val_loss: 0.0229 - val_mae: 0.0362\n",
      "Epoch 130/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0101 - mae: 0.0228 - val_loss: 0.0229 - val_mae: 0.0362\n",
      "Epoch 131/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0101 - mae: 0.0218 - val_loss: 0.0230 - val_mae: 0.0356\n",
      "Epoch 132/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0101 - mae: 0.0221 - val_loss: 0.0229 - val_mae: 0.0358\n",
      "Epoch 133/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0101 - mae: 0.0201 - val_loss: 0.0229 - val_mae: 0.0357\n",
      "Epoch 134/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0101 - mae: 0.0255 - val_loss: 0.0225 - val_mae: 0.0383\n",
      "Epoch 135/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0100 - mae: 0.0218 - val_loss: 0.0228 - val_mae: 0.0352\n",
      "Epoch 136/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0101 - mae: 0.0247 - val_loss: 0.0225 - val_mae: 0.0387\n",
      "Epoch 137/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0100 - mae: 0.0231 - val_loss: 0.0227 - val_mae: 0.0352\n",
      "Epoch 138/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0100 - mae: 0.0202 - val_loss: 0.0228 - val_mae: 0.0343\n",
      "Epoch 139/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0100 - mae: 0.0211 - val_loss: 0.0226 - val_mae: 0.0361\n",
      "Epoch 140/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0100 - mae: 0.0220 - val_loss: 0.0225 - val_mae: 0.0363\n",
      "Epoch 141/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0100 - mae: 0.0231 - val_loss: 0.0226 - val_mae: 0.0357\n",
      "Epoch 142/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0100 - mae: 0.0224 - val_loss: 0.0226 - val_mae: 0.0352\n",
      "Epoch 143/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0100 - mae: 0.0198 - val_loss: 0.0227 - val_mae: 0.0346\n",
      "Epoch 144/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0099 - mae: 0.0208 - val_loss: 0.0224 - val_mae: 0.0361\n",
      "Epoch 145/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0099 - mae: 0.0205 - val_loss: 0.0225 - val_mae: 0.0357\n",
      "Epoch 146/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0101 - mae: 0.0267 - val_loss: 0.0222 - val_mae: 0.0377\n",
      "Epoch 147/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0099 - mae: 0.0205 - val_loss: 0.0227 - val_mae: 0.0333\n",
      "Epoch 148/300\n",
      "910/910 [==============================] - 0s 67us/sample - loss: 0.0099 - mae: 0.0201 - val_loss: 0.0225 - val_mae: 0.0351\n",
      "Epoch 149/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0100 - mae: 0.0247 - val_loss: 0.0223 - val_mae: 0.0365\n",
      "Epoch 150/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0099 - mae: 0.0224 - val_loss: 0.0224 - val_mae: 0.0350\n",
      "Epoch 151/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0099 - mae: 0.0197 - val_loss: 0.0225 - val_mae: 0.0343\n",
      "Epoch 152/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0099 - mae: 0.0193 - val_loss: 0.0224 - val_mae: 0.0343\n",
      "Epoch 153/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.0098 - mae: 0.0211 - val_loss: 0.0223 - val_mae: 0.0347\n",
      "Epoch 154/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0098 - mae: 0.0199 - val_loss: 0.0223 - val_mae: 0.0346\n",
      "Epoch 155/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0099 - mae: 0.0241 - val_loss: 0.0220 - val_mae: 0.0379\n",
      "Epoch 156/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0098 - mae: 0.0213 - val_loss: 0.0224 - val_mae: 0.0340\n",
      "Epoch 157/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0098 - mae: 0.0200 - val_loss: 0.0222 - val_mae: 0.0347\n",
      "Epoch 158/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0098 - mae: 0.0208 - val_loss: 0.0222 - val_mae: 0.0353\n",
      "Epoch 159/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0098 - mae: 0.0191 - val_loss: 0.0222 - val_mae: 0.0343\n",
      "Epoch 160/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0099 - mae: 0.0253 - val_loss: 0.0218 - val_mae: 0.0390\n",
      "Epoch 161/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0098 - mae: 0.0217 - val_loss: 0.0223 - val_mae: 0.0339\n",
      "Epoch 162/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0098 - mae: 0.0184 - val_loss: 0.0221 - val_mae: 0.0348\n",
      "Epoch 163/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0098 - mae: 0.0242 - val_loss: 0.0218 - val_mae: 0.0381\n",
      "Epoch 164/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0097 - mae: 0.0210 - val_loss: 0.0222 - val_mae: 0.0328\n",
      "Epoch 165/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0097 - mae: 0.0185 - val_loss: 0.0221 - val_mae: 0.0348\n",
      "Epoch 166/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0097 - mae: 0.0236 - val_loss: 0.0218 - val_mae: 0.0374\n",
      "Epoch 167/300\n",
      "910/910 [==============================] - 0s 51us/sample - loss: 0.0097 - mae: 0.0226 - val_loss: 0.0220 - val_mae: 0.0343\n",
      "Epoch 168/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0097 - mae: 0.0188 - val_loss: 0.0220 - val_mae: 0.0337\n",
      "Epoch 169/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.0097 - mae: 0.0194 - val_loss: 0.0219 - val_mae: 0.0343\n",
      "Epoch 170/300\n",
      "910/910 [==============================] - 0s 68us/sample - loss: 0.0097 - mae: 0.0188 - val_loss: 0.0220 - val_mae: 0.0343\n",
      "Epoch 171/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0097 - mae: 0.0223 - val_loss: 0.0218 - val_mae: 0.0350\n",
      "Epoch 172/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0097 - mae: 0.0218 - val_loss: 0.0219 - val_mae: 0.0344\n",
      "Epoch 173/300\n",
      "910/910 [==============================] - 0s 66us/sample - loss: 0.0097 - mae: 0.0199 - val_loss: 0.0218 - val_mae: 0.0347\n",
      "Epoch 174/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0096 - mae: 0.0198 - val_loss: 0.0219 - val_mae: 0.0328\n",
      "Epoch 175/300\n",
      "910/910 [==============================] - 0s 51us/sample - loss: 0.0096 - mae: 0.0203 - val_loss: 0.0217 - val_mae: 0.0345\n",
      "Epoch 176/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0096 - mae: 0.0205 - val_loss: 0.0217 - val_mae: 0.0351\n",
      "Epoch 177/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0096 - mae: 0.0220 - val_loss: 0.0218 - val_mae: 0.0344\n",
      "Epoch 178/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0096 - mae: 0.0197 - val_loss: 0.0216 - val_mae: 0.0351\n",
      "Epoch 179/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0096 - mae: 0.0207 - val_loss: 0.0216 - val_mae: 0.0343\n",
      "Epoch 180/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0095 - mae: 0.0205 - val_loss: 0.0216 - val_mae: 0.0346\n",
      "Epoch 181/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0095 - mae: 0.0230 - val_loss: 0.0214 - val_mae: 0.0366\n",
      "Epoch 182/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0097 - mae: 0.0195 - val_loss: 0.0215 - val_mae: 0.0345\n",
      "Epoch 183/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0097 - mae: 0.0248 - val_loss: 0.0214 - val_mae: 0.0353\n",
      "Epoch 184/300\n",
      "910/910 [==============================] - 0s 52us/sample - loss: 0.0095 - mae: 0.0196 - val_loss: 0.0216 - val_mae: 0.0333\n",
      "Epoch 185/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0095 - mae: 0.0203 - val_loss: 0.0215 - val_mae: 0.0335\n",
      "Epoch 186/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0095 - mae: 0.0195 - val_loss: 0.0215 - val_mae: 0.0334\n",
      "Epoch 187/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0094 - mae: 0.0191 - val_loss: 0.0213 - val_mae: 0.0343\n",
      "Epoch 188/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0095 - mae: 0.0232 - val_loss: 0.0213 - val_mae: 0.0361\n",
      "Epoch 189/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0096 - mae: 0.0189 - val_loss: 0.0213 - val_mae: 0.0363\n",
      "Epoch 190/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0095 - mae: 0.0252 - val_loss: 0.0211 - val_mae: 0.0370\n",
      "Epoch 191/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0094 - mae: 0.0224 - val_loss: 0.0211 - val_mae: 0.0355\n",
      "Epoch 192/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0095 - mae: 0.0196 - val_loss: 0.0213 - val_mae: 0.0344\n",
      "Epoch 193/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0094 - mae: 0.0222 - val_loss: 0.0212 - val_mae: 0.0333\n",
      "Epoch 194/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0094 - mae: 0.0188 - val_loss: 0.0211 - val_mae: 0.0349\n",
      "Epoch 195/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0093 - mae: 0.0203 - val_loss: 0.0211 - val_mae: 0.0338\n",
      "Epoch 196/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0093 - mae: 0.0222 - val_loss: 0.0210 - val_mae: 0.0359\n",
      "Epoch 197/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0093 - mae: 0.0197 - val_loss: 0.0210 - val_mae: 0.0341\n",
      "Epoch 198/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0093 - mae: 0.0212 - val_loss: 0.0209 - val_mae: 0.0352\n",
      "Epoch 199/300\n",
      "910/910 [==============================] - 0s 51us/sample - loss: 0.0093 - mae: 0.0206 - val_loss: 0.0210 - val_mae: 0.0356\n",
      "Epoch 200/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0093 - mae: 0.0202 - val_loss: 0.0210 - val_mae: 0.0334\n",
      "Epoch 201/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0093 - mae: 0.0237 - val_loss: 0.0208 - val_mae: 0.0357\n",
      "Epoch 202/300\n",
      "910/910 [==============================] - 0s 58us/sample - loss: 0.0093 - mae: 0.0182 - val_loss: 0.0208 - val_mae: 0.0343\n",
      "Epoch 203/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0092 - mae: 0.0208 - val_loss: 0.0208 - val_mae: 0.0336\n",
      "Epoch 204/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0092 - mae: 0.0191 - val_loss: 0.0208 - val_mae: 0.0348\n",
      "Epoch 205/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0092 - mae: 0.0202 - val_loss: 0.0208 - val_mae: 0.0332\n",
      "Epoch 206/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0092 - mae: 0.0206 - val_loss: 0.0207 - val_mae: 0.0334\n",
      "Epoch 207/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0092 - mae: 0.0175 - val_loss: 0.0207 - val_mae: 0.0335\n",
      "Epoch 208/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0092 - mae: 0.0237 - val_loss: 0.0205 - val_mae: 0.0349\n",
      "Epoch 209/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0091 - mae: 0.0195 - val_loss: 0.0206 - val_mae: 0.0334\n",
      "Epoch 210/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0092 - mae: 0.0186 - val_loss: 0.0206 - val_mae: 0.0343\n",
      "Epoch 211/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0091 - mae: 0.0210 - val_loss: 0.0204 - val_mae: 0.0350\n",
      "Epoch 212/300\n",
      "910/910 [==============================] - 0s 59us/sample - loss: 0.0091 - mae: 0.0190 - val_loss: 0.0205 - val_mae: 0.0341\n",
      "Epoch 213/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0091 - mae: 0.0200 - val_loss: 0.0204 - val_mae: 0.0344\n",
      "Epoch 214/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0091 - mae: 0.0230 - val_loss: 0.0204 - val_mae: 0.0344\n",
      "Epoch 215/300\n",
      "910/910 [==============================] - 0s 57us/sample - loss: 0.0091 - mae: 0.0192 - val_loss: 0.0203 - val_mae: 0.0343\n",
      "Epoch 216/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0090 - mae: 0.0195 - val_loss: 0.0204 - val_mae: 0.0320\n",
      "Epoch 217/300\n",
      "910/910 [==============================] - 0s 62us/sample - loss: 0.0090 - mae: 0.0184 - val_loss: 0.0204 - val_mae: 0.0323\n",
      "Epoch 218/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0090 - mae: 0.0202 - val_loss: 0.0203 - val_mae: 0.0327\n",
      "Epoch 219/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0091 - mae: 0.0190 - val_loss: 0.0202 - val_mae: 0.0364\n",
      "Epoch 220/300\n",
      "910/910 [==============================] - 0s 60us/sample - loss: 0.0090 - mae: 0.0189 - val_loss: 0.0202 - val_mae: 0.0340\n",
      "Epoch 221/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0090 - mae: 0.0189 - val_loss: 0.0202 - val_mae: 0.0346\n",
      "Epoch 222/300\n",
      "910/910 [==============================] - 0s 55us/sample - loss: 0.0090 - mae: 0.0205 - val_loss: 0.0202 - val_mae: 0.0328\n",
      "Epoch 223/300\n",
      "910/910 [==============================] - 0s 54us/sample - loss: 0.0091 - mae: 0.0246 - val_loss: 0.0201 - val_mae: 0.0336\n",
      "Epoch 224/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0091 - mae: 0.0164 - val_loss: 0.0199 - val_mae: 0.0352\n",
      "Epoch 225/300\n",
      "910/910 [==============================] - 0s 63us/sample - loss: 0.0089 - mae: 0.0225 - val_loss: 0.0201 - val_mae: 0.0319\n",
      "Epoch 226/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0089 - mae: 0.0198 - val_loss: 0.0199 - val_mae: 0.0331\n",
      "Epoch 227/300\n",
      "910/910 [==============================] - 0s 56us/sample - loss: 0.0088 - mae: 0.0191 - val_loss: 0.0200 - val_mae: 0.0314\n",
      "Epoch 228/300\n",
      "910/910 [==============================] - 0s 51us/sample - loss: 0.0089 - mae: 0.0160 - val_loss: 0.0199 - val_mae: 0.0336\n",
      "Epoch 229/300\n",
      "910/910 [==============================] - 0s 53us/sample - loss: 0.0088 - mae: 0.0206 - val_loss: 0.0200 - val_mae: 0.0315\n",
      "Epoch 230/300\n",
      "910/910 [==============================] - 0s 65us/sample - loss: 0.0089 - mae: 0.0191 - val_loss: 0.0196 - val_mae: 0.0341\n",
      "Epoch 231/300\n",
      "910/910 [==============================] - 0s 64us/sample - loss: 0.0088 - mae: 0.0183 - val_loss: 0.0198 - val_mae: 0.0340\n",
      "Epoch 232/300\n",
      " 64/910 [=>............................] - ETA: 0s - loss: 0.0121 - mae: 0.0234"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(keras.layers.Dense(32, activation='relu', input_shape=(1,)))\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "history = model.fit(train_X, train_Y, epochs=400, batch_size=64,\n",
    "                    validation_data=(dev_X, dev_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "SKIP = 100\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate and print the loss on our test dataset\n",
    "loss = model.evaluate(test_X, test_Y)\n",
    "\n",
    "# Make predictions based on our test dataset\n",
    "predictions = model.predict(test_X)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.clf()\n",
    "plt.title('Comparison of predictions and actual values')\n",
    "plt.plot(test_Y, test_X, 'b.', label='Actual')\n",
    "plt.plot(predictions, test_X, 'r.', label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "#model = load_model('model.h5')\n",
    "# summarize model.\n",
    "#model.summary()\n",
    "\n",
    "model.save(\"model_TinyML.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "  for i in range(500):\n",
    "    yield([train_X[i].reshape(1, 1)])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce full-int8 quantization (except inputs/outputs which are always float)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)\n",
    "\n",
    "import os\n",
    "model_size = os.path.getsize(MODEL_TFLITE)\n",
    "print(\"Quantized model is %d bytes\" % model_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an interpreter for the model\n",
    "model = tf.lite.Interpreter(MODEL_TFLITE)\n",
    "\n",
    "# Allocate memory for the model\n",
    "model.allocate_tensors()\n",
    "\n",
    "# Get the input and output tensors so we can feed in values and get the results\n",
    "model_input = model.tensor(model.get_input_details()[0][\"index\"])\n",
    "model_output = model.tensor(model.get_output_details()[0][\"index\"])\n",
    "\n",
    "# Create arrays to store the results\n",
    "model_predictions = np.empty(test_X.shape[0])\n",
    "\n",
    "# Run each model's interpreter for each value and store the results in arrays\n",
    "for i in range(test_X.size):\n",
    "  model.set_tensor(model.get_input_details()[0][\"index\"], train_X[i].reshape(1,1))\n",
    "  model.invoke()\n",
    "  model_predictions[i] = model_output()[0]\n",
    "\n",
    "# See how they line up with the data\n",
    "plt.clf()\n",
    "plt.title('Comparison of various models against actual values')\n",
    "plt.plot(test_Y, 'bo', label='Actual values')\n",
    "plt.plot(model_predictions, 'gx', label='Lite quantized predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
